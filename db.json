{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/sonic/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/sonic/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/images/aerial.png","path":"css/images/aerial.png","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/images/cluster.png","path":"css/images/cluster.png","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/images/portrait.jpg","path":"css/images/portrait.jpg","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/images/ring.png","path":"css/images/ring.png","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/sonic/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/sonic/.npmignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1486062152000},{"_id":"themes/sonic/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1486062152000},{"_id":"themes/sonic/README.md","hash":"c7e83cfe8f2c724fc9cac32bd71bb5faf9ceeddb","modified":1486062152000},{"_id":"themes/sonic/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1486062152000},{"_id":"themes/sonic/_config.yml","hash":"d33e3ecf7eee04b4328aebf595c0b3786a52c4b7","modified":1486744784000},{"_id":"themes/sonic/package.json","hash":"85358dc34311c6662e841584e206a4679183943f","modified":1486062152000},{"_id":"source/_posts/.DS_Store","hash":"bd98a6fec0bd2eda2cc15a6d295e690887f9aa75","modified":1518467962745},{"_id":"source/About/index.md","hash":"7817ba404fa111b29f00946cc79cdcb013054b03","modified":1486733828000},{"_id":"source/_posts/Don-t-block-your-Async-calls.md","hash":"8a626e8f10786fc625064191eacbe1056bbd6551","modified":1492718313000},{"_id":"source/_posts/Dropping-in-on-my-cluster.md","hash":"e10550b15d37c69b52dc1a7b155d21ff1bf65ff3","modified":1487003719000},{"_id":"source/_posts/I-m-Sure-You-Weren-t-Looking.md","hash":"4bbf894490655fcebc454249cdba90c91776c789","modified":1486504560000},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s.md","hash":"b18d2189536545d5012f42eb1ad8077c07c2ff3b","modified":1486760678000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-3.md","hash":"f83ed008089e99dd411493383a00ac7eac5b222c","modified":1518455623873},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2.md","hash":"eeed7141a52237d5e4d8e8c9d2129ac089905747","modified":1518471194452},{"_id":"source/_posts/Ok-yea-so-maybe-it-s-been-a-while-since-I-posted.md","hash":"33c3f0c825b104b05cd40baaaf8265f50dfeaee2","modified":1515525246000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I.md","hash":"cc8deb6be1a75c4275bf720c7456ac14eb0698dd","modified":1518469874747},{"_id":"themes/sonic/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1486062152000},{"_id":"themes/sonic/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1486062152000},{"_id":"themes/sonic/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1486062152000},{"_id":"themes/sonic/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1486062152000},{"_id":"themes/sonic/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1486062152000},{"_id":"themes/sonic/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1486062152000},{"_id":"themes/sonic/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1486062152000},{"_id":"themes/sonic/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1486062152000},{"_id":"themes/sonic/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1486062152000},{"_id":"themes/sonic/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1486062152000},{"_id":"themes/sonic/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1486062152000},{"_id":"themes/sonic/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1486062152000},{"_id":"themes/sonic/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1486062152000},{"_id":"themes/sonic/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1486062152000},{"_id":"themes/sonic/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1486062152000},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberrypi.jpg","hash":"272317ca80eae327245bf68500f7c56c353b2dd5","modified":1486588734000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tag.png","hash":"763a1e46145c9d40add3ca9a5420ff0e0911bd2c","modified":1518209248111},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/overviewarch.png","hash":"6015d84245d41b7a1629f68bd016f0e782690000","modified":1515699175000},{"_id":"themes/sonic/layout/_partial/after-footer.ejs","hash":"82a30f81c0e8ba4a8af17acd6cc99e93834e4d5e","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/archive.ejs","hash":"931aaaffa0910a48199388ede576184ff15793ee","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/article.ejs","hash":"c4c835615d96a950d51fa2c3b5d64d0596534fed","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/head.ejs","hash":"4fe8853e864d192701c03e5cd3a5390287b90612","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1486062152000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tagsbyletterexample.png","hash":"d8a24ea71d3d62410f66798e8ea5f2e03cd37ec2","modified":1516646427000},{"_id":"themes/sonic/layout/_partial/header.ejs","hash":"3e26f3453d581d76e62512fe2c90b56a0ab4e5d0","modified":1486758694000},{"_id":"themes/sonic/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1486062152000},{"_id":"themes/sonic/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1486062152000},{"_id":"themes/sonic/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1486062152000},{"_id":"themes/sonic/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1486062152000},{"_id":"themes/sonic/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1486062152000},{"_id":"themes/sonic/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1486062152000},{"_id":"themes/sonic/source/css/.DS_Store","hash":"495dc0d217dbc3e7cb0c015a4aa9af3e7011d37f","modified":1486477097000},{"_id":"themes/sonic/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1486062152000},{"_id":"themes/sonic/source/css/_variables.styl","hash":"8baf64b83bbb118d8191a6e6d7b56b82fbaa5b9d","modified":1486658549000},{"_id":"themes/sonic/source/css/style.styl","hash":"eff7ea0c1c85f78fa5b64b82bcf7c7490f5db7b9","modified":1486746726000},{"_id":"themes/sonic/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1486062152000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tag.png","hash":"763a1e46145c9d40add3ca9a5420ff0e0911bd2c","modified":1515617533000},{"_id":"themes/sonic/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1486062152000},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/opscenter_cluster.png","hash":"b52da9fb9e980ead1b60435f4adf26ee60ee1150","modified":1486671546000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tagsbyletterorig.png","hash":"0aabd9c5abe6042c3df32ddc80824d7c61b502f0","modified":1518139094957},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/pie-pi.jpg","hash":"d93f3955eecc84e21ce33ed9e560016bb62a224e","modified":1486563203000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch1.png","hash":"7cf161c0830955236d372e899642b2a48945633a","modified":1518139297541},{"_id":"themes/sonic/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1486062152000},{"_id":"themes/sonic/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1486062152000},{"_id":"themes/sonic/source/css/_partial/archive.styl","hash":"203a8803642438c4389dde5b8158e803f556f5eb","modified":1486489179000},{"_id":"themes/sonic/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1486062152000},{"_id":"themes/sonic/source/css/_partial/article.styl","hash":"5628c0f28e1e6d257e5ee172a32a9322b0362d9a","modified":1486746745000},{"_id":"themes/sonic/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1486062152000},{"_id":"themes/sonic/source/css/_partial/header.styl","hash":"b40437472ec4151355b82a67ae0ca07e23395e82","modified":1486487251000},{"_id":"themes/sonic/source/css/_partial/highlight.styl","hash":"8677f7dc62a69679df3f10fafa67b78cbe84521a","modified":1486659453000},{"_id":"themes/sonic/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1486487869000},{"_id":"themes/sonic/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1486062152000},{"_id":"themes/sonic/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1486062152000},{"_id":"themes/sonic/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1486062152000},{"_id":"themes/sonic/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1486062152000},{"_id":"themes/sonic/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1486062152000},{"_id":"themes/sonic/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1486062152000},{"_id":"themes/sonic/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1486062152000},{"_id":"themes/sonic/source/css/images/aerial.png","hash":"9280b24baa6825b909b557f153cfd564bb310302","modified":1486398762000},{"_id":"themes/sonic/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1486062152000},{"_id":"themes/sonic/source/css/images/cluster.png","hash":"05fd049eaea1edc121d3ee7beb70050998b92141","modified":1486398952000},{"_id":"themes/sonic/source/css/images/portrait.jpg","hash":"7b1c23db69ed4870f8444d685d50070d3adf9df1","modified":1486395745000},{"_id":"themes/sonic/source/css/images/ring.png","hash":"86b8b08b45634a1d425baacf15bb28742f8201f1","modified":1486407903000},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1486062152000},{"_id":"themes/sonic/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1486062152000},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberry.jpg","hash":"0f426be98f54895b574ebcf4ca9ebc1378b823d9","modified":1486563203000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch2.png","hash":"fd2d542241b36a6d5607d37d979bc473d5ddf7d7","modified":1518139376029},{"_id":"themes/sonic/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1486062152000},{"_id":"themes/sonic/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1486062152000},{"_id":"themes/sonic/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1486062152000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/typeahead.png","hash":"e83013be7c58eb9d029dac05ca452283b4437bd1","modified":1515679919000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/morelikethis.png","hash":"907f9bd145dcdbc6bd1b310eed80e8b8d93b2db5","modified":1518209248227},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/morelikethis.png","hash":"907f9bd145dcdbc6bd1b310eed80e8b8d93b2db5","modified":1515618084000},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/hugesearchbarlist.png","hash":"98acc0e09320d311a2e0503572d631e68cbe5914","modified":1518140362982},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/notag.png","hash":"64767dda0b93bb2d17a4a57f96470d3b30d37ce5","modified":1518214581318},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/videodetail.png","hash":"ddd7aae5daeeb1145b269287f4f7ccef0ffa6667","modified":1515618433000},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/myPIs.gif","hash":"c4fcede0402ea86cdb7c8456dead47112caa3189","modified":1486654238000},{"_id":"source/_posts/Dropping-in-on-my-cluster/datastax_drop.gif","hash":"ea2bb1ac95206e178572205412fd7f8da36645b8","modified":1487003427000},{"_id":"public/content.json","hash":"6bec7c5d5281bd43ebe89a6af9dac5da7963fa30","modified":1518471334099},{"_id":"public/About/index.html","hash":"f680859aee53ba413ac7919934dfccd5c649db10","modified":1518471334251},{"_id":"public/2018/01/09/Ok-yea-so-maybe-it-s-been-a-while-since-I-posted/index.html","hash":"77573b36af8a4211a303af0fd81276e80cfb532e","modified":1518471334251},{"_id":"public/2017/02/13/Dropping-in-on-my-cluster/index.html","hash":"e81c6eeba59ca57dd4c8b547ce9988b2fc8c5e03","modified":1518471334252},{"_id":"public/2017/02/07/I-m-Sure-You-Weren-t-Looking/index.html","hash":"a37788b30361bc11fe0ca338811a7843e2fae6c2","modified":1518471334252},{"_id":"public/archives/index.html","hash":"ee385d3f9e44253492638fa283e1b18d8ff42830","modified":1518471334252},{"_id":"public/archives/2017/index.html","hash":"fe1527ed745741827791940a903954b4f9832c7c","modified":1518471334252},{"_id":"public/archives/2017/02/index.html","hash":"e5425f248297cb161dae02a35eef3f77a658acba","modified":1518471334252},{"_id":"public/archives/2017/04/index.html","hash":"c59eb47e2d1dd68f369ae3982c60eb676bb1c648","modified":1518471334252},{"_id":"public/archives/2018/index.html","hash":"e3772c392b84bc8f4a04e00e847ef0c7b4575f63","modified":1518471334252},{"_id":"public/archives/2018/01/index.html","hash":"6dcae4418ea9a258d9909a9c643f1b945c71a379","modified":1518471334253},{"_id":"public/archives/2018/02/index.html","hash":"2f7c712aaf7fabe3dfec576e2e58477942b96dd0","modified":1518471334253},{"_id":"public/categories/Technical/index.html","hash":"6ace8ad963841aa02bd2a680d301fc5be942d0cc","modified":1518471334253},{"_id":"public/categories/Aerial/index.html","hash":"b2a4807b6232d1981e037fae05d985be5a63b839","modified":1518471334253},{"_id":"public/categories/Something-Else/index.html","hash":"f4a21575d2abe961cdf715fd159cfcdb619f2325","modified":1518471334253},{"_id":"public/tags/TIL/index.html","hash":"429c9e898c55d80cf81d006527066fd4c17f4e17","modified":1518471334253},{"_id":"public/tags/async/index.html","hash":"4dc50671621e085a00a5ab76faabd71269b0ae33","modified":1518471334253},{"_id":"public/tags/blocking/index.html","hash":"8309142e5f760cf9ca6d45b529eb002152ceb2bf","modified":1518471334253},{"_id":"public/tags/java/index.html","hash":"be80a7208e7a13198d4cdce8b45d39303cc5a298","modified":1518471334253},{"_id":"public/tags/killrvideo/index.html","hash":"1adc54fb8fd358a46f6303cd041a3bb937df4ec4","modified":1518471334253},{"_id":"public/tags/datastax/index.html","hash":"9072cc5eb996016c985c6d81d69201d9f280db32","modified":1518471334253},{"_id":"public/tags/opscenter/index.html","hash":"dca87d102a7bb3a6d6dfe9b4760ecf57f7fc7416","modified":1518471334253},{"_id":"public/tags/aerial/index.html","hash":"adfd55eb7377409157051ebc6fa6dcfc5ef197cb","modified":1518471334253},{"_id":"public/tags/drop/index.html","hash":"7d76a15a5cd0e26946257683a1e56e65742298e3","modified":1518471334253},{"_id":"public/tags/hi-there/index.html","hash":"2e9cc2a46b2fdf7870c6f8479f13bb362d68584d","modified":1518471334253},{"_id":"public/tags/welcome/index.html","hash":"b793f0ca9e33ec390b754158a3059214284c399d","modified":1518471334254},{"_id":"public/tags/fun-times/index.html","hash":"d3b20fe879e2054cd64096f7aa62f80337e71e1a","modified":1518471334254},{"_id":"public/tags/OMG/index.html","hash":"06e293ad1d155d814660ac214c44d8c3847d7521","modified":1518471334254},{"_id":"public/tags/raspberry-PI/index.html","hash":"809477150494d28256c745addab39ab259b7defa","modified":1518471334254},{"_id":"public/tags/cluster/index.html","hash":"d87861012a106b853007359b3a692b64c8e0d6e9","modified":1518471334254},{"_id":"public/tags/search/index.html","hash":"4f79715a42b7472108682f09fc5b26a51900075e","modified":1518471334254},{"_id":"public/tags/DSE-Search/index.html","hash":"2dc887263cff53b1737229f992fd17e2a333faee","modified":1518471334254},{"_id":"public/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/index.html","hash":"0862f5606773eb74cfabcbf20cf75d13a3bac238","modified":1518471334254},{"_id":"public/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/index.html","hash":"38a914d1795bd7c291d234e5515256ff1f5e0161","modified":1518471334254},{"_id":"public/2017/04/17/Don-t-block-your-Async-calls/index.html","hash":"40c449a6967a94438372ecf7f7c0a4d4e7725775","modified":1518471334254},{"_id":"public/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/index.html","hash":"f1454c218160651b68b18c7b17afd9196f8de2c8","modified":1518471334254},{"_id":"public/index.html","hash":"e6a0a9f86fb4b27dd85ade19e36c66c0c42882e0","modified":1518471334254},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1518471334281},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1518471334281},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1518471334282},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1518471334282},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1518471334282},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1518471334282},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1518471334282},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1518471334282},{"_id":"public/css/images/aerial.png","hash":"9280b24baa6825b909b557f153cfd564bb310302","modified":1518471334282},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1518471334282},{"_id":"public/css/images/cluster.png","hash":"05fd049eaea1edc121d3ee7beb70050998b92141","modified":1518471334282},{"_id":"public/css/images/portrait.jpg","hash":"7b1c23db69ed4870f8444d685d50070d3adf9df1","modified":1518471334282},{"_id":"public/css/images/ring.png","hash":"86b8b08b45634a1d425baacf15bb28742f8201f1","modified":1518471334283},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1518471334283},{"_id":"public/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberrypi.jpg","hash":"272317ca80eae327245bf68500f7c56c353b2dd5","modified":1518471334283},{"_id":"public/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/overviewarch.png","hash":"6015d84245d41b7a1629f68bd016f0e782690000","modified":1518471334283},{"_id":"public/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tag.png","hash":"763a1e46145c9d40add3ca9a5420ff0e0911bd2c","modified":1518471334283},{"_id":"public/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tagsbyletterexample.png","hash":"d8a24ea71d3d62410f66798e8ea5f2e03cd37ec2","modified":1518471334283},{"_id":"public/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tag.png","hash":"763a1e46145c9d40add3ca9a5420ff0e0911bd2c","modified":1518471334283},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1518471335111},{"_id":"public/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/opscenter_cluster.png","hash":"b52da9fb9e980ead1b60435f4adf26ee60ee1150","modified":1518471335113},{"_id":"public/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tagsbyletterorig.png","hash":"0aabd9c5abe6042c3df32ddc80824d7c61b502f0","modified":1518471335113},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1518471335117},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1518471335117},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1518471335117},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1518471335117},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1518471335117},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1518471335118},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1518471335118},{"_id":"public/css/style.css","hash":"49fd3973b38875d6beccfbe16691632784d7eeba","modified":1518471335118},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1518471335118},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1518471335118},{"_id":"public/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/pie-pi.jpg","hash":"d93f3955eecc84e21ce33ed9e560016bb62a224e","modified":1518471335119},{"_id":"public/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch1.png","hash":"7cf161c0830955236d372e899642b2a48945633a","modified":1518471335119},{"_id":"public/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1518471335123},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1518471335123},{"_id":"public/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberry.jpg","hash":"0f426be98f54895b574ebcf4ca9ebc1378b823d9","modified":1518471335123},{"_id":"public/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch2.png","hash":"fd2d542241b36a6d5607d37d979bc473d5ddf7d7","modified":1518471335124},{"_id":"public/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/typeahead.png","hash":"e83013be7c58eb9d029dac05ca452283b4437bd1","modified":1518471335128},{"_id":"public/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/morelikethis.png","hash":"907f9bd145dcdbc6bd1b310eed80e8b8d93b2db5","modified":1518471335137},{"_id":"public/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/morelikethis.png","hash":"907f9bd145dcdbc6bd1b310eed80e8b8d93b2db5","modified":1518471335138},{"_id":"public/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/hugesearchbarlist.png","hash":"98acc0e09320d311a2e0503572d631e68cbe5914","modified":1518471335147},{"_id":"public/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/videodetail.png","hash":"ddd7aae5daeeb1145b269287f4f7ccef0ffa6667","modified":1518471335149},{"_id":"public/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/notag.png","hash":"64767dda0b93bb2d17a4a57f96470d3b30d37ce5","modified":1518471335151},{"_id":"public/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/myPIs.gif","hash":"c4fcede0402ea86cdb7c8456dead47112caa3189","modified":1518471335154},{"_id":"public/2017/02/13/Dropping-in-on-my-cluster/datastax_drop.gif","hash":"ea2bb1ac95206e178572205412fd7f8da36645b8","modified":1518471335168}],"Category":[{"name":"Technical","_id":"cjdkqmje20003nhkmhq6tuaym"},{"name":"Aerial","_id":"cjdkqmjek0008nhkmvlrxg3xz"},{"name":"Something Else","_id":"cjdkqmjes000dnhkmvu8o6p7j"}],"Data":[],"Page":[{"title":"About me","date":"2017-02-06T20:54:38.000Z","_content":"Hi there, I'm David Gilardi, a nerd, sci-fi, fantasy enthusiast who would like nothing more than to get on the Starship Enterprise (or anything remotely like it that won't explode on its first voyage) and explore the universe.  Until that happens I'll continue playing games, building distributed database clusters, climbing up multi-story strips of fabric while calling it \"art\", and \"improving\" every bit of my house that I can.\n\n## You mentioned distributed databases\nYuppers.  I'm currently a Technical Evangelist at DataStax and let me tell you after 20+ years in my career coding, DBAing, building bare metal and cloud infrastructure, and managing I am a happy camper getting back into some seriously cool tech.  I have a mixed-workload search/graph/Cassandra cluster using 4 Raspberry PI's for my core Cassandra DC.  You can't get much more commodity hardware than PI's and my cluster is humming along quite nicely.\n\n## Strips of fabric?\nYes!  One of my favorite activities is aerial arts.  Seriously, drop the gym, start climbing stuff and your body will thank you.  It also might reward you with some torn, ripped, pulled tendons, ligaments, and muscles, but no matter.  It's all earned pain.  I realize I don't make it sound all that great, but after 5 years I'm still in one piece and love every moment of it (most of the time).\n\nHere is a fun example.  Sorry for the potato quality, it won't happen again.  Turn up the sound and wait for the end. \n{% youtube RywLBWQcrys %}","source":"About/index.md","raw":"---\ntitle: About me\ndate: 2017-02-06 15:54:38\n---\nHi there, I'm David Gilardi, a nerd, sci-fi, fantasy enthusiast who would like nothing more than to get on the Starship Enterprise (or anything remotely like it that won't explode on its first voyage) and explore the universe.  Until that happens I'll continue playing games, building distributed database clusters, climbing up multi-story strips of fabric while calling it \"art\", and \"improving\" every bit of my house that I can.\n\n## You mentioned distributed databases\nYuppers.  I'm currently a Technical Evangelist at DataStax and let me tell you after 20+ years in my career coding, DBAing, building bare metal and cloud infrastructure, and managing I am a happy camper getting back into some seriously cool tech.  I have a mixed-workload search/graph/Cassandra cluster using 4 Raspberry PI's for my core Cassandra DC.  You can't get much more commodity hardware than PI's and my cluster is humming along quite nicely.\n\n## Strips of fabric?\nYes!  One of my favorite activities is aerial arts.  Seriously, drop the gym, start climbing stuff and your body will thank you.  It also might reward you with some torn, ripped, pulled tendons, ligaments, and muscles, but no matter.  It's all earned pain.  I realize I don't make it sound all that great, but after 5 years I'm still in one piece and love every moment of it (most of the time).\n\nHere is a fun example.  Sorry for the potato quality, it won't happen again.  Turn up the sound and wait for the end. \n{% youtube RywLBWQcrys %}","updated":"2017-02-10T13:37:08.000Z","path":"About/index.html","comments":1,"layout":"page","_id":"cjdkqmjdq0000nhkm4vc167cj","content":"<p>Hi there, I’m David Gilardi, a nerd, sci-fi, fantasy enthusiast who would like nothing more than to get on the Starship Enterprise (or anything remotely like it that won’t explode on its first voyage) and explore the universe.  Until that happens I’ll continue playing games, building distributed database clusters, climbing up multi-story strips of fabric while calling it “art”, and “improving” every bit of my house that I can.</p>\n<h2 id=\"You-mentioned-distributed-databases\"><a href=\"#You-mentioned-distributed-databases\" class=\"headerlink\" title=\"You mentioned distributed databases\"></a>You mentioned distributed databases</h2><p>Yuppers.  I’m currently a Technical Evangelist at DataStax and let me tell you after 20+ years in my career coding, DBAing, building bare metal and cloud infrastructure, and managing I am a happy camper getting back into some seriously cool tech.  I have a mixed-workload search/graph/Cassandra cluster using 4 Raspberry PI’s for my core Cassandra DC.  You can’t get much more commodity hardware than PI’s and my cluster is humming along quite nicely.</p>\n<h2 id=\"Strips-of-fabric\"><a href=\"#Strips-of-fabric\" class=\"headerlink\" title=\"Strips of fabric?\"></a>Strips of fabric?</h2><p>Yes!  One of my favorite activities is aerial arts.  Seriously, drop the gym, start climbing stuff and your body will thank you.  It also might reward you with some torn, ripped, pulled tendons, ligaments, and muscles, but no matter.  It’s all earned pain.  I realize I don’t make it sound all that great, but after 5 years I’m still in one piece and love every moment of it (most of the time).</p>\n<p>Here is a fun example.  Sorry for the potato quality, it won’t happen again.  Turn up the sound and wait for the end.<br><div class=\"video-container\"><iframe src=\"//www.youtube.com/embed/RywLBWQcrys\" frameborder=\"0\" allowfullscreen></iframe></div></p>\n","excerpt":"","more":"<p>Hi there, I’m David Gilardi, a nerd, sci-fi, fantasy enthusiast who would like nothing more than to get on the Starship Enterprise (or anything remotely like it that won’t explode on its first voyage) and explore the universe.  Until that happens I’ll continue playing games, building distributed database clusters, climbing up multi-story strips of fabric while calling it “art”, and “improving” every bit of my house that I can.</p>\n<h2 id=\"You-mentioned-distributed-databases\"><a href=\"#You-mentioned-distributed-databases\" class=\"headerlink\" title=\"You mentioned distributed databases\"></a>You mentioned distributed databases</h2><p>Yuppers.  I’m currently a Technical Evangelist at DataStax and let me tell you after 20+ years in my career coding, DBAing, building bare metal and cloud infrastructure, and managing I am a happy camper getting back into some seriously cool tech.  I have a mixed-workload search/graph/Cassandra cluster using 4 Raspberry PI’s for my core Cassandra DC.  You can’t get much more commodity hardware than PI’s and my cluster is humming along quite nicely.</p>\n<h2 id=\"Strips-of-fabric\"><a href=\"#Strips-of-fabric\" class=\"headerlink\" title=\"Strips of fabric?\"></a>Strips of fabric?</h2><p>Yes!  One of my favorite activities is aerial arts.  Seriously, drop the gym, start climbing stuff and your body will thank you.  It also might reward you with some torn, ripped, pulled tendons, ligaments, and muscles, but no matter.  It’s all earned pain.  I realize I don’t make it sound all that great, but after 5 years I’m still in one piece and love every moment of it (most of the time).</p>\n<p>Here is a fun example.  Sorry for the potato quality, it won’t happen again.  Turn up the sound and wait for the end.<br><div class=\"video-container\"><iframe src=\"//www.youtube.com/embed/RywLBWQcrys\" frameborder=\"0\" allowfullscreen></iframe></div></p>\n"}],"Post":[{"title":"Don't block your Async calls","date":"2017-04-17T14:31:42.000Z","_content":"Or rather I should be saying that to myself.  So, TIL (today I learned) something simple yet profound while working with asynchronous programming and the [DSE java driver][dsejava].  Ensure that you are properly iterating through your results when making an async call.  You cannot simply iterate all of your rows using a for loop or something along the lines.  Ok, well, technically you can, but if you have more rows than your fetch size the [DSE java driver][dsejava] will throw a big fat error your way letting you know you are blocking within an async call.  I should point that I am still somewhat new to working with asynchronous calls (yes, someone finally pulled up the rock I was under) so for you veterans this may be knowledge already gained from async NOOB 101.  By the way, here is the error the driver threw at me (thank you for doing so DSE driver peeps).\n\n<!-- more -->\n\n```java\nDetected a synchronous call on an I/O thread, this can cause deadlocks or unpredictable behavior. This generally happens when a Future callback calls a synchronous Session method (execute() or prepare()), or iterates a result set past the fetch size (causing an internal synchronous fetch of the next page of results). Avoid this in your callbacks, or schedule them on a different executor.\n\tcom.datastax.driver.core.AbstractSession.checkNotInEventLoop(AbstractSession.java:206)\n\tcom.datastax.driver.core.ArrayBackedResultSet$MultiPage.prepareNextRow(ArrayBackedResultSet.java:310)\n\tcom.datastax.driver.core.ArrayBackedResultSet$MultiPage.isExhausted(ArrayBackedResultSet.java:269)\n\tcom.datastax.driver.core.ArrayBackedResultSet$1.hasNext(ArrayBackedResultSet.java:143)\n\tcom.datastax.driver.mapping.Result$1.hasNext(Result.java:102...\n```\n\nThe reason is stated [here][asyncpaging].  I'll quote it just to be clear \"If you consume a ResultSet in a callback, be aware that iterating the rows will trigger synchronous queries as you page through the results. To avoid this, use getAvailableWithoutFetching to limit the iteration to the current page, and fetchMoreResults to get a future to the next page\".  Even though I read this before I started into this code I must have glossed over this concept the first time through as my implementation was acting very strange indeed.\n\nLet's look at a simple example.  At this point in my code I already made an aynchronous call with session.executeAsync(), created a future, and returned my results into a callback.  The following examples are within my callback.\nIn the case below I mapped my results to the UserVideos entity and now I am iterating through those results to do something with each \"userVideo\" object.\nThis...DOES NOT work and will throw the error I mentioned above.\n\n*Ehem, I have a utility class handle callbacks if you were wondering where that was.  I wanted to keep the example nice and simple.  Just know that by the time you see \".handle\" we are within the callback.*\n```java\n        FutureUtils.buildCompletableFuture(userVideosMapper.mapAsync(future))\n                .handle((userVideos, ex) -> {\n                    try {\n                        if (userVideos != null) {\n                            for (UserVideos userVideo : userVideos) {\n                                \"do something with userVideo here\"\n                            }\n\n```\nIt seems so simple.  I returned my results and now I want to iterate over those results and do something with them, but these aren't synchronous calls that block until complete.  I need to handle them properly from an asynchronous standpoint and only grab those results that have actually been returned.  The rest I will need to fetch with more asynchronous calls.\n\nAgain, this is demonstrated very clearly [here][asyncpaging] in the Async paging section.\n\nThis...is a snippet pulled from the working code using the example given from the [async][asyncpaging] page I keep referencing.  Now, I see how many items I have remaining without fetching, loop through the remaining items, and break out once I have exhausted the list.  You may not see in my example below, but once I \"break;\" I exit out and grab futures for any more items that may be left, rinse and repeat.   \n```java\n        FutureUtils.buildCompletableFuture(userVideosMapper.mapAsync(future))\n                .handle((userVideos, ex) -> {\n                    try {\n                        if (userVideos != null) {\n                            int remaining = userVideos.getAvailableWithoutFetching();\n                            for (UserVideos userVideo : userVideos) {\n                                \"do something with userVideo here\"\n\n                                if (--remaining == 0) {\n                                    break;\n                                }\n                            }\n```\nThe whole point of this post was to point out a potential \"gotcha\" with a very simple fix when dealing with asynchronous programming and the [DSE driver for Java][dsejava].  This one tripped me up for a moment until I realized my mistake.  Now that I know better my \"futures\" are looking bright in deed....see my joke there....ha....haha.....ha...*awkward pause*.  Honestly, this simple change tightend all of my async code up.  No more strange artifacts\n\n\n\n[dsejava]: http://docs.datastax.com/en/developer/java-driver/3.2/\n[asyncprogramming]: http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/\n[asyncpaging]: http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/#async-paging","source":"_posts/Don-t-block-your-Async-calls.md","raw":"---\ntitle: Don't block your Async calls\ndate: 2017-04-17 10:31:42\ntags:\n    - TIL\n    - async\n    - blocking\n    - java\n    - killrvideo\ncategories:\n    - Technical\n---\nOr rather I should be saying that to myself.  So, TIL (today I learned) something simple yet profound while working with asynchronous programming and the [DSE java driver][dsejava].  Ensure that you are properly iterating through your results when making an async call.  You cannot simply iterate all of your rows using a for loop or something along the lines.  Ok, well, technically you can, but if you have more rows than your fetch size the [DSE java driver][dsejava] will throw a big fat error your way letting you know you are blocking within an async call.  I should point that I am still somewhat new to working with asynchronous calls (yes, someone finally pulled up the rock I was under) so for you veterans this may be knowledge already gained from async NOOB 101.  By the way, here is the error the driver threw at me (thank you for doing so DSE driver peeps).\n\n<!-- more -->\n\n```java\nDetected a synchronous call on an I/O thread, this can cause deadlocks or unpredictable behavior. This generally happens when a Future callback calls a synchronous Session method (execute() or prepare()), or iterates a result set past the fetch size (causing an internal synchronous fetch of the next page of results). Avoid this in your callbacks, or schedule them on a different executor.\n\tcom.datastax.driver.core.AbstractSession.checkNotInEventLoop(AbstractSession.java:206)\n\tcom.datastax.driver.core.ArrayBackedResultSet$MultiPage.prepareNextRow(ArrayBackedResultSet.java:310)\n\tcom.datastax.driver.core.ArrayBackedResultSet$MultiPage.isExhausted(ArrayBackedResultSet.java:269)\n\tcom.datastax.driver.core.ArrayBackedResultSet$1.hasNext(ArrayBackedResultSet.java:143)\n\tcom.datastax.driver.mapping.Result$1.hasNext(Result.java:102...\n```\n\nThe reason is stated [here][asyncpaging].  I'll quote it just to be clear \"If you consume a ResultSet in a callback, be aware that iterating the rows will trigger synchronous queries as you page through the results. To avoid this, use getAvailableWithoutFetching to limit the iteration to the current page, and fetchMoreResults to get a future to the next page\".  Even though I read this before I started into this code I must have glossed over this concept the first time through as my implementation was acting very strange indeed.\n\nLet's look at a simple example.  At this point in my code I already made an aynchronous call with session.executeAsync(), created a future, and returned my results into a callback.  The following examples are within my callback.\nIn the case below I mapped my results to the UserVideos entity and now I am iterating through those results to do something with each \"userVideo\" object.\nThis...DOES NOT work and will throw the error I mentioned above.\n\n*Ehem, I have a utility class handle callbacks if you were wondering where that was.  I wanted to keep the example nice and simple.  Just know that by the time you see \".handle\" we are within the callback.*\n```java\n        FutureUtils.buildCompletableFuture(userVideosMapper.mapAsync(future))\n                .handle((userVideos, ex) -> {\n                    try {\n                        if (userVideos != null) {\n                            for (UserVideos userVideo : userVideos) {\n                                \"do something with userVideo here\"\n                            }\n\n```\nIt seems so simple.  I returned my results and now I want to iterate over those results and do something with them, but these aren't synchronous calls that block until complete.  I need to handle them properly from an asynchronous standpoint and only grab those results that have actually been returned.  The rest I will need to fetch with more asynchronous calls.\n\nAgain, this is demonstrated very clearly [here][asyncpaging] in the Async paging section.\n\nThis...is a snippet pulled from the working code using the example given from the [async][asyncpaging] page I keep referencing.  Now, I see how many items I have remaining without fetching, loop through the remaining items, and break out once I have exhausted the list.  You may not see in my example below, but once I \"break;\" I exit out and grab futures for any more items that may be left, rinse and repeat.   \n```java\n        FutureUtils.buildCompletableFuture(userVideosMapper.mapAsync(future))\n                .handle((userVideos, ex) -> {\n                    try {\n                        if (userVideos != null) {\n                            int remaining = userVideos.getAvailableWithoutFetching();\n                            for (UserVideos userVideo : userVideos) {\n                                \"do something with userVideo here\"\n\n                                if (--remaining == 0) {\n                                    break;\n                                }\n                            }\n```\nThe whole point of this post was to point out a potential \"gotcha\" with a very simple fix when dealing with asynchronous programming and the [DSE driver for Java][dsejava].  This one tripped me up for a moment until I realized my mistake.  Now that I know better my \"futures\" are looking bright in deed....see my joke there....ha....haha.....ha...*awkward pause*.  Honestly, this simple change tightend all of my async code up.  No more strange artifacts\n\n\n\n[dsejava]: http://docs.datastax.com/en/developer/java-driver/3.2/\n[asyncprogramming]: http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/\n[asyncpaging]: http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/#async-paging","slug":"Don-t-block-your-Async-calls","published":1,"updated":"2017-04-20T19:58:33.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjdkqmjds0001nhkm3dxrj2l7","content":"<p>Or rather I should be saying that to myself.  So, TIL (today I learned) something simple yet profound while working with asynchronous programming and the <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/\" target=\"_blank\" rel=\"external\">DSE java driver</a>.  Ensure that you are properly iterating through your results when making an async call.  You cannot simply iterate all of your rows using a for loop or something along the lines.  Ok, well, technically you can, but if you have more rows than your fetch size the <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/\" target=\"_blank\" rel=\"external\">DSE java driver</a> will throw a big fat error your way letting you know you are blocking within an async call.  I should point that I am still somewhat new to working with asynchronous calls (yes, someone finally pulled up the rock I was under) so for you veterans this may be knowledge already gained from async NOOB 101.  By the way, here is the error the driver threw at me (thank you for doing so DSE driver peeps).</p>\n<a id=\"more\"></a>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Detected a synchronous call on an I/O thread, <span class=\"keyword\">this</span> can cause deadlocks or unpredictable behavior. <span class=\"function\">This generally happens when a Future callback calls a synchronous Session <span class=\"title\">method</span> <span class=\"params\">(execute()</span> or <span class=\"title\">prepare</span><span class=\"params\">()</span>), or iterates a result set past the fetch <span class=\"title\">size</span> <span class=\"params\">(causing an internal synchronous fetch of the next page of results)</span>. Avoid <span class=\"keyword\">this</span> in your callbacks, or schedule them on a different executor.</span></div><div class=\"line\">\tcom.datastax.driver.core.AbstractSession.<span class=\"title\">checkNotInEventLoop</span><span class=\"params\">(AbstractSession.java:<span class=\"number\">206</span>)</span></div><div class=\"line\">\tcom.datastax.driver.core.ArrayBackedResultSet$MultiPage.<span class=\"title\">prepareNextRow</span><span class=\"params\">(ArrayBackedResultSet.java:<span class=\"number\">310</span>)</span></div><div class=\"line\">\tcom.datastax.driver.core.ArrayBackedResultSet$MultiPage.<span class=\"title\">isExhausted</span><span class=\"params\">(ArrayBackedResultSet.java:<span class=\"number\">269</span>)</span></div><div class=\"line\">\tcom.datastax.driver.core.ArrayBackedResultSet$1.<span class=\"title\">hasNext</span><span class=\"params\">(ArrayBackedResultSet.java:<span class=\"number\">143</span>)</span></div><div class=\"line\">\tcom.datastax.driver.mapping.Result$1.<span class=\"title\">hasNext</span><span class=\"params\">(Result.java:<span class=\"number\">102.</span>..</span></div></pre></td></tr></table></figure>\n<p>The reason is stated <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/#async-paging\" target=\"_blank\" rel=\"external\">here</a>.  I’ll quote it just to be clear “If you consume a ResultSet in a callback, be aware that iterating the rows will trigger synchronous queries as you page through the results. To avoid this, use getAvailableWithoutFetching to limit the iteration to the current page, and fetchMoreResults to get a future to the next page”.  Even though I read this before I started into this code I must have glossed over this concept the first time through as my implementation was acting very strange indeed.</p>\n<p>Let’s look at a simple example.  At this point in my code I already made an aynchronous call with session.executeAsync(), created a future, and returned my results into a callback.  The following examples are within my callback.<br>In the case below I mapped my results to the UserVideos entity and now I am iterating through those results to do something with each “userVideo” object.<br>This…DOES NOT work and will throw the error I mentioned above.</p>\n<p><em>Ehem, I have a utility class handle callbacks if you were wondering where that was.  I wanted to keep the example nice and simple.  Just know that by the time you see “.handle” we are within the callback.</em><br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">FutureUtils.buildCompletableFuture(userVideosMapper.mapAsync(future))</div><div class=\"line\">        .handle((userVideos, ex) -&gt; &#123;</div><div class=\"line\">            <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">                <span class=\"keyword\">if</span> (userVideos != <span class=\"keyword\">null</span>) &#123;</div><div class=\"line\">                    <span class=\"keyword\">for</span> (UserVideos userVideo : userVideos) &#123;</div><div class=\"line\">                        <span class=\"string\">\"do something with userVideo here\"</span></div><div class=\"line\">                    &#125;</div></pre></td></tr></table></figure></p>\n<p>It seems so simple.  I returned my results and now I want to iterate over those results and do something with them, but these aren’t synchronous calls that block until complete.  I need to handle them properly from an asynchronous standpoint and only grab those results that have actually been returned.  The rest I will need to fetch with more asynchronous calls.</p>\n<p>Again, this is demonstrated very clearly <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/#async-paging\" target=\"_blank\" rel=\"external\">here</a> in the Async paging section.</p>\n<p>This…is a snippet pulled from the working code using the example given from the <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/#async-paging\" target=\"_blank\" rel=\"external\">async</a> page I keep referencing.  Now, I see how many items I have remaining without fetching, loop through the remaining items, and break out once I have exhausted the list.  You may not see in my example below, but once I “break;” I exit out and grab futures for any more items that may be left, rinse and repeat.<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">FutureUtils.buildCompletableFuture(userVideosMapper.mapAsync(future))</div><div class=\"line\">        .handle((userVideos, ex) -&gt; &#123;</div><div class=\"line\">            <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">                <span class=\"keyword\">if</span> (userVideos != <span class=\"keyword\">null</span>) &#123;</div><div class=\"line\">                    <span class=\"keyword\">int</span> remaining = userVideos.getAvailableWithoutFetching();</div><div class=\"line\">                    <span class=\"keyword\">for</span> (UserVideos userVideo : userVideos) &#123;</div><div class=\"line\">                        <span class=\"string\">\"do something with userVideo here\"</span></div><div class=\"line\"></div><div class=\"line\">                        <span class=\"keyword\">if</span> (--remaining == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">                            <span class=\"keyword\">break</span>;</div><div class=\"line\">                        &#125;</div><div class=\"line\">                    &#125;</div></pre></td></tr></table></figure></p>\n<p>The whole point of this post was to point out a potential “gotcha” with a very simple fix when dealing with asynchronous programming and the <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/\" target=\"_blank\" rel=\"external\">DSE driver for Java</a>.  This one tripped me up for a moment until I realized my mistake.  Now that I know better my “futures” are looking bright in deed….see my joke there….ha….haha…..ha…<em>awkward pause</em>.  Honestly, this simple change tightend all of my async code up.  No more strange artifacts</p>\n","excerpt":"<p>Or rather I should be saying that to myself.  So, TIL (today I learned) something simple yet profound while working with asynchronous programming and the <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/\">DSE java driver</a>.  Ensure that you are properly iterating through your results when making an async call.  You cannot simply iterate all of your rows using a for loop or something along the lines.  Ok, well, technically you can, but if you have more rows than your fetch size the <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/\">DSE java driver</a> will throw a big fat error your way letting you know you are blocking within an async call.  I should point that I am still somewhat new to working with asynchronous calls (yes, someone finally pulled up the rock I was under) so for you veterans this may be knowledge already gained from async NOOB 101.  By the way, here is the error the driver threw at me (thank you for doing so DSE driver peeps).</p>","more":"<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Detected a synchronous call on an I/O thread, <span class=\"keyword\">this</span> can cause deadlocks or unpredictable behavior. <span class=\"function\">This generally happens when a Future callback calls a synchronous Session <span class=\"title\">method</span> <span class=\"params\">(execute()</span> or <span class=\"title\">prepare</span><span class=\"params\">()</span>), or iterates a result set past the fetch <span class=\"title\">size</span> <span class=\"params\">(causing an internal synchronous fetch of the next page of results)</span>. Avoid <span class=\"keyword\">this</span> in your callbacks, or schedule them on a different executor.</div><div class=\"line\">\tcom.datastax.driver.core.AbstractSession.<span class=\"title\">checkNotInEventLoop</span><span class=\"params\">(AbstractSession.java:<span class=\"number\">206</span>)</span></div><div class=\"line\">\tcom.datastax.driver.core.ArrayBackedResultSet$MultiPage.<span class=\"title\">prepareNextRow</span><span class=\"params\">(ArrayBackedResultSet.java:<span class=\"number\">310</span>)</span></div><div class=\"line\">\tcom.datastax.driver.core.ArrayBackedResultSet$MultiPage.<span class=\"title\">isExhausted</span><span class=\"params\">(ArrayBackedResultSet.java:<span class=\"number\">269</span>)</span></div><div class=\"line\">\tcom.datastax.driver.core.ArrayBackedResultSet$1.<span class=\"title\">hasNext</span><span class=\"params\">(ArrayBackedResultSet.java:<span class=\"number\">143</span>)</span></div><div class=\"line\">\tcom.datastax.driver.mapping.Result$1.<span class=\"title\">hasNext</span><span class=\"params\">(Result.java:<span class=\"number\">102.</span>..</span></span></div></pre></td></tr></table></figure>\n<p>The reason is stated <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/#async-paging\">here</a>.  I’ll quote it just to be clear “If you consume a ResultSet in a callback, be aware that iterating the rows will trigger synchronous queries as you page through the results. To avoid this, use getAvailableWithoutFetching to limit the iteration to the current page, and fetchMoreResults to get a future to the next page”.  Even though I read this before I started into this code I must have glossed over this concept the first time through as my implementation was acting very strange indeed.</p>\n<p>Let’s look at a simple example.  At this point in my code I already made an aynchronous call with session.executeAsync(), created a future, and returned my results into a callback.  The following examples are within my callback.<br>In the case below I mapped my results to the UserVideos entity and now I am iterating through those results to do something with each “userVideo” object.<br>This…DOES NOT work and will throw the error I mentioned above.</p>\n<p><em>Ehem, I have a utility class handle callbacks if you were wondering where that was.  I wanted to keep the example nice and simple.  Just know that by the time you see “.handle” we are within the callback.</em><br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">FutureUtils.buildCompletableFuture(userVideosMapper.mapAsync(future))</div><div class=\"line\">        .handle((userVideos, ex) -&gt; &#123;</div><div class=\"line\">            <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">                <span class=\"keyword\">if</span> (userVideos != <span class=\"keyword\">null</span>) &#123;</div><div class=\"line\">                    <span class=\"keyword\">for</span> (UserVideos userVideo : userVideos) &#123;</div><div class=\"line\">                        <span class=\"string\">\"do something with userVideo here\"</span></div><div class=\"line\">                    &#125;</div></pre></td></tr></table></figure></p>\n<p>It seems so simple.  I returned my results and now I want to iterate over those results and do something with them, but these aren’t synchronous calls that block until complete.  I need to handle them properly from an asynchronous standpoint and only grab those results that have actually been returned.  The rest I will need to fetch with more asynchronous calls.</p>\n<p>Again, this is demonstrated very clearly <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/#async-paging\">here</a> in the Async paging section.</p>\n<p>This…is a snippet pulled from the working code using the example given from the <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/manual/async/#async-paging\">async</a> page I keep referencing.  Now, I see how many items I have remaining without fetching, loop through the remaining items, and break out once I have exhausted the list.  You may not see in my example below, but once I “break;” I exit out and grab futures for any more items that may be left, rinse and repeat.<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">FutureUtils.buildCompletableFuture(userVideosMapper.mapAsync(future))</div><div class=\"line\">        .handle((userVideos, ex) -&gt; &#123;</div><div class=\"line\">            <span class=\"keyword\">try</span> &#123;</div><div class=\"line\">                <span class=\"keyword\">if</span> (userVideos != <span class=\"keyword\">null</span>) &#123;</div><div class=\"line\">                    <span class=\"keyword\">int</span> remaining = userVideos.getAvailableWithoutFetching();</div><div class=\"line\">                    <span class=\"keyword\">for</span> (UserVideos userVideo : userVideos) &#123;</div><div class=\"line\">                        <span class=\"string\">\"do something with userVideo here\"</span></div><div class=\"line\"></div><div class=\"line\">                        <span class=\"keyword\">if</span> (--remaining == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">                            <span class=\"keyword\">break</span>;</div><div class=\"line\">                        &#125;</div><div class=\"line\">                    &#125;</div></pre></td></tr></table></figure></p>\n<p>The whole point of this post was to point out a potential “gotcha” with a very simple fix when dealing with asynchronous programming and the <a href=\"http://docs.datastax.com/en/developer/java-driver/3.2/\">DSE driver for Java</a>.  This one tripped me up for a moment until I realized my mistake.  Now that I know better my “futures” are looking bright in deed….see my joke there….ha….haha…..ha…<em>awkward pause</em>.  Honestly, this simple change tightend all of my async code up.  No more strange artifacts</p>"},{"title":"Dropping in on my cluster","date":"2017-02-13T16:27:17.000Z","_content":"{% asset_img datastax_drop.gif \"Dropping in on my cluster\" %}\nLooks like my nodes are healthy.  :)","source":"_posts/Dropping-in-on-my-cluster.md","raw":"---\ntitle: Dropping in on my cluster\ndate: 2017-02-13 11:27:17\ntags:\n    - datastax\n    - opscenter\n    - aerial\n    - drop\ncategories: Aerial\n---\n{% asset_img datastax_drop.gif \"Dropping in on my cluster\" %}\nLooks like my nodes are healthy.  :)","slug":"Dropping-in-on-my-cluster","published":1,"updated":"2017-02-13T16:35:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjdkqmjdy0002nhkmtoby0ogn","content":"<img src=\"/2017/02/13/Dropping-in-on-my-cluster/datastax_drop.gif\" alt=\"Dropping in on my cluster\" title=\"Dropping in on my cluster\">\n<p>Looks like my nodes are healthy.  :)</p>\n","excerpt":"","more":"<img src=\"/2017/02/13/Dropping-in-on-my-cluster/datastax_drop.gif\" alt=\"Dropping in on my cluster\" title=\"Dropping in on my cluster\">\n<p>Looks like my nodes are healthy.  :)</p>\n"},{"title":"I'm Sure You Weren't Looking","date":"2017-02-07T18:51:11.000Z","_content":"Hi there and welcome to my blog.  As the title suggests I am pretty sure you had no idea this blog or page even existed.  This is most likely due to the fact that I had not published anything until....just now.  \n\n\nWow, you are like....\n\n\n**THE FIRST PERSON HERE OMG!**\n<iframe src=\"//giphy.com/embed/l3q2SubtPHg5E3utW?html5=true\" width=\"480\" height=\"266\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\nSeriously though, thanks for taking a look and make sure to come back and check out my other posts as I muse on things ranging from mishaps while up on silks to technical discussions on distributed database clusters.\n\nIn my next post, I'm going to bring you through my experience setting up a Raspberry PI mixed-worlkload cluster using Cassandra.\n\nSee ya :)","source":"_posts/I-m-Sure-You-Weren-t-Looking.md","raw":"---\ntitle: I'm Sure You Weren't Looking\ndate: 2017-02-07 13:51:11\ncategories:\n    - Something Else\ntags:\n    - hi there\n    - welcome\n    - fun times\n    - OMG\n---\nHi there and welcome to my blog.  As the title suggests I am pretty sure you had no idea this blog or page even existed.  This is most likely due to the fact that I had not published anything until....just now.  \n\n\nWow, you are like....\n\n\n**THE FIRST PERSON HERE OMG!**\n<iframe src=\"//giphy.com/embed/l3q2SubtPHg5E3utW?html5=true\" width=\"480\" height=\"266\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\nSeriously though, thanks for taking a look and make sure to come back and check out my other posts as I muse on things ranging from mishaps while up on silks to technical discussions on distributed database clusters.\n\nIn my next post, I'm going to bring you through my experience setting up a Raspberry PI mixed-worlkload cluster using Cassandra.\n\nSee ya :)","slug":"I-m-Sure-You-Weren-t-Looking","published":1,"updated":"2017-02-07T21:56:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjdkqmje50005nhkm631rdeng","content":"<p>Hi there and welcome to my blog.  As the title suggests I am pretty sure you had no idea this blog or page even existed.  This is most likely due to the fact that I had not published anything until….just now.  </p>\n<p>Wow, you are like….</p>\n<p><strong>THE FIRST PERSON HERE OMG!</strong></p>\n<iframe src=\"//giphy.com/embed/l3q2SubtPHg5E3utW?html5=true\" width=\"480\" height=\"266\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe>\n\n<p>Seriously though, thanks for taking a look and make sure to come back and check out my other posts as I muse on things ranging from mishaps while up on silks to technical discussions on distributed database clusters.</p>\n<p>In my next post, I’m going to bring you through my experience setting up a Raspberry PI mixed-worlkload cluster using Cassandra.</p>\n<p>See ya :)</p>\n","excerpt":"","more":"<p>Hi there and welcome to my blog.  As the title suggests I am pretty sure you had no idea this blog or page even existed.  This is most likely due to the fact that I had not published anything until….just now.  </p>\n<p>Wow, you are like….</p>\n<p><strong>THE FIRST PERSON HERE OMG!</strong></p>\n<iframe src=\"//giphy.com/embed/l3q2SubtPHg5E3utW?html5=true\" width=\"480\" height=\"266\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\n<p>Seriously though, thanks for taking a look and make sure to come back and check out my other posts as I muse on things ranging from mishaps while up on silks to technical discussions on distributed database clusters.</p>\n<p>In my next post, I’m going to bring you through my experience setting up a Raspberry PI mixed-worlkload cluster using Cassandra.</p>\n<p>See ya :)</p>\n"},{"title":"Mixed Workload DSE Cluster with Raspberry PI's","date":"2017-02-07T18:52:11.000Z","_content":"Alrighty, as I mentioned in my previous [post](/2017/02/07/I-m-Sure-You-Weren-t-Looking) I have a mixed-workload cluster (Cassandra, DSE search, DSE graph) using a combination of 4 Raspberry PI's and my laptop.  I had multiple things in mind when I started into this.\n\n1. Low cost for learning\n\n1. Something I can break and not cry about\n\n1. How low can one really go when setting up a cluster?\n\n1. Get some DSE OpsCenter knowledge\n\n1. These are Raspberry PI's, they are just damn cool, so why not setup a cluster?!\n\n<!-- more -->\n\n## PIE?  Raspberries? 3.14? PI?\n{% raw %}\n<div class=\"responsive-container\" style=\"height:160px\">\n    <div class=\"dummy\"></div>\n    <div class=\"img-container\">\n        <div class=\"centerer\"></div>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/pie-pi.jpg\" title=\"pie\" width=\"25%\" height=\"auto\">\n          <span><strong>+</strong></span>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberry.jpg\" title=\"raspberries\" width=\"25%\" height=\"auto\">\n          <span><strong>=</strong></span>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberrypi.jpg\" title=\"raspberrypi\" width=\"25%\" height=\"auto\">\n    </div>\n</div>\n{% endraw %}\n\nIf you are not already familiar with RaspberryPI's [go take a look][raspberrypi].  These are cool little machines for very little cost.\n\n[Here are the specs for the model 3][model3], but just to summarize each node in our cluster only has 1GB of RAM and a 1.2GHz quad-core processor.  This is clearly not a setup to use in your production environment.  This is, however, a great way to learn and experiment.\n\n\n## The setup\n4 [RaspberryPI's][raspberrypi] (wired ethernet)\nNOTE:  These are designed to be \"built up\" so you will need to purchase microSD cards and the outer shells separately\n\nOne `2.6GHz 8 core` MacBook with `16GB RAM` (wired ethernet)\n\n[DataStax Enterprise Opscenter 6.0.7][opscenter] using [tarball installation][opscentertarball]\n\n[DataStax Agent 6.0.7][agent] using [tarball installation][agenttarball]\n\n[DataStax Enterprise 5.0.5][dse], again, using the [tarball installation][dsetarball]\n\n[RAVPower 6 port USB charger][rav] with a set of USB `Male A` to `Micro B` cables.  I also purchased a `4x1 HDMI` switch, but you can easily run these headless if you know your way around a Linux shell.\n\nJust a quick note about the tarball installations.  DSE generally supports using installers across most major platforms and for each of the various installs, but since we are using RaspberryPI's in this case and since I used the [NOOBS][noobs] install to get up and going as fast as I could it just so happens that combination **only works with tarball installs**.  Please, learn from me and don't spend the many, many hours I did eventually figuring this out.   \n\nYou can, in fact, install other operating systems on RaspberryPI's which may allow the installers to work, but you'll have to come back and tell me about it if you give it a go.\n\nAaaaaaand for the reveal dun dunn dunnnnnnnnn! (Yes, those are shiny, lighted cables)\n{% asset_img myPIs.gif \"My Raspberry PI Cluster\" %}\n\n## I may have cheated just a little bit\nSo, I mentioned above \"mixed workload cluster with Raspberry PI's\".  This is 100% true, but also notice there is a laptop in the mix.  I ended up using the laptop to house OpsCenter and my search/graph datacenter and I'm using the PI's for my core Cassandra cluster.  In my experience I don't usually install operations tools and the like directly on production devices facing the public because they have a tendency to cause unpredicatable load.  The limited RAM on the PI's (1GB) is also a factor which I will address here in a moment.  As far as the search/graph datacenter portion I simply used the laptop out of convienence because I already had a 4-node core Cassandra cluster running on the PI's at the time and I wanted to observe the interaction between my search/graph and Cassandra datacenters in a \"pure\" fashion.\n\n## Get this working on PI's\nRaspberry PI's are special snowflakes when it comes to making this all work.  I will detail all this below, but here, for you, is the summarized list of what is needed.\n\n1. [Disable swap][swap]\n`sudo swapoff -a` is your friend.  It is also the quick and dirty way, not permanent on reboot.  Take a look at the \"Disable swapping\" section of [this post][disableswap] if you would like a more permanent solution.\n\n1. Go Headless\nThis is quite easy to do using `sudo raspi-config` while ssh'd into your PI and it will help free up enough memory to make things stable.  Just make sure you already know your PI's IP address or know how to find it if things go sour.\n\n1. Decrease RAM allocated to datastax-agent from `128MB to 64MB` \nEdit `datastax-agent-env.sh` located in [your datastax-agent install dir]/conf/datastax-agent-env.sh\n```bash\nFrom:\nJVM_OPTS=\"$JVM_OPTS -Xmx128M -Djclouds.mpu.parts.magnitude=100000 -Djclouds.mpu.parts.size=16777216\"\n\nTo:\nJVM_OPTS=\"$JVM_OPTS -Xmx64M -Djclouds.mpu.parts.magnitude=100000 -Djclouds.mpu.parts.size=16777216\"\n```\n\n1. Explicitly set Java HEAP settings for Cassandra node\nEdit `cassandra-env.sh` located in [your DSE install dir]/resources/cassandra/conf/cassandra-env.sh.  Search for \"HEAP\" to find and edit the lines.  Notice mine are already set to the working values.  These are commented out by default which will allow the script to calculate values for you, but for our PI case we cannot use the calculated values.\n```bash\nMAX_HEAP_SIZE=\"200M\"\nHEAP_NEWSIZE=\"50M\"\n```\n\n1. [Store collection data on a separate cluster][storecollection]\nRemember that part about \"cheating\" with my [OpsCenter][opscenter] laptop?  Yup, this is part of it.  I'll give more details down below.\n\n## Let's talk about OpsCenter, agents, memory, disk speed, and mucho frustrationo \nThat's kind of a long list now that I see it all typed out, but there's a lot to consider.\n\nWe have nodes with `1GB of RAM`, a `32 bit` os, `4 cores`, and a `32GB microSD` drive acting as a hard disk.  This is way below the recommended values of `16-32GB of RAM`, `500GB-1TB` of fast disk, and `64bit` with `8 cores` for running Cassandra nodes, or really any database for that matter.  I wasn't really sure how well this would work, if at all, given memory contraints alone not to mention the speed of microSD's for a database that is known to need very fast disk.\n\n### OpsCenter\nI decided right off the bat I wanted OpsCenter in the mix.  Part of this whole project was to learn and what better way than to go whole hog and see what it could do.  If you use OpsCenter you must install [DataStax agents][agent] on each of your nodes in order for magic to happen.  That magic comes at a memory cost, not a huge one, but one that matters when only dealing with `1GB of RAM`.  In order to leave enough room for the Cassandra node itself to run I effectively cut this requirement in half.  So far, after months of running, I have not seen an issue running agents at `64MB of RAM`.\n{% asset_img opscenter_cluster.png \"Laptop + PI Mixed-Workload Cluster\" %}\n\n### Cassandra memory\nThe default auto caluclated memory configuration for DSE managed Cassandra nodes works well enough even on the PI's, but there's a catch.  Remember those agents we need for [OpsCenter][opscenter]?  Well, turns out the agents need just enough extra memory to push things over the edge and on a system with no swap file this means **page fault** which is exactly what happened.  I tried to quash every little process I could to free up enough RAM for my nodes to remain stable and I even made them headless, but to remain stable I had to explicitly configure the HEAP settings for my Cassandra nodes.  The end result is listed up above.\n\n### Headless\nSo, before I went headless things were working...uhh...well enough.  Not well enough that I could leave it alone really and any time the system was put under stress **!BAM!** I would lose a node.  This ended up being **the clincher**.  I noticed the Raspbian UI itself was eating up just enough RAM to prevent my nodes from allocating more in times of need.  I chopped off their heads and since then along with the other changes I made my nodes have been rock solid on the memory front.\n\n### Memory is good how about disk?\nWe already talked about the swap file.  Not only is it [strongly recommended][swap] to disable swap on nodes running Cassandra, but even more so on PI's running on microSD's.  Before I did so it was clear my nodes were struggling as even small tasks kept driving load up and upon some inspection it was obvious I/O was mostly to blame.  However, something else was lurking even after I disabled swap.  At times I would see my nodes shoot up from a load of `<1 upwards to 10+`.  At this point they would usually become unresponsive and either crash or eventually come back to reality, but always, always under heavy load.\n\n### Colllleccccctionnnnnn Daaaaatttttaaaaa\nSorry, couldn't help myself.  As stated above move collection data storage off the PI's onto a [separate cluster][storecollection].  They simply cannot handle all of the I/O associated with collecting, storing, and repairing the collection data from the rollup\\* tables.  Compaction was happening way too fast for the nodes to keep up most likely a result of having very little memory to work with, the PI's could not keep up with the amount of collection data itself, and read repair on the rollup\\* tables was a constant, never ending stream of repair.  Once I made the switch my PI nodes all quieted down to a normal `load around 1`, things have stabilized, and   I no longer have gaps in my analytics data (except for when I **HULK SMASH** nodes myself for fun).\n\n## Finally, the mixed workload part\nYup, right there in the title and all and I haven't really mentioned it.  Part of the reason I went and did all of this aside from learning and seeing what could be done was to extend [Luke Tillman's **\\*cough\\*....shame...less..plug \\*cooouugh\\***][luke] freaking awesome [KillrVideo][killrvideo] reference app to hook up to clusters outside of its [Dockerized][docker] container.  This forced me to extend my existing Cassandra cluster into a mixed workload scenario with [DSE Search][dsesearch].  Right, I could have simply put search within the same cluster, but I was looking to emulate what I would do in a production scenario.  I have an upcoming post on this very topic coming here in the future.  I also had need to extend into [DSE graph][dsegraph] as well for some of my own projects so I took the opportunity to go ahead and just do it all.  The end result is a fully functional Cassandra/Search/Graph DSE managed mixed workload cluster being served up mostly on Raspberry PI's with a little help from a laptop all hooked up to [KillrVideo][killrvideo].\n\nOne last thing before I go.  I find that tailing the agent.log, opscenterd.log, and system.log files from all of the nodes is quite insightful especially when watching the interaction between the nodes when performing regular CQL, search, and graph queries.  I'm also the type of person who can watch a defrag for hours and find every little box color change useful information.  \n\nNot sure what that says about me.  \n\n\n[raspberrypi]: https://www.raspberrypi.org/ \n[model3]: https://www.raspberrypi.org/products/raspberry-pi-3-model-b/ \n[opscenter]: http://docs.datastax.com/en/latest-opscenter/opsc/about_c.html\n[opscentertarball]: https://docs.datastax.com/en/latest-opscenter/opsc/install/opscInstallTar_t.html\n[agent]: http://docs.datastax.com/en/latest-opscenter/opsc/install/installDSagents.html\n[agenttarball]: http://docs.datastax.com/en/latest-opscenter/opsc/install/opsc-agentInstallManual_t.html\n[dse]: http://docs.datastax.com/en/latest-dse/\n[dsetarball]: http://docs.datastax.com/en/latest-dse/datastax_enterprise/install/installTARdse.html\n[dsesearch]: http://docs.datastax.com/en/datastax_enterprise/5.0/datastax_enterprise/srch/searchOverview.html\n[dsegraph]: http://www.datastax.com/products/datastax-enterprise-graph\n[noobs]: https://www.raspberrypi.org/downloads/noobs/\n[rav]: https://www.ravpower.com/6-port-usb-wall-charger-black-.html\n[recommendedsettings]: https://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettingsLinux.html\n[swap]: https://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettingsLinux.html#recommendedSettingsLinux__disable-swap\n[disableswap]: http://ideaheap.com/2013/07/stopping-sd-card-corruption-on-a-raspberry-pi/\n[storecollection]: https://docs.datastax.com/en/opscenter/6.0/opsc/configure/opscStoringCollectionDataDifferentCluster_t.html\n[killrvideo]: https://killrvideo.github.io/\n[luke]: http://www.luketillman.com/\n[docker]: https://www.docker.com/","source":"_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s.md","raw":"---\ntitle: Mixed Workload DSE Cluster with Raspberry PI's\ndate: 2017-02-07 13:52:11\ncategories:\n    - Technical\ntags:\n    - raspberry PI\n    - cluster\n    - killrvideo\n---\nAlrighty, as I mentioned in my previous [post](/2017/02/07/I-m-Sure-You-Weren-t-Looking) I have a mixed-workload cluster (Cassandra, DSE search, DSE graph) using a combination of 4 Raspberry PI's and my laptop.  I had multiple things in mind when I started into this.\n\n1. Low cost for learning\n\n1. Something I can break and not cry about\n\n1. How low can one really go when setting up a cluster?\n\n1. Get some DSE OpsCenter knowledge\n\n1. These are Raspberry PI's, they are just damn cool, so why not setup a cluster?!\n\n<!-- more -->\n\n## PIE?  Raspberries? 3.14? PI?\n{% raw %}\n<div class=\"responsive-container\" style=\"height:160px\">\n    <div class=\"dummy\"></div>\n    <div class=\"img-container\">\n        <div class=\"centerer\"></div>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/pie-pi.jpg\" title=\"pie\" width=\"25%\" height=\"auto\">\n          <span><strong>+</strong></span>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberry.jpg\" title=\"raspberries\" width=\"25%\" height=\"auto\">\n          <span><strong>=</strong></span>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberrypi.jpg\" title=\"raspberrypi\" width=\"25%\" height=\"auto\">\n    </div>\n</div>\n{% endraw %}\n\nIf you are not already familiar with RaspberryPI's [go take a look][raspberrypi].  These are cool little machines for very little cost.\n\n[Here are the specs for the model 3][model3], but just to summarize each node in our cluster only has 1GB of RAM and a 1.2GHz quad-core processor.  This is clearly not a setup to use in your production environment.  This is, however, a great way to learn and experiment.\n\n\n## The setup\n4 [RaspberryPI's][raspberrypi] (wired ethernet)\nNOTE:  These are designed to be \"built up\" so you will need to purchase microSD cards and the outer shells separately\n\nOne `2.6GHz 8 core` MacBook with `16GB RAM` (wired ethernet)\n\n[DataStax Enterprise Opscenter 6.0.7][opscenter] using [tarball installation][opscentertarball]\n\n[DataStax Agent 6.0.7][agent] using [tarball installation][agenttarball]\n\n[DataStax Enterprise 5.0.5][dse], again, using the [tarball installation][dsetarball]\n\n[RAVPower 6 port USB charger][rav] with a set of USB `Male A` to `Micro B` cables.  I also purchased a `4x1 HDMI` switch, but you can easily run these headless if you know your way around a Linux shell.\n\nJust a quick note about the tarball installations.  DSE generally supports using installers across most major platforms and for each of the various installs, but since we are using RaspberryPI's in this case and since I used the [NOOBS][noobs] install to get up and going as fast as I could it just so happens that combination **only works with tarball installs**.  Please, learn from me and don't spend the many, many hours I did eventually figuring this out.   \n\nYou can, in fact, install other operating systems on RaspberryPI's which may allow the installers to work, but you'll have to come back and tell me about it if you give it a go.\n\nAaaaaaand for the reveal dun dunn dunnnnnnnnn! (Yes, those are shiny, lighted cables)\n{% asset_img myPIs.gif \"My Raspberry PI Cluster\" %}\n\n## I may have cheated just a little bit\nSo, I mentioned above \"mixed workload cluster with Raspberry PI's\".  This is 100% true, but also notice there is a laptop in the mix.  I ended up using the laptop to house OpsCenter and my search/graph datacenter and I'm using the PI's for my core Cassandra cluster.  In my experience I don't usually install operations tools and the like directly on production devices facing the public because they have a tendency to cause unpredicatable load.  The limited RAM on the PI's (1GB) is also a factor which I will address here in a moment.  As far as the search/graph datacenter portion I simply used the laptop out of convienence because I already had a 4-node core Cassandra cluster running on the PI's at the time and I wanted to observe the interaction between my search/graph and Cassandra datacenters in a \"pure\" fashion.\n\n## Get this working on PI's\nRaspberry PI's are special snowflakes when it comes to making this all work.  I will detail all this below, but here, for you, is the summarized list of what is needed.\n\n1. [Disable swap][swap]\n`sudo swapoff -a` is your friend.  It is also the quick and dirty way, not permanent on reboot.  Take a look at the \"Disable swapping\" section of [this post][disableswap] if you would like a more permanent solution.\n\n1. Go Headless\nThis is quite easy to do using `sudo raspi-config` while ssh'd into your PI and it will help free up enough memory to make things stable.  Just make sure you already know your PI's IP address or know how to find it if things go sour.\n\n1. Decrease RAM allocated to datastax-agent from `128MB to 64MB` \nEdit `datastax-agent-env.sh` located in [your datastax-agent install dir]/conf/datastax-agent-env.sh\n```bash\nFrom:\nJVM_OPTS=\"$JVM_OPTS -Xmx128M -Djclouds.mpu.parts.magnitude=100000 -Djclouds.mpu.parts.size=16777216\"\n\nTo:\nJVM_OPTS=\"$JVM_OPTS -Xmx64M -Djclouds.mpu.parts.magnitude=100000 -Djclouds.mpu.parts.size=16777216\"\n```\n\n1. Explicitly set Java HEAP settings for Cassandra node\nEdit `cassandra-env.sh` located in [your DSE install dir]/resources/cassandra/conf/cassandra-env.sh.  Search for \"HEAP\" to find and edit the lines.  Notice mine are already set to the working values.  These are commented out by default which will allow the script to calculate values for you, but for our PI case we cannot use the calculated values.\n```bash\nMAX_HEAP_SIZE=\"200M\"\nHEAP_NEWSIZE=\"50M\"\n```\n\n1. [Store collection data on a separate cluster][storecollection]\nRemember that part about \"cheating\" with my [OpsCenter][opscenter] laptop?  Yup, this is part of it.  I'll give more details down below.\n\n## Let's talk about OpsCenter, agents, memory, disk speed, and mucho frustrationo \nThat's kind of a long list now that I see it all typed out, but there's a lot to consider.\n\nWe have nodes with `1GB of RAM`, a `32 bit` os, `4 cores`, and a `32GB microSD` drive acting as a hard disk.  This is way below the recommended values of `16-32GB of RAM`, `500GB-1TB` of fast disk, and `64bit` with `8 cores` for running Cassandra nodes, or really any database for that matter.  I wasn't really sure how well this would work, if at all, given memory contraints alone not to mention the speed of microSD's for a database that is known to need very fast disk.\n\n### OpsCenter\nI decided right off the bat I wanted OpsCenter in the mix.  Part of this whole project was to learn and what better way than to go whole hog and see what it could do.  If you use OpsCenter you must install [DataStax agents][agent] on each of your nodes in order for magic to happen.  That magic comes at a memory cost, not a huge one, but one that matters when only dealing with `1GB of RAM`.  In order to leave enough room for the Cassandra node itself to run I effectively cut this requirement in half.  So far, after months of running, I have not seen an issue running agents at `64MB of RAM`.\n{% asset_img opscenter_cluster.png \"Laptop + PI Mixed-Workload Cluster\" %}\n\n### Cassandra memory\nThe default auto caluclated memory configuration for DSE managed Cassandra nodes works well enough even on the PI's, but there's a catch.  Remember those agents we need for [OpsCenter][opscenter]?  Well, turns out the agents need just enough extra memory to push things over the edge and on a system with no swap file this means **page fault** which is exactly what happened.  I tried to quash every little process I could to free up enough RAM for my nodes to remain stable and I even made them headless, but to remain stable I had to explicitly configure the HEAP settings for my Cassandra nodes.  The end result is listed up above.\n\n### Headless\nSo, before I went headless things were working...uhh...well enough.  Not well enough that I could leave it alone really and any time the system was put under stress **!BAM!** I would lose a node.  This ended up being **the clincher**.  I noticed the Raspbian UI itself was eating up just enough RAM to prevent my nodes from allocating more in times of need.  I chopped off their heads and since then along with the other changes I made my nodes have been rock solid on the memory front.\n\n### Memory is good how about disk?\nWe already talked about the swap file.  Not only is it [strongly recommended][swap] to disable swap on nodes running Cassandra, but even more so on PI's running on microSD's.  Before I did so it was clear my nodes were struggling as even small tasks kept driving load up and upon some inspection it was obvious I/O was mostly to blame.  However, something else was lurking even after I disabled swap.  At times I would see my nodes shoot up from a load of `<1 upwards to 10+`.  At this point they would usually become unresponsive and either crash or eventually come back to reality, but always, always under heavy load.\n\n### Colllleccccctionnnnnn Daaaaatttttaaaaa\nSorry, couldn't help myself.  As stated above move collection data storage off the PI's onto a [separate cluster][storecollection].  They simply cannot handle all of the I/O associated with collecting, storing, and repairing the collection data from the rollup\\* tables.  Compaction was happening way too fast for the nodes to keep up most likely a result of having very little memory to work with, the PI's could not keep up with the amount of collection data itself, and read repair on the rollup\\* tables was a constant, never ending stream of repair.  Once I made the switch my PI nodes all quieted down to a normal `load around 1`, things have stabilized, and   I no longer have gaps in my analytics data (except for when I **HULK SMASH** nodes myself for fun).\n\n## Finally, the mixed workload part\nYup, right there in the title and all and I haven't really mentioned it.  Part of the reason I went and did all of this aside from learning and seeing what could be done was to extend [Luke Tillman's **\\*cough\\*....shame...less..plug \\*cooouugh\\***][luke] freaking awesome [KillrVideo][killrvideo] reference app to hook up to clusters outside of its [Dockerized][docker] container.  This forced me to extend my existing Cassandra cluster into a mixed workload scenario with [DSE Search][dsesearch].  Right, I could have simply put search within the same cluster, but I was looking to emulate what I would do in a production scenario.  I have an upcoming post on this very topic coming here in the future.  I also had need to extend into [DSE graph][dsegraph] as well for some of my own projects so I took the opportunity to go ahead and just do it all.  The end result is a fully functional Cassandra/Search/Graph DSE managed mixed workload cluster being served up mostly on Raspberry PI's with a little help from a laptop all hooked up to [KillrVideo][killrvideo].\n\nOne last thing before I go.  I find that tailing the agent.log, opscenterd.log, and system.log files from all of the nodes is quite insightful especially when watching the interaction between the nodes when performing regular CQL, search, and graph queries.  I'm also the type of person who can watch a defrag for hours and find every little box color change useful information.  \n\nNot sure what that says about me.  \n\n\n[raspberrypi]: https://www.raspberrypi.org/ \n[model3]: https://www.raspberrypi.org/products/raspberry-pi-3-model-b/ \n[opscenter]: http://docs.datastax.com/en/latest-opscenter/opsc/about_c.html\n[opscentertarball]: https://docs.datastax.com/en/latest-opscenter/opsc/install/opscInstallTar_t.html\n[agent]: http://docs.datastax.com/en/latest-opscenter/opsc/install/installDSagents.html\n[agenttarball]: http://docs.datastax.com/en/latest-opscenter/opsc/install/opsc-agentInstallManual_t.html\n[dse]: http://docs.datastax.com/en/latest-dse/\n[dsetarball]: http://docs.datastax.com/en/latest-dse/datastax_enterprise/install/installTARdse.html\n[dsesearch]: http://docs.datastax.com/en/datastax_enterprise/5.0/datastax_enterprise/srch/searchOverview.html\n[dsegraph]: http://www.datastax.com/products/datastax-enterprise-graph\n[noobs]: https://www.raspberrypi.org/downloads/noobs/\n[rav]: https://www.ravpower.com/6-port-usb-wall-charger-black-.html\n[recommendedsettings]: https://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettingsLinux.html\n[swap]: https://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettingsLinux.html#recommendedSettingsLinux__disable-swap\n[disableswap]: http://ideaheap.com/2013/07/stopping-sd-card-corruption-on-a-raspberry-pi/\n[storecollection]: https://docs.datastax.com/en/opscenter/6.0/opsc/configure/opscStoringCollectionDataDifferentCluster_t.html\n[killrvideo]: https://killrvideo.github.io/\n[luke]: http://www.luketillman.com/\n[docker]: https://www.docker.com/","slug":"Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s","published":1,"updated":"2017-02-10T21:04:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjdkqmjee0006nhkmfmlpf7j5","content":"<p>Alrighty, as I mentioned in my previous <a href=\"/2017/02/07/I-m-Sure-You-Weren-t-Looking\">post</a> I have a mixed-workload cluster (Cassandra, DSE search, DSE graph) using a combination of 4 Raspberry PI’s and my laptop.  I had multiple things in mind when I started into this.</p>\n<ol>\n<li><p>Low cost for learning</p>\n</li>\n<li><p>Something I can break and not cry about</p>\n</li>\n<li><p>How low can one really go when setting up a cluster?</p>\n</li>\n<li><p>Get some DSE OpsCenter knowledge</p>\n</li>\n<li><p>These are Raspberry PI’s, they are just damn cool, so why not setup a cluster?!</p>\n</li>\n</ol>\n<a id=\"more\"></a>\n<h2 id=\"PIE-Raspberries-3-14-PI\"><a href=\"#PIE-Raspberries-3-14-PI\" class=\"headerlink\" title=\"PIE?  Raspberries? 3.14? PI?\"></a>PIE?  Raspberries? 3.14? PI?</h2>\n<div class=\"responsive-container\" style=\"height:160px\">\n    <div class=\"dummy\"></div>\n    <div class=\"img-container\">\n        <div class=\"centerer\"></div>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/pie-pi.jpg\" title=\"pie\" width=\"25%\" height=\"auto\">\n          <span><strong>+</strong></span>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberry.jpg\" title=\"raspberries\" width=\"25%\" height=\"auto\">\n          <span><strong>=</strong></span>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberrypi.jpg\" title=\"raspberrypi\" width=\"25%\" height=\"auto\">\n    </div>\n</div>\n\n<p>If you are not already familiar with RaspberryPI’s <a href=\"https://www.raspberrypi.org/\" target=\"_blank\" rel=\"external\">go take a look</a>.  These are cool little machines for very little cost.</p>\n<p><a href=\"https://www.raspberrypi.org/products/raspberry-pi-3-model-b/\" target=\"_blank\" rel=\"external\">Here are the specs for the model 3</a>, but just to summarize each node in our cluster only has 1GB of RAM and a 1.2GHz quad-core processor.  This is clearly not a setup to use in your production environment.  This is, however, a great way to learn and experiment.</p>\n<h2 id=\"The-setup\"><a href=\"#The-setup\" class=\"headerlink\" title=\"The setup\"></a>The setup</h2><p>4 <a href=\"https://www.raspberrypi.org/\" target=\"_blank\" rel=\"external\">RaspberryPI’s</a> (wired ethernet)<br>NOTE:  These are designed to be “built up” so you will need to purchase microSD cards and the outer shells separately</p>\n<p>One <code>2.6GHz 8 core</code> MacBook with <code>16GB RAM</code> (wired ethernet)</p>\n<p><a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/about_c.html\" target=\"_blank\" rel=\"external\">DataStax Enterprise Opscenter 6.0.7</a> using <a href=\"https://docs.datastax.com/en/latest-opscenter/opsc/install/opscInstallTar_t.html\" target=\"_blank\" rel=\"external\">tarball installation</a></p>\n<p><a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/install/installDSagents.html\" target=\"_blank\" rel=\"external\">DataStax Agent 6.0.7</a> using <a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/install/opsc-agentInstallManual_t.html\" target=\"_blank\" rel=\"external\">tarball installation</a></p>\n<p><a href=\"http://docs.datastax.com/en/latest-dse/\" target=\"_blank\" rel=\"external\">DataStax Enterprise 5.0.5</a>, again, using the <a href=\"http://docs.datastax.com/en/latest-dse/datastax_enterprise/install/installTARdse.html\" target=\"_blank\" rel=\"external\">tarball installation</a></p>\n<p><a href=\"https://www.ravpower.com/6-port-usb-wall-charger-black-.html\" target=\"_blank\" rel=\"external\">RAVPower 6 port USB charger</a> with a set of USB <code>Male A</code> to <code>Micro B</code> cables.  I also purchased a <code>4x1 HDMI</code> switch, but you can easily run these headless if you know your way around a Linux shell.</p>\n<p>Just a quick note about the tarball installations.  DSE generally supports using installers across most major platforms and for each of the various installs, but since we are using RaspberryPI’s in this case and since I used the <a href=\"https://www.raspberrypi.org/downloads/noobs/\" target=\"_blank\" rel=\"external\">NOOBS</a> install to get up and going as fast as I could it just so happens that combination <strong>only works with tarball installs</strong>.  Please, learn from me and don’t spend the many, many hours I did eventually figuring this out.   </p>\n<p>You can, in fact, install other operating systems on RaspberryPI’s which may allow the installers to work, but you’ll have to come back and tell me about it if you give it a go.</p>\n<p>Aaaaaaand for the reveal dun dunn dunnnnnnnnn! (Yes, those are shiny, lighted cables)<br><img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/myPIs.gif\" alt=\"My Raspberry PI Cluster\" title=\"My Raspberry PI Cluster\"></p>\n<h2 id=\"I-may-have-cheated-just-a-little-bit\"><a href=\"#I-may-have-cheated-just-a-little-bit\" class=\"headerlink\" title=\"I may have cheated just a little bit\"></a>I may have cheated just a little bit</h2><p>So, I mentioned above “mixed workload cluster with Raspberry PI’s”.  This is 100% true, but also notice there is a laptop in the mix.  I ended up using the laptop to house OpsCenter and my search/graph datacenter and I’m using the PI’s for my core Cassandra cluster.  In my experience I don’t usually install operations tools and the like directly on production devices facing the public because they have a tendency to cause unpredicatable load.  The limited RAM on the PI’s (1GB) is also a factor which I will address here in a moment.  As far as the search/graph datacenter portion I simply used the laptop out of convienence because I already had a 4-node core Cassandra cluster running on the PI’s at the time and I wanted to observe the interaction between my search/graph and Cassandra datacenters in a “pure” fashion.</p>\n<h2 id=\"Get-this-working-on-PI’s\"><a href=\"#Get-this-working-on-PI’s\" class=\"headerlink\" title=\"Get this working on PI’s\"></a>Get this working on PI’s</h2><p>Raspberry PI’s are special snowflakes when it comes to making this all work.  I will detail all this below, but here, for you, is the summarized list of what is needed.</p>\n<ol>\n<li><p><a href=\"https://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettingsLinux.html#recommendedSettingsLinux__disable-swap\" target=\"_blank\" rel=\"external\">Disable swap</a><br><code>sudo swapoff -a</code> is your friend.  It is also the quick and dirty way, not permanent on reboot.  Take a look at the “Disable swapping” section of <a href=\"http://ideaheap.com/2013/07/stopping-sd-card-corruption-on-a-raspberry-pi/\" target=\"_blank\" rel=\"external\">this post</a> if you would like a more permanent solution.</p>\n</li>\n<li><p>Go Headless<br>This is quite easy to do using <code>sudo raspi-config</code> while ssh’d into your PI and it will help free up enough memory to make things stable.  Just make sure you already know your PI’s IP address or know how to find it if things go sour.</p>\n</li>\n<li><p>Decrease RAM allocated to datastax-agent from <code>128MB to 64MB</code><br>Edit <code>datastax-agent-env.sh</code> located in [your datastax-agent install dir]/conf/datastax-agent-env.sh</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">From:</div><div class=\"line\">JVM_OPTS=<span class=\"string\">\"<span class=\"variable\">$JVM_OPTS</span> -Xmx128M -Djclouds.mpu.parts.magnitude=100000 -Djclouds.mpu.parts.size=16777216\"</span></div><div class=\"line\"></div><div class=\"line\">To:</div><div class=\"line\">JVM_OPTS=<span class=\"string\">\"<span class=\"variable\">$JVM_OPTS</span> -Xmx64M -Djclouds.mpu.parts.magnitude=100000 -Djclouds.mpu.parts.size=16777216\"</span></div></pre></td></tr></table></figure>\n</li>\n<li><p>Explicitly set Java HEAP settings for Cassandra node<br>Edit <code>cassandra-env.sh</code> located in [your DSE install dir]/resources/cassandra/conf/cassandra-env.sh.  Search for “HEAP” to find and edit the lines.  Notice mine are already set to the working values.  These are commented out by default which will allow the script to calculate values for you, but for our PI case we cannot use the calculated values.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">MAX_HEAP_SIZE=<span class=\"string\">\"200M\"</span></div><div class=\"line\">HEAP_NEWSIZE=<span class=\"string\">\"50M\"</span></div></pre></td></tr></table></figure>\n</li>\n<li><p><a href=\"https://docs.datastax.com/en/opscenter/6.0/opsc/configure/opscStoringCollectionDataDifferentCluster_t.html\" target=\"_blank\" rel=\"external\">Store collection data on a separate cluster</a><br>Remember that part about “cheating” with my <a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/about_c.html\" target=\"_blank\" rel=\"external\">OpsCenter</a> laptop?  Yup, this is part of it.  I’ll give more details down below.</p>\n</li>\n</ol>\n<h2 id=\"Let’s-talk-about-OpsCenter-agents-memory-disk-speed-and-mucho-frustrationo\"><a href=\"#Let’s-talk-about-OpsCenter-agents-memory-disk-speed-and-mucho-frustrationo\" class=\"headerlink\" title=\"Let’s talk about OpsCenter, agents, memory, disk speed, and mucho frustrationo\"></a>Let’s talk about OpsCenter, agents, memory, disk speed, and mucho frustrationo</h2><p>That’s kind of a long list now that I see it all typed out, but there’s a lot to consider.</p>\n<p>We have nodes with <code>1GB of RAM</code>, a <code>32 bit</code> os, <code>4 cores</code>, and a <code>32GB microSD</code> drive acting as a hard disk.  This is way below the recommended values of <code>16-32GB of RAM</code>, <code>500GB-1TB</code> of fast disk, and <code>64bit</code> with <code>8 cores</code> for running Cassandra nodes, or really any database for that matter.  I wasn’t really sure how well this would work, if at all, given memory contraints alone not to mention the speed of microSD’s for a database that is known to need very fast disk.</p>\n<h3 id=\"OpsCenter\"><a href=\"#OpsCenter\" class=\"headerlink\" title=\"OpsCenter\"></a>OpsCenter</h3><p>I decided right off the bat I wanted OpsCenter in the mix.  Part of this whole project was to learn and what better way than to go whole hog and see what it could do.  If you use OpsCenter you must install <a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/install/installDSagents.html\" target=\"_blank\" rel=\"external\">DataStax agents</a> on each of your nodes in order for magic to happen.  That magic comes at a memory cost, not a huge one, but one that matters when only dealing with <code>1GB of RAM</code>.  In order to leave enough room for the Cassandra node itself to run I effectively cut this requirement in half.  So far, after months of running, I have not seen an issue running agents at <code>64MB of RAM</code>.<br><img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/opscenter_cluster.png\" alt=\"Laptop + PI Mixed-Workload Cluster\" title=\"Laptop + PI Mixed-Workload Cluster\"></p>\n<h3 id=\"Cassandra-memory\"><a href=\"#Cassandra-memory\" class=\"headerlink\" title=\"Cassandra memory\"></a>Cassandra memory</h3><p>The default auto caluclated memory configuration for DSE managed Cassandra nodes works well enough even on the PI’s, but there’s a catch.  Remember those agents we need for <a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/about_c.html\" target=\"_blank\" rel=\"external\">OpsCenter</a>?  Well, turns out the agents need just enough extra memory to push things over the edge and on a system with no swap file this means <strong>page fault</strong> which is exactly what happened.  I tried to quash every little process I could to free up enough RAM for my nodes to remain stable and I even made them headless, but to remain stable I had to explicitly configure the HEAP settings for my Cassandra nodes.  The end result is listed up above.</p>\n<h3 id=\"Headless\"><a href=\"#Headless\" class=\"headerlink\" title=\"Headless\"></a>Headless</h3><p>So, before I went headless things were working…uhh…well enough.  Not well enough that I could leave it alone really and any time the system was put under stress <strong>!BAM!</strong> I would lose a node.  This ended up being <strong>the clincher</strong>.  I noticed the Raspbian UI itself was eating up just enough RAM to prevent my nodes from allocating more in times of need.  I chopped off their heads and since then along with the other changes I made my nodes have been rock solid on the memory front.</p>\n<h3 id=\"Memory-is-good-how-about-disk\"><a href=\"#Memory-is-good-how-about-disk\" class=\"headerlink\" title=\"Memory is good how about disk?\"></a>Memory is good how about disk?</h3><p>We already talked about the swap file.  Not only is it <a href=\"https://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettingsLinux.html#recommendedSettingsLinux__disable-swap\" target=\"_blank\" rel=\"external\">strongly recommended</a> to disable swap on nodes running Cassandra, but even more so on PI’s running on microSD’s.  Before I did so it was clear my nodes were struggling as even small tasks kept driving load up and upon some inspection it was obvious I/O was mostly to blame.  However, something else was lurking even after I disabled swap.  At times I would see my nodes shoot up from a load of <code>&lt;1 upwards to 10+</code>.  At this point they would usually become unresponsive and either crash or eventually come back to reality, but always, always under heavy load.</p>\n<h3 id=\"Colllleccccctionnnnnn-Daaaaatttttaaaaa\"><a href=\"#Colllleccccctionnnnnn-Daaaaatttttaaaaa\" class=\"headerlink\" title=\"Colllleccccctionnnnnn Daaaaatttttaaaaa\"></a>Colllleccccctionnnnnn Daaaaatttttaaaaa</h3><p>Sorry, couldn’t help myself.  As stated above move collection data storage off the PI’s onto a <a href=\"https://docs.datastax.com/en/opscenter/6.0/opsc/configure/opscStoringCollectionDataDifferentCluster_t.html\" target=\"_blank\" rel=\"external\">separate cluster</a>.  They simply cannot handle all of the I/O associated with collecting, storing, and repairing the collection data from the rollup* tables.  Compaction was happening way too fast for the nodes to keep up most likely a result of having very little memory to work with, the PI’s could not keep up with the amount of collection data itself, and read repair on the rollup* tables was a constant, never ending stream of repair.  Once I made the switch my PI nodes all quieted down to a normal <code>load around 1</code>, things have stabilized, and   I no longer have gaps in my analytics data (except for when I <strong>HULK SMASH</strong> nodes myself for fun).</p>\n<h2 id=\"Finally-the-mixed-workload-part\"><a href=\"#Finally-the-mixed-workload-part\" class=\"headerlink\" title=\"Finally, the mixed workload part\"></a>Finally, the mixed workload part</h2><p>Yup, right there in the title and all and I haven’t really mentioned it.  Part of the reason I went and did all of this aside from learning and seeing what could be done was to extend <a href=\"http://www.luketillman.com/\" target=\"_blank\" rel=\"external\">Luke Tillman’s <strong>*cough*….shame…less..plug *cooouugh*</strong></a> freaking awesome <a href=\"https://killrvideo.github.io/\" target=\"_blank\" rel=\"external\">KillrVideo</a> reference app to hook up to clusters outside of its <a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"external\">Dockerized</a> container.  This forced me to extend my existing Cassandra cluster into a mixed workload scenario with <a href=\"http://docs.datastax.com/en/datastax_enterprise/5.0/datastax_enterprise/srch/searchOverview.html\" target=\"_blank\" rel=\"external\">DSE Search</a>.  Right, I could have simply put search within the same cluster, but I was looking to emulate what I would do in a production scenario.  I have an upcoming post on this very topic coming here in the future.  I also had need to extend into <a href=\"http://www.datastax.com/products/datastax-enterprise-graph\" target=\"_blank\" rel=\"external\">DSE graph</a> as well for some of my own projects so I took the opportunity to go ahead and just do it all.  The end result is a fully functional Cassandra/Search/Graph DSE managed mixed workload cluster being served up mostly on Raspberry PI’s with a little help from a laptop all hooked up to <a href=\"https://killrvideo.github.io/\" target=\"_blank\" rel=\"external\">KillrVideo</a>.</p>\n<p>One last thing before I go.  I find that tailing the agent.log, opscenterd.log, and system.log files from all of the nodes is quite insightful especially when watching the interaction between the nodes when performing regular CQL, search, and graph queries.  I’m also the type of person who can watch a defrag for hours and find every little box color change useful information.  </p>\n<p>Not sure what that says about me.  </p>\n","excerpt":"<p>Alrighty, as I mentioned in my previous <a href=\"/2017/02/07/I-m-Sure-You-Weren-t-Looking\">post</a> I have a mixed-workload cluster (Cassandra, DSE search, DSE graph) using a combination of 4 Raspberry PI’s and my laptop.  I had multiple things in mind when I started into this.</p>\n<ol>\n<li><p>Low cost for learning</p>\n</li>\n<li><p>Something I can break and not cry about</p>\n</li>\n<li><p>How low can one really go when setting up a cluster?</p>\n</li>\n<li><p>Get some DSE OpsCenter knowledge</p>\n</li>\n<li><p>These are Raspberry PI’s, they are just damn cool, so why not setup a cluster?!</p>\n</li>\n</ol>","more":"<h2 id=\"PIE-Raspberries-3-14-PI\"><a href=\"#PIE-Raspberries-3-14-PI\" class=\"headerlink\" title=\"PIE?  Raspberries? 3.14? PI?\"></a>PIE?  Raspberries? 3.14? PI?</h2>\n<div class=\"responsive-container\" style=\"height:160px\">\n    <div class=\"dummy\"></div>\n    <div class=\"img-container\">\n        <div class=\"centerer\"></div>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/pie-pi.jpg\" title=\"pie\" width=\"25%\" height=\"auto\">\n          <span><strong>+</strong></span>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberry.jpg\" title=\"raspberries\" width=\"25%\" height=\"auto\">\n          <span><strong>=</strong></span>\n          <img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberrypi.jpg\" title=\"raspberrypi\" width=\"25%\" height=\"auto\">\n    </div>\n</div>\n\n<p>If you are not already familiar with RaspberryPI’s <a href=\"https://www.raspberrypi.org/\">go take a look</a>.  These are cool little machines for very little cost.</p>\n<p><a href=\"https://www.raspberrypi.org/products/raspberry-pi-3-model-b/\">Here are the specs for the model 3</a>, but just to summarize each node in our cluster only has 1GB of RAM and a 1.2GHz quad-core processor.  This is clearly not a setup to use in your production environment.  This is, however, a great way to learn and experiment.</p>\n<h2 id=\"The-setup\"><a href=\"#The-setup\" class=\"headerlink\" title=\"The setup\"></a>The setup</h2><p>4 <a href=\"https://www.raspberrypi.org/\">RaspberryPI’s</a> (wired ethernet)<br>NOTE:  These are designed to be “built up” so you will need to purchase microSD cards and the outer shells separately</p>\n<p>One <code>2.6GHz 8 core</code> MacBook with <code>16GB RAM</code> (wired ethernet)</p>\n<p><a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/about_c.html\">DataStax Enterprise Opscenter 6.0.7</a> using <a href=\"https://docs.datastax.com/en/latest-opscenter/opsc/install/opscInstallTar_t.html\">tarball installation</a></p>\n<p><a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/install/installDSagents.html\">DataStax Agent 6.0.7</a> using <a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/install/opsc-agentInstallManual_t.html\">tarball installation</a></p>\n<p><a href=\"http://docs.datastax.com/en/latest-dse/\">DataStax Enterprise 5.0.5</a>, again, using the <a href=\"http://docs.datastax.com/en/latest-dse/datastax_enterprise/install/installTARdse.html\">tarball installation</a></p>\n<p><a href=\"https://www.ravpower.com/6-port-usb-wall-charger-black-.html\">RAVPower 6 port USB charger</a> with a set of USB <code>Male A</code> to <code>Micro B</code> cables.  I also purchased a <code>4x1 HDMI</code> switch, but you can easily run these headless if you know your way around a Linux shell.</p>\n<p>Just a quick note about the tarball installations.  DSE generally supports using installers across most major platforms and for each of the various installs, but since we are using RaspberryPI’s in this case and since I used the <a href=\"https://www.raspberrypi.org/downloads/noobs/\">NOOBS</a> install to get up and going as fast as I could it just so happens that combination <strong>only works with tarball installs</strong>.  Please, learn from me and don’t spend the many, many hours I did eventually figuring this out.   </p>\n<p>You can, in fact, install other operating systems on RaspberryPI’s which may allow the installers to work, but you’ll have to come back and tell me about it if you give it a go.</p>\n<p>Aaaaaaand for the reveal dun dunn dunnnnnnnnn! (Yes, those are shiny, lighted cables)<br><img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/myPIs.gif\" alt=\"My Raspberry PI Cluster\" title=\"My Raspberry PI Cluster\"></p>\n<h2 id=\"I-may-have-cheated-just-a-little-bit\"><a href=\"#I-may-have-cheated-just-a-little-bit\" class=\"headerlink\" title=\"I may have cheated just a little bit\"></a>I may have cheated just a little bit</h2><p>So, I mentioned above “mixed workload cluster with Raspberry PI’s”.  This is 100% true, but also notice there is a laptop in the mix.  I ended up using the laptop to house OpsCenter and my search/graph datacenter and I’m using the PI’s for my core Cassandra cluster.  In my experience I don’t usually install operations tools and the like directly on production devices facing the public because they have a tendency to cause unpredicatable load.  The limited RAM on the PI’s (1GB) is also a factor which I will address here in a moment.  As far as the search/graph datacenter portion I simply used the laptop out of convienence because I already had a 4-node core Cassandra cluster running on the PI’s at the time and I wanted to observe the interaction between my search/graph and Cassandra datacenters in a “pure” fashion.</p>\n<h2 id=\"Get-this-working-on-PI’s\"><a href=\"#Get-this-working-on-PI’s\" class=\"headerlink\" title=\"Get this working on PI’s\"></a>Get this working on PI’s</h2><p>Raspberry PI’s are special snowflakes when it comes to making this all work.  I will detail all this below, but here, for you, is the summarized list of what is needed.</p>\n<ol>\n<li><p><a href=\"https://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettingsLinux.html#recommendedSettingsLinux__disable-swap\">Disable swap</a><br><code>sudo swapoff -a</code> is your friend.  It is also the quick and dirty way, not permanent on reboot.  Take a look at the “Disable swapping” section of <a href=\"http://ideaheap.com/2013/07/stopping-sd-card-corruption-on-a-raspberry-pi/\">this post</a> if you would like a more permanent solution.</p>\n</li>\n<li><p>Go Headless<br>This is quite easy to do using <code>sudo raspi-config</code> while ssh’d into your PI and it will help free up enough memory to make things stable.  Just make sure you already know your PI’s IP address or know how to find it if things go sour.</p>\n</li>\n<li><p>Decrease RAM allocated to datastax-agent from <code>128MB to 64MB</code><br>Edit <code>datastax-agent-env.sh</code> located in [your datastax-agent install dir]/conf/datastax-agent-env.sh</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">From:</div><div class=\"line\">JVM_OPTS=<span class=\"string\">\"<span class=\"variable\">$JVM_OPTS</span> -Xmx128M -Djclouds.mpu.parts.magnitude=100000 -Djclouds.mpu.parts.size=16777216\"</span></div><div class=\"line\"></div><div class=\"line\">To:</div><div class=\"line\">JVM_OPTS=<span class=\"string\">\"<span class=\"variable\">$JVM_OPTS</span> -Xmx64M -Djclouds.mpu.parts.magnitude=100000 -Djclouds.mpu.parts.size=16777216\"</span></div></pre></td></tr></table></figure>\n</li>\n<li><p>Explicitly set Java HEAP settings for Cassandra node<br>Edit <code>cassandra-env.sh</code> located in [your DSE install dir]/resources/cassandra/conf/cassandra-env.sh.  Search for “HEAP” to find and edit the lines.  Notice mine are already set to the working values.  These are commented out by default which will allow the script to calculate values for you, but for our PI case we cannot use the calculated values.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">MAX_HEAP_SIZE=<span class=\"string\">\"200M\"</span></div><div class=\"line\">HEAP_NEWSIZE=<span class=\"string\">\"50M\"</span></div></pre></td></tr></table></figure>\n</li>\n<li><p><a href=\"https://docs.datastax.com/en/opscenter/6.0/opsc/configure/opscStoringCollectionDataDifferentCluster_t.html\">Store collection data on a separate cluster</a><br>Remember that part about “cheating” with my <a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/about_c.html\">OpsCenter</a> laptop?  Yup, this is part of it.  I’ll give more details down below.</p>\n</li>\n</ol>\n<h2 id=\"Let’s-talk-about-OpsCenter-agents-memory-disk-speed-and-mucho-frustrationo\"><a href=\"#Let’s-talk-about-OpsCenter-agents-memory-disk-speed-and-mucho-frustrationo\" class=\"headerlink\" title=\"Let’s talk about OpsCenter, agents, memory, disk speed, and mucho frustrationo\"></a>Let’s talk about OpsCenter, agents, memory, disk speed, and mucho frustrationo</h2><p>That’s kind of a long list now that I see it all typed out, but there’s a lot to consider.</p>\n<p>We have nodes with <code>1GB of RAM</code>, a <code>32 bit</code> os, <code>4 cores</code>, and a <code>32GB microSD</code> drive acting as a hard disk.  This is way below the recommended values of <code>16-32GB of RAM</code>, <code>500GB-1TB</code> of fast disk, and <code>64bit</code> with <code>8 cores</code> for running Cassandra nodes, or really any database for that matter.  I wasn’t really sure how well this would work, if at all, given memory contraints alone not to mention the speed of microSD’s for a database that is known to need very fast disk.</p>\n<h3 id=\"OpsCenter\"><a href=\"#OpsCenter\" class=\"headerlink\" title=\"OpsCenter\"></a>OpsCenter</h3><p>I decided right off the bat I wanted OpsCenter in the mix.  Part of this whole project was to learn and what better way than to go whole hog and see what it could do.  If you use OpsCenter you must install <a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/install/installDSagents.html\">DataStax agents</a> on each of your nodes in order for magic to happen.  That magic comes at a memory cost, not a huge one, but one that matters when only dealing with <code>1GB of RAM</code>.  In order to leave enough room for the Cassandra node itself to run I effectively cut this requirement in half.  So far, after months of running, I have not seen an issue running agents at <code>64MB of RAM</code>.<br><img src=\"/2017/02/07/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/opscenter_cluster.png\" alt=\"Laptop + PI Mixed-Workload Cluster\" title=\"Laptop + PI Mixed-Workload Cluster\"></p>\n<h3 id=\"Cassandra-memory\"><a href=\"#Cassandra-memory\" class=\"headerlink\" title=\"Cassandra memory\"></a>Cassandra memory</h3><p>The default auto caluclated memory configuration for DSE managed Cassandra nodes works well enough even on the PI’s, but there’s a catch.  Remember those agents we need for <a href=\"http://docs.datastax.com/en/latest-opscenter/opsc/about_c.html\">OpsCenter</a>?  Well, turns out the agents need just enough extra memory to push things over the edge and on a system with no swap file this means <strong>page fault</strong> which is exactly what happened.  I tried to quash every little process I could to free up enough RAM for my nodes to remain stable and I even made them headless, but to remain stable I had to explicitly configure the HEAP settings for my Cassandra nodes.  The end result is listed up above.</p>\n<h3 id=\"Headless\"><a href=\"#Headless\" class=\"headerlink\" title=\"Headless\"></a>Headless</h3><p>So, before I went headless things were working…uhh…well enough.  Not well enough that I could leave it alone really and any time the system was put under stress <strong>!BAM!</strong> I would lose a node.  This ended up being <strong>the clincher</strong>.  I noticed the Raspbian UI itself was eating up just enough RAM to prevent my nodes from allocating more in times of need.  I chopped off their heads and since then along with the other changes I made my nodes have been rock solid on the memory front.</p>\n<h3 id=\"Memory-is-good-how-about-disk\"><a href=\"#Memory-is-good-how-about-disk\" class=\"headerlink\" title=\"Memory is good how about disk?\"></a>Memory is good how about disk?</h3><p>We already talked about the swap file.  Not only is it <a href=\"https://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettingsLinux.html#recommendedSettingsLinux__disable-swap\">strongly recommended</a> to disable swap on nodes running Cassandra, but even more so on PI’s running on microSD’s.  Before I did so it was clear my nodes were struggling as even small tasks kept driving load up and upon some inspection it was obvious I/O was mostly to blame.  However, something else was lurking even after I disabled swap.  At times I would see my nodes shoot up from a load of <code>&lt;1 upwards to 10+</code>.  At this point they would usually become unresponsive and either crash or eventually come back to reality, but always, always under heavy load.</p>\n<h3 id=\"Colllleccccctionnnnnn-Daaaaatttttaaaaa\"><a href=\"#Colllleccccctionnnnnn-Daaaaatttttaaaaa\" class=\"headerlink\" title=\"Colllleccccctionnnnnn Daaaaatttttaaaaa\"></a>Colllleccccctionnnnnn Daaaaatttttaaaaa</h3><p>Sorry, couldn’t help myself.  As stated above move collection data storage off the PI’s onto a <a href=\"https://docs.datastax.com/en/opscenter/6.0/opsc/configure/opscStoringCollectionDataDifferentCluster_t.html\">separate cluster</a>.  They simply cannot handle all of the I/O associated with collecting, storing, and repairing the collection data from the rollup* tables.  Compaction was happening way too fast for the nodes to keep up most likely a result of having very little memory to work with, the PI’s could not keep up with the amount of collection data itself, and read repair on the rollup* tables was a constant, never ending stream of repair.  Once I made the switch my PI nodes all quieted down to a normal <code>load around 1</code>, things have stabilized, and   I no longer have gaps in my analytics data (except for when I <strong>HULK SMASH</strong> nodes myself for fun).</p>\n<h2 id=\"Finally-the-mixed-workload-part\"><a href=\"#Finally-the-mixed-workload-part\" class=\"headerlink\" title=\"Finally, the mixed workload part\"></a>Finally, the mixed workload part</h2><p>Yup, right there in the title and all and I haven’t really mentioned it.  Part of the reason I went and did all of this aside from learning and seeing what could be done was to extend <a href=\"http://www.luketillman.com/\">Luke Tillman’s <strong>*cough*….shame…less..plug *cooouugh*</strong></a> freaking awesome <a href=\"https://killrvideo.github.io/\">KillrVideo</a> reference app to hook up to clusters outside of its <a href=\"https://www.docker.com/\">Dockerized</a> container.  This forced me to extend my existing Cassandra cluster into a mixed workload scenario with <a href=\"http://docs.datastax.com/en/datastax_enterprise/5.0/datastax_enterprise/srch/searchOverview.html\">DSE Search</a>.  Right, I could have simply put search within the same cluster, but I was looking to emulate what I would do in a production scenario.  I have an upcoming post on this very topic coming here in the future.  I also had need to extend into <a href=\"http://www.datastax.com/products/datastax-enterprise-graph\">DSE graph</a> as well for some of my own projects so I took the opportunity to go ahead and just do it all.  The end result is a fully functional Cassandra/Search/Graph DSE managed mixed workload cluster being served up mostly on Raspberry PI’s with a little help from a laptop all hooked up to <a href=\"https://killrvideo.github.io/\">KillrVideo</a>.</p>\n<p>One last thing before I go.  I find that tailing the agent.log, opscenterd.log, and system.log files from all of the nodes is quite insightful especially when watching the interaction between the nodes when performing regular CQL, search, and graph queries.  I’m also the type of person who can watch a defrag for hours and find every little box color change useful information.  </p>\n<p>Not sure what that says about me.  </p>"},{"title":"Moving from Cassandra tables to Search with DataStax: Part 3","date":"2018-03-02T16:09:15.000Z","_content":"\nResults\nNotice that we can use the exact same return types because Search is embedded within CQL queries\n\n\nLOCAL_ONE compared to LOCAL_QUORUM\n\nexclusion of conjunctions now that search expands beyond tags\n\npaging:driver","source":"_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-3.md","raw":"---\ntitle: 'Moving from Cassandra tables to Search with DataStax: Part 3'\ndate: 2018-02-30 11:09:15\ncategories:\n    - Technical\ntags:\n    - killrvideo\n    - datastax\n    - search\n---\n\nResults\nNotice that we can use the exact same return types because Search is embedded within CQL queries\n\n\nLOCAL_ONE compared to LOCAL_QUORUM\n\nexclusion of conjunctions now that search expands beyond tags\n\npaging:driver","slug":"Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-3","published":1,"updated":"2018-02-12T17:13:43.873Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjdkqmjej0007nhkm7nbywoua","content":"<p>Results<br>Notice that we can use the exact same return types because Search is embedded within CQL queries</p>\n<p>LOCAL_ONE compared to LOCAL_QUORUM</p>\n<p>exclusion of conjunctions now that search expands beyond tags</p>\n<p>paging:driver</p>\n","excerpt":"","more":"<p>Results<br>Notice that we can use the exact same return types because Search is embedded within CQL queries</p>\n<p>LOCAL_ONE compared to LOCAL_QUORUM</p>\n<p>exclusion of conjunctions now that search expands beyond tags</p>\n<p>paging:driver</p>\n"},{"title":"Moving from Cassandra tables to Search with DataStax: Part 2","date":"2018-02-12T21:11:12.000Z","_content":"Hello again and welcome to part 2 of my 3 part series on moving from Cassandra tables to using [DataStax Enterprise Search][dsesearch].  If you haven't read part 1 yet go take a look as it contains the backstory for this series.\n\nIn part 1 we looked at the types of searches we perform in KillrVideo, scratched the surface on how those searches were implemented, and then I asked a set of questions that lead us into why we might use DSE Search.  Here in part 2, I'll discuss why we moved to using DSE Search, detail what the transition encompassed, and explain considerations I took into account when making the switch.\n\nOne thing I'd like to point out before we get started is the Cassandra only approach that we replaced with DSE Search is perfectly valid.  At times I make the case for why the Search approach is better IMO for our particular situation, but it is not broken or anything along those lines and it follows established denormalized query-first design patterns.\n\n## The move to DSE Search\nSo, we decided to switch from using only Cassandra tables for our searches to using DSE Search.  That part is obvious enough, but some of you might be curious as to why we made this move.\n<iframe src=\"https://giphy.com/embed/1M9fmo1WAFVK0\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\n<!-- more -->\n\nAll of the searches worked perfectly fine with Cassandra tables, they performed well, and honestly the code to implement was not terribly complex so what was it that pushed us over the edge?\n\nIt was the need to expand searches to include more than tags, provide more comprehensive, \"fuzzy\" searches, and enable more flexibility for future search enhancements.\n\n### Why, why, why\nIf you remember from part 1, I detailed what the various searches were all doing.  One common denominator was the use of the **tag** column for all of our searches.  Now, we wanted to expand our searches to include both video **name** and **description** columns along with **tag**.  Sure, I could modify the existing schema to include the new columns, but then I would have a data migration to worry about to populate the new columns on existing rows.  I would also have to touch all code points that intersected with any of the searches, update entity classes, change CQL queries, and potentially change or add code logic to handle the new columns not to mention the inflexibility of it all if I needed to add another column(s) down the line.\n\nNow in all frankness I would have to do some of this if we switched to using DSE Search, but as you'll see it's more of a removal task than a data model and design change.  While writing this article it also dawned on me I have the benefit of hindsight since we're already using Search.  It's easy to say \"well just do it this way\", but when coming at this fresh and looking at what we were trying to accomplish it was a no brainer.  Comparing the Cassandra, Search, Analytics, and Graph workloads available to [DSE][dse] the requirements here almost read like a [product page for Search][dsesearch].  It's the right tool for the job.\n\n## Time to get dirty\nOk, we made the decision to use DSE Search and now it's time to update the application.  Before I started hacking at code though I needed to figure out what I was dealing with from a query perspective.  Remember from part 1 of this series we have the following Cassandra only CQL queries to perform our searches.\n```SQL\n// typeahead\nSELECT tag FROM tags_by_letter WHERE first_letter = ? AND tag >= ?\n```\nand\n```SQL\n// tag and \"more videos like this\"\nSELECT * FROM videos_by_tag WHERE tag = ?\n```\nNot very hard, but we need multiple, specialized tables to handle our searches.\n\nIn order to start using DSE Search I needed to create a search index.  At this point I just want to point out my intent here is not to be a whole guide on how to create and implement search indexes.  The focus is on our case moving from Cassandra tables to DSE Search.  I will go over some of the highlights just to connect some dots and break down the sections that are relevant for this post.  If you are not familiar with how to create Search indexes I highly suggest you take a look at [this blog post on creating search indexes in DSE 5.1][searchindexmanagementblog] along with the [documentation][searchindexmanagementdocs] on the same topic.  If you want a total deep dive on DSE Search I highly suggest you check out the [DataStax Academy course on DSE Search][dsesearchacademy] and prepare to have your mind blown.\n\n### Back to it\n[Here is the schema][videosschemaxml] defined for our **videos** table.  It was mostly auto-generated after enabling Search with dse_tool.  If you are curious about how the schema is configured take a look [here][searchindexschema].  Why the **videos** table?  Because it holds all of the information necessary for our searches, namely, **tags** (as before), **name**, and **description** and since the **videos** table is populated on each video upload we get everything we need without having to write to multiple denormalized tables.  As a matter of fact, implementing our searches against the **videos** table allowed us to remove the VideoAddedHandlers class and the asynchronous Cassandra queries contained within, but I am getting ahead of myself.\n\nFor our current discussion lets focus on the following snippet:\n```XML\n    <!-- For search autocomplete functionality, copy name and tags fields to search_suggestions field -->\n    <field indexed=\"true\" multiValued=\"false\" name=\"search_suggestions\" stored=\"true\" type=\"textSuggest\" />\n    <copyField source=\"name\" dest=\"search_suggestions\" />\n    <copyField source=\"tags\" dest=\"search_suggestions\" />\n```\nNotice the field name of \"search_suggestions\" and both the \"name\" and \"tags\" **copyField**'s.  We essentially copied **name** and **tag** column information into a single field called \"search_suggestions\".  This will come into play here in a moment.\n\nThen take a look at the \"Basic fields\" section:\n```XML\n    <!-- Basic fields -->\n    <field indexed=\"true\" multiValued=\"false\" name=\"added_date\" stored=\"true\" type=\"TrieDateField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"location\" stored=\"true\" type=\"TextField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"preview_image_location\" stored=\"true\" type=\"TextField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"name\" termVectors=\"true\" stored=\"true\" type=\"TextField\"/>\n    <field indexed=\"true\" multiValued=\"true\" name=\"tags\" termVectors=\"true\" stored=\"true\" type=\"TextField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"userid\" stored=\"true\" type=\"UUIDField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"videoid\" stored=\"true\" type=\"UUIDField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"location_type\" stored=\"true\" type=\"TrieIntField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"description\" termVectors=\"true\" stored=\"true\" type=\"TextField\"/>\n```\nAs I mentioned above most of this was auto-generated.  This includes indexes for all of the columns in the **videos** table which allows us to perform searches against any of the columns in our table.  For our case we are using **tags**, **name**, and **description**.  If you are curious about why we might want the other columns I refer you to *OutOfScopeOfThisArticleException*.  It is something I will cover in the future.  The important takeaway is we have the needed columns indexed.\n\nSome of you might be thinking \"wait, isn't this more complex than just creating some Cassandra tables like you had before?\".  It's about the same IMO.  We're defining fields and their types in a schema, just a different type of schema, but once we do this we are all set to go...**for all of our searches!**\n\n### Back to creating our index\nI've pulled the following out of KillrVideo's bootstrap script.  We use this to create all of the initial database artifacts needed to run KillrVideo on cluster creation.  This may obviously be different for you depending on your setup, but it should give you the general idea.  We are using dsetool to both create and reload our core against the **videos** tables in our **killrvideo** keyspace.\n```BASH\n    echo '=> Creating search core'\n      dsetool -h $YOUR_CLUSTER_IP create_core killrvideo.videos schema=$YOUR_SCHEMA_LOCATION/videos.schema.xml solrconfig=$YOUR_SCHEMA_LOCATION/videos.solrconfig.xml -l $USERNAME -p $PASSWORD\n\n    echo '=> Reloading search core'\n      dsetool -h $YOUR_CLUSTER_IP reload_core killrvideo.videos schema=$YOUR_SCHEMA_LOCATION/videos.schema.xml solrconfig=$YOUR_SCHEMA_LOCATION/videos.solrconfig.xml -l $USERNAME -p $PASSWORD\n```\nOnce this completes, that's it.  Search indexes are in place and ready for use.  As we insert data into the Cassandra based **videos** table our indexes will automatically be updated.  No extra queries, explicit code, or anything else needed.\n\n*One more thing on this whole schema thing before I move on.  Search index creation will be a* **whole lot easier in the upcoming DSE 6**.  *I'll have some posts digging into this in the near future and I'm totally stoked to say the least so keep an eye out for updates*.\n\n### Let's take stock\nI think it's a good idea to summarize where we're at so far.  We've effectively replaced our 2 Cassandra only tables with a Search core loaded against the **videos** table, and we've loaded that same core for use within our database.  Within our search core we created a field named \"search_suggestions\" that combines data from the **tags** and **name** columns into a single field and now we can start performing searches using DSE Search against any of the fields we created in the search schema above.\n\n## Cassandra based search vs. DSE Search comparisons\nSo now comes the fun part where we get to take a look at how the different Cassandra and Search based searches compare.\n\n### \"Typeahead\" search\nLet's start with the \"typeahead\" search from the search bar.  For our examples I'm using query parameters with value 'd'.  This is the same as if I typed 'd' in the search bar from the UI.\nHere's the original CQL:\n```SQL\nSELECT\n    tag\nFROM \n    tags_by_letter \nWHERE \n    first_letter = 'd' AND tag >= 'd';\n```\nHere's the CQL with Search in place:\n```SQL\nSELECT\n    tags, name\nFROM\n    videos \nWHERE \n    solr_query='{\"q\":\"search_suggestions:d*\", \"paging\":\"driver\"}';\n```\nRight away there are a couple differences to point out.\n\nOne, notice that in the original query I am selecting only the **tag** column.  This is because the **tags_by_letter** table only includes tags, there is nothing else to extract.  The purpose of the table is to provide tags in a very efficient manner.  In the Search based query I am selecting both **tags** and **name** in this case, but I could get any column from the **videos** table if I wanted to.  \n\nAlso, notice the difference between the **tag** and **tags** columns between the two queries.  Since the Search based query is pulling from the **videos** table we return a set of tags in the **tags** column compared to a single tag per row.\n\nThe final piece is probably the most obvious of all, the WHERE clause.  In the original query we are using both our partition key and clustering column to find rows that have the letter 'd' with tags >= 'd'.  I should note this will return an alphabetically ordered list of results because of how clustering columns work.  In the Search query we are looking for any words starting with the letter 'd' from the \"search_suggestions\" field.  This field is a combination of all tags and names.  Don't forget **tags** is a set of tags per row.\n\n*I'm totally glossing over the \"paging\" parameter you see above in the Search query.  We will get to that in part 3.*\n\nNow comes the fun.  Watch what happens when I execute each query.  Also remember that our goal was to expand our search results to provide more complex and varied results.\n{% asset_img tagsbyletterorig.png \"tags_by_letter\" %}\nI'd like to point out there is no LIMIT clause in my query and this is from a database with thousands of videos.\n\nNow, here is the Search query.\n{% asset_img videoswithsearch1.png \"videos\" %}\n.........\n...............\n..........................\n{% asset_img videoswithsearch2.png \"videos2\" %}\n\nNotice not only the amount of results, but that we are matching across both the **tags** and **name** columns and we are matching within the set of values in the **tags** column.  I could have added **description** or any other relevant column from the **videos** table if I wanted to by simply adding it to my query.\n\nSo, ok, we have more results, we have more variation in results, but you might notice we have a lot of repeated terms where the Cassandra based query returned a more succinct set of results.  In my case I handled this with a little regex and a TreeSet that ensures I don't have repeats and results are ordered alphabetically naturally within the set.  As a matter of fact here is that very snippet:\n```Java\n                        // Use a TreeSet to ensure 1) no duplicates, and 2) words are ordered naturally alphabetically\n                        final Set<String> suggestionSet = new TreeSet<>();\n\n                        /**\n                         * Here, we are inserting the request from the search bar, maybe something\n                         * like \"c\", \"ca\", or \"cas\" as someone starts to type the word \"cassandra\".\n                         * For each of these cases we are looking for any words in the search data that\n                         * start with the values above.\n                         */\n                        final String pattern = \"(?i)\\\\b\" + request.getQuery() + \"[a-z]*\\\\b\";\n                        final Pattern checkRegex = Pattern.compile(pattern);\n\n                        int remaining = rows.getAvailableWithoutFetching();\n                        for (Row row : rows) {\n                            String name = row.getString(\"name\");\n                            Set<String> tags = row.getSet(\"tags\", new TypeToken<String>() {});\n\n                            /**\n                             * Since I simply want matches from both the name and tags fields\n                             * concatenate them together, apply regex, and add any results into\n                             * our suggestionSet TreeMap.  The TreeMap will handle any duplicates.\n                             */\n                            Matcher regexMatcher = checkRegex.matcher(name.concat(tags.toString()));\n                            while (regexMatcher.find()) {\n                                suggestionSet.add(regexMatcher.group().toLowerCase());\n                            }\n\n                            if (--remaining == 0) {\n                                break;\n                            }\n                        }\n```\n\n It was a small price to pay for taking this particular approach and there was no noticeable performance degradation in doing so.  I will explore some other options coming up here in the future.\n\n#### Almost there\nBear with me for another example to bring this together.  In the following case I purposely removed the constraint on my pagesize to illustrate the difference in results.  Remember with our Cassandra only query we returned just 5 tags out of thousands of videos.  These were simply the only tags that started with the letter 'd' in the database.  So, nothing wrong with this, it is doing exactly what it was designed for, but we wanted to provide a \"richer\" experience and expand beyond tags.  With Search in place we could now do exactly that and provide a definite increase in variation all while working right out of the **videos** table.  I could expand this further to include any column in my table by simply modifying my query, no data model change needed.\n{% asset_img hugesearchbarlist.png \"long search bar list\" %}\n\nHopefully the amount, and variation of, the options in my search bar are obvious.  Compare this to the 5 results we had previously.\n\n#### I don't know about you, but I could use a break right about now.\n<iframe src=\"https://giphy.com/embed/jAe22Ec5iICCk\" width=\"480\" height=\"358\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\nOk, moving on.\n\n### Tag search and the \"more videos like this\" section\nI'm just going to go ahead and combine these because the original Cassandra only searches are effectively the same.  For reference we are talking about the following query using 'dsl' as the query parameter for the **tag** column:\n```SQL\nSELECT * FROM videos_by_tag WHERE tag = 'dsl';\n```\nFrom the UI perspective this query was used both if an end-user clicked on any of the tag buttons on the video detail page and when viewing the \"More videos like this\" section at the bottom of the video detail page. The former case would simply pass the clicked tag value to the back-end and execute a query similar to what you see above. In our example it would be as if I clicked on the \"dsl\" button below.\n{% asset_img tag.png \"tag\" %}\n\nThe latter case would essentially loop through all of the different tags associated with a video and execute the above query for each tag in the list.  In our example we have 4 queries for \"datastax\", \"dsl\", \"graph\", and \"gremlin\".  The results were then combined and used to populate the \"more video like this\" section.\n{% asset_img morelikethis.png \"more videos like this\" %}\n\n#### Something to point out\nAt this point I'm sure you have noticed that tags are a core component of how searches are powered.  The UI enforces including at least one tag on video upload and they are included in the design for every search.  However, we loosened this restriction when pulling videos from the back-end using the generator service.  We did this because the difference in the amount of videos available to us without tags compared to those with tags under the various topics we are pulling from YouTube is pretty huge.  There are also some pretty useful/cool videos out there that don't include tags.  For each of the Cassandra only searches, if there are no tags, you get no videos, nothing.\n{% asset_img notag.png \"no tag\" %}\n\nCase in point, take a look at the above image.  There are no tags at all, yet if you look at the \"more videos like this\" section at the bottom notice how relevant our results are when compared to the video we are viewing.  This is a nice example of how using Search allowed us to provide a more comprehensive experience by making it easy to include multiple facets of data and even cover the case of missing one of our key pieces of data.  In the previous solution the \"more videos like this\" section would be empty.\n\n### Let's wrap this up\nOk, so we talked about why we made the switch to using DSE Search, looked at some of the details of how this was done, discussed some considerations taken into account, and then viewed some result comparisons.  That's a good amount of stuff, but it's not the full picture.  My goal here was to demonstrate how using DSE Search enhanced our search capability and didn't require us to radically change our overall design.  Hopefully I accomplished my goal.\n\nIn part 3, we'll dive into simplifying our code base by removing the pieces we no longer needed after moving to Search, tie up some loose ends, and look at advanced search capabilities we got for \"free\" simply because we are using Search.\n\nSee you soon :D \n\n\n[dse]: https://www.datastax.com/products/datastax-enterprise\n[dsesearch]: https://www.datastax.com/products/datastax-enterprise-search\n[dsesearchacademy]: https://academy.datastax.com/resources/ds310-datastax-enterprise-search\n[killrvideodata]: https://github.com/KillrVideo/killrvideo-data/tree/master/search\n[searchindexschema]: https://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/search/customizeSchemaSearch.html\n[searchindexmanagementblog]: https://www.datastax.com/2017/05/whats-new-for-search-in-dse-5-1\n[searchindexmanagementdocs]: https://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/search/indexMgmt.html?hl=index%252Cmanagement\n[videosschemaxml]: https://github.com/KillrVideo/killrvideo-data/blob/cbf72443ede4b4d7b712b422a5d95ea0c84664e6/search/videos.schema.xml\n\n","source":"_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2.md","raw":"---\ntitle: 'Moving from Cassandra tables to Search with DataStax: Part 2'\ndate: 2018-02-12 16:11:12\ncategories:\n    - Technical\ntags:\n    - killrvideo\n    - datastax\n    - search\n    - DSE Search\n---\nHello again and welcome to part 2 of my 3 part series on moving from Cassandra tables to using [DataStax Enterprise Search][dsesearch].  If you haven't read part 1 yet go take a look as it contains the backstory for this series.\n\nIn part 1 we looked at the types of searches we perform in KillrVideo, scratched the surface on how those searches were implemented, and then I asked a set of questions that lead us into why we might use DSE Search.  Here in part 2, I'll discuss why we moved to using DSE Search, detail what the transition encompassed, and explain considerations I took into account when making the switch.\n\nOne thing I'd like to point out before we get started is the Cassandra only approach that we replaced with DSE Search is perfectly valid.  At times I make the case for why the Search approach is better IMO for our particular situation, but it is not broken or anything along those lines and it follows established denormalized query-first design patterns.\n\n## The move to DSE Search\nSo, we decided to switch from using only Cassandra tables for our searches to using DSE Search.  That part is obvious enough, but some of you might be curious as to why we made this move.\n<iframe src=\"https://giphy.com/embed/1M9fmo1WAFVK0\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\n<!-- more -->\n\nAll of the searches worked perfectly fine with Cassandra tables, they performed well, and honestly the code to implement was not terribly complex so what was it that pushed us over the edge?\n\nIt was the need to expand searches to include more than tags, provide more comprehensive, \"fuzzy\" searches, and enable more flexibility for future search enhancements.\n\n### Why, why, why\nIf you remember from part 1, I detailed what the various searches were all doing.  One common denominator was the use of the **tag** column for all of our searches.  Now, we wanted to expand our searches to include both video **name** and **description** columns along with **tag**.  Sure, I could modify the existing schema to include the new columns, but then I would have a data migration to worry about to populate the new columns on existing rows.  I would also have to touch all code points that intersected with any of the searches, update entity classes, change CQL queries, and potentially change or add code logic to handle the new columns not to mention the inflexibility of it all if I needed to add another column(s) down the line.\n\nNow in all frankness I would have to do some of this if we switched to using DSE Search, but as you'll see it's more of a removal task than a data model and design change.  While writing this article it also dawned on me I have the benefit of hindsight since we're already using Search.  It's easy to say \"well just do it this way\", but when coming at this fresh and looking at what we were trying to accomplish it was a no brainer.  Comparing the Cassandra, Search, Analytics, and Graph workloads available to [DSE][dse] the requirements here almost read like a [product page for Search][dsesearch].  It's the right tool for the job.\n\n## Time to get dirty\nOk, we made the decision to use DSE Search and now it's time to update the application.  Before I started hacking at code though I needed to figure out what I was dealing with from a query perspective.  Remember from part 1 of this series we have the following Cassandra only CQL queries to perform our searches.\n```SQL\n// typeahead\nSELECT tag FROM tags_by_letter WHERE first_letter = ? AND tag >= ?\n```\nand\n```SQL\n// tag and \"more videos like this\"\nSELECT * FROM videos_by_tag WHERE tag = ?\n```\nNot very hard, but we need multiple, specialized tables to handle our searches.\n\nIn order to start using DSE Search I needed to create a search index.  At this point I just want to point out my intent here is not to be a whole guide on how to create and implement search indexes.  The focus is on our case moving from Cassandra tables to DSE Search.  I will go over some of the highlights just to connect some dots and break down the sections that are relevant for this post.  If you are not familiar with how to create Search indexes I highly suggest you take a look at [this blog post on creating search indexes in DSE 5.1][searchindexmanagementblog] along with the [documentation][searchindexmanagementdocs] on the same topic.  If you want a total deep dive on DSE Search I highly suggest you check out the [DataStax Academy course on DSE Search][dsesearchacademy] and prepare to have your mind blown.\n\n### Back to it\n[Here is the schema][videosschemaxml] defined for our **videos** table.  It was mostly auto-generated after enabling Search with dse_tool.  If you are curious about how the schema is configured take a look [here][searchindexschema].  Why the **videos** table?  Because it holds all of the information necessary for our searches, namely, **tags** (as before), **name**, and **description** and since the **videos** table is populated on each video upload we get everything we need without having to write to multiple denormalized tables.  As a matter of fact, implementing our searches against the **videos** table allowed us to remove the VideoAddedHandlers class and the asynchronous Cassandra queries contained within, but I am getting ahead of myself.\n\nFor our current discussion lets focus on the following snippet:\n```XML\n    <!-- For search autocomplete functionality, copy name and tags fields to search_suggestions field -->\n    <field indexed=\"true\" multiValued=\"false\" name=\"search_suggestions\" stored=\"true\" type=\"textSuggest\" />\n    <copyField source=\"name\" dest=\"search_suggestions\" />\n    <copyField source=\"tags\" dest=\"search_suggestions\" />\n```\nNotice the field name of \"search_suggestions\" and both the \"name\" and \"tags\" **copyField**'s.  We essentially copied **name** and **tag** column information into a single field called \"search_suggestions\".  This will come into play here in a moment.\n\nThen take a look at the \"Basic fields\" section:\n```XML\n    <!-- Basic fields -->\n    <field indexed=\"true\" multiValued=\"false\" name=\"added_date\" stored=\"true\" type=\"TrieDateField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"location\" stored=\"true\" type=\"TextField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"preview_image_location\" stored=\"true\" type=\"TextField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"name\" termVectors=\"true\" stored=\"true\" type=\"TextField\"/>\n    <field indexed=\"true\" multiValued=\"true\" name=\"tags\" termVectors=\"true\" stored=\"true\" type=\"TextField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"userid\" stored=\"true\" type=\"UUIDField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"videoid\" stored=\"true\" type=\"UUIDField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"location_type\" stored=\"true\" type=\"TrieIntField\"/>\n    <field indexed=\"true\" multiValued=\"false\" name=\"description\" termVectors=\"true\" stored=\"true\" type=\"TextField\"/>\n```\nAs I mentioned above most of this was auto-generated.  This includes indexes for all of the columns in the **videos** table which allows us to perform searches against any of the columns in our table.  For our case we are using **tags**, **name**, and **description**.  If you are curious about why we might want the other columns I refer you to *OutOfScopeOfThisArticleException*.  It is something I will cover in the future.  The important takeaway is we have the needed columns indexed.\n\nSome of you might be thinking \"wait, isn't this more complex than just creating some Cassandra tables like you had before?\".  It's about the same IMO.  We're defining fields and their types in a schema, just a different type of schema, but once we do this we are all set to go...**for all of our searches!**\n\n### Back to creating our index\nI've pulled the following out of KillrVideo's bootstrap script.  We use this to create all of the initial database artifacts needed to run KillrVideo on cluster creation.  This may obviously be different for you depending on your setup, but it should give you the general idea.  We are using dsetool to both create and reload our core against the **videos** tables in our **killrvideo** keyspace.\n```BASH\n    echo '=> Creating search core'\n      dsetool -h $YOUR_CLUSTER_IP create_core killrvideo.videos schema=$YOUR_SCHEMA_LOCATION/videos.schema.xml solrconfig=$YOUR_SCHEMA_LOCATION/videos.solrconfig.xml -l $USERNAME -p $PASSWORD\n\n    echo '=> Reloading search core'\n      dsetool -h $YOUR_CLUSTER_IP reload_core killrvideo.videos schema=$YOUR_SCHEMA_LOCATION/videos.schema.xml solrconfig=$YOUR_SCHEMA_LOCATION/videos.solrconfig.xml -l $USERNAME -p $PASSWORD\n```\nOnce this completes, that's it.  Search indexes are in place and ready for use.  As we insert data into the Cassandra based **videos** table our indexes will automatically be updated.  No extra queries, explicit code, or anything else needed.\n\n*One more thing on this whole schema thing before I move on.  Search index creation will be a* **whole lot easier in the upcoming DSE 6**.  *I'll have some posts digging into this in the near future and I'm totally stoked to say the least so keep an eye out for updates*.\n\n### Let's take stock\nI think it's a good idea to summarize where we're at so far.  We've effectively replaced our 2 Cassandra only tables with a Search core loaded against the **videos** table, and we've loaded that same core for use within our database.  Within our search core we created a field named \"search_suggestions\" that combines data from the **tags** and **name** columns into a single field and now we can start performing searches using DSE Search against any of the fields we created in the search schema above.\n\n## Cassandra based search vs. DSE Search comparisons\nSo now comes the fun part where we get to take a look at how the different Cassandra and Search based searches compare.\n\n### \"Typeahead\" search\nLet's start with the \"typeahead\" search from the search bar.  For our examples I'm using query parameters with value 'd'.  This is the same as if I typed 'd' in the search bar from the UI.\nHere's the original CQL:\n```SQL\nSELECT\n    tag\nFROM \n    tags_by_letter \nWHERE \n    first_letter = 'd' AND tag >= 'd';\n```\nHere's the CQL with Search in place:\n```SQL\nSELECT\n    tags, name\nFROM\n    videos \nWHERE \n    solr_query='{\"q\":\"search_suggestions:d*\", \"paging\":\"driver\"}';\n```\nRight away there are a couple differences to point out.\n\nOne, notice that in the original query I am selecting only the **tag** column.  This is because the **tags_by_letter** table only includes tags, there is nothing else to extract.  The purpose of the table is to provide tags in a very efficient manner.  In the Search based query I am selecting both **tags** and **name** in this case, but I could get any column from the **videos** table if I wanted to.  \n\nAlso, notice the difference between the **tag** and **tags** columns between the two queries.  Since the Search based query is pulling from the **videos** table we return a set of tags in the **tags** column compared to a single tag per row.\n\nThe final piece is probably the most obvious of all, the WHERE clause.  In the original query we are using both our partition key and clustering column to find rows that have the letter 'd' with tags >= 'd'.  I should note this will return an alphabetically ordered list of results because of how clustering columns work.  In the Search query we are looking for any words starting with the letter 'd' from the \"search_suggestions\" field.  This field is a combination of all tags and names.  Don't forget **tags** is a set of tags per row.\n\n*I'm totally glossing over the \"paging\" parameter you see above in the Search query.  We will get to that in part 3.*\n\nNow comes the fun.  Watch what happens when I execute each query.  Also remember that our goal was to expand our search results to provide more complex and varied results.\n{% asset_img tagsbyletterorig.png \"tags_by_letter\" %}\nI'd like to point out there is no LIMIT clause in my query and this is from a database with thousands of videos.\n\nNow, here is the Search query.\n{% asset_img videoswithsearch1.png \"videos\" %}\n.........\n...............\n..........................\n{% asset_img videoswithsearch2.png \"videos2\" %}\n\nNotice not only the amount of results, but that we are matching across both the **tags** and **name** columns and we are matching within the set of values in the **tags** column.  I could have added **description** or any other relevant column from the **videos** table if I wanted to by simply adding it to my query.\n\nSo, ok, we have more results, we have more variation in results, but you might notice we have a lot of repeated terms where the Cassandra based query returned a more succinct set of results.  In my case I handled this with a little regex and a TreeSet that ensures I don't have repeats and results are ordered alphabetically naturally within the set.  As a matter of fact here is that very snippet:\n```Java\n                        // Use a TreeSet to ensure 1) no duplicates, and 2) words are ordered naturally alphabetically\n                        final Set<String> suggestionSet = new TreeSet<>();\n\n                        /**\n                         * Here, we are inserting the request from the search bar, maybe something\n                         * like \"c\", \"ca\", or \"cas\" as someone starts to type the word \"cassandra\".\n                         * For each of these cases we are looking for any words in the search data that\n                         * start with the values above.\n                         */\n                        final String pattern = \"(?i)\\\\b\" + request.getQuery() + \"[a-z]*\\\\b\";\n                        final Pattern checkRegex = Pattern.compile(pattern);\n\n                        int remaining = rows.getAvailableWithoutFetching();\n                        for (Row row : rows) {\n                            String name = row.getString(\"name\");\n                            Set<String> tags = row.getSet(\"tags\", new TypeToken<String>() {});\n\n                            /**\n                             * Since I simply want matches from both the name and tags fields\n                             * concatenate them together, apply regex, and add any results into\n                             * our suggestionSet TreeMap.  The TreeMap will handle any duplicates.\n                             */\n                            Matcher regexMatcher = checkRegex.matcher(name.concat(tags.toString()));\n                            while (regexMatcher.find()) {\n                                suggestionSet.add(regexMatcher.group().toLowerCase());\n                            }\n\n                            if (--remaining == 0) {\n                                break;\n                            }\n                        }\n```\n\n It was a small price to pay for taking this particular approach and there was no noticeable performance degradation in doing so.  I will explore some other options coming up here in the future.\n\n#### Almost there\nBear with me for another example to bring this together.  In the following case I purposely removed the constraint on my pagesize to illustrate the difference in results.  Remember with our Cassandra only query we returned just 5 tags out of thousands of videos.  These were simply the only tags that started with the letter 'd' in the database.  So, nothing wrong with this, it is doing exactly what it was designed for, but we wanted to provide a \"richer\" experience and expand beyond tags.  With Search in place we could now do exactly that and provide a definite increase in variation all while working right out of the **videos** table.  I could expand this further to include any column in my table by simply modifying my query, no data model change needed.\n{% asset_img hugesearchbarlist.png \"long search bar list\" %}\n\nHopefully the amount, and variation of, the options in my search bar are obvious.  Compare this to the 5 results we had previously.\n\n#### I don't know about you, but I could use a break right about now.\n<iframe src=\"https://giphy.com/embed/jAe22Ec5iICCk\" width=\"480\" height=\"358\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\nOk, moving on.\n\n### Tag search and the \"more videos like this\" section\nI'm just going to go ahead and combine these because the original Cassandra only searches are effectively the same.  For reference we are talking about the following query using 'dsl' as the query parameter for the **tag** column:\n```SQL\nSELECT * FROM videos_by_tag WHERE tag = 'dsl';\n```\nFrom the UI perspective this query was used both if an end-user clicked on any of the tag buttons on the video detail page and when viewing the \"More videos like this\" section at the bottom of the video detail page. The former case would simply pass the clicked tag value to the back-end and execute a query similar to what you see above. In our example it would be as if I clicked on the \"dsl\" button below.\n{% asset_img tag.png \"tag\" %}\n\nThe latter case would essentially loop through all of the different tags associated with a video and execute the above query for each tag in the list.  In our example we have 4 queries for \"datastax\", \"dsl\", \"graph\", and \"gremlin\".  The results were then combined and used to populate the \"more video like this\" section.\n{% asset_img morelikethis.png \"more videos like this\" %}\n\n#### Something to point out\nAt this point I'm sure you have noticed that tags are a core component of how searches are powered.  The UI enforces including at least one tag on video upload and they are included in the design for every search.  However, we loosened this restriction when pulling videos from the back-end using the generator service.  We did this because the difference in the amount of videos available to us without tags compared to those with tags under the various topics we are pulling from YouTube is pretty huge.  There are also some pretty useful/cool videos out there that don't include tags.  For each of the Cassandra only searches, if there are no tags, you get no videos, nothing.\n{% asset_img notag.png \"no tag\" %}\n\nCase in point, take a look at the above image.  There are no tags at all, yet if you look at the \"more videos like this\" section at the bottom notice how relevant our results are when compared to the video we are viewing.  This is a nice example of how using Search allowed us to provide a more comprehensive experience by making it easy to include multiple facets of data and even cover the case of missing one of our key pieces of data.  In the previous solution the \"more videos like this\" section would be empty.\n\n### Let's wrap this up\nOk, so we talked about why we made the switch to using DSE Search, looked at some of the details of how this was done, discussed some considerations taken into account, and then viewed some result comparisons.  That's a good amount of stuff, but it's not the full picture.  My goal here was to demonstrate how using DSE Search enhanced our search capability and didn't require us to radically change our overall design.  Hopefully I accomplished my goal.\n\nIn part 3, we'll dive into simplifying our code base by removing the pieces we no longer needed after moving to Search, tie up some loose ends, and look at advanced search capabilities we got for \"free\" simply because we are using Search.\n\nSee you soon :D \n\n\n[dse]: https://www.datastax.com/products/datastax-enterprise\n[dsesearch]: https://www.datastax.com/products/datastax-enterprise-search\n[dsesearchacademy]: https://academy.datastax.com/resources/ds310-datastax-enterprise-search\n[killrvideodata]: https://github.com/KillrVideo/killrvideo-data/tree/master/search\n[searchindexschema]: https://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/search/customizeSchemaSearch.html\n[searchindexmanagementblog]: https://www.datastax.com/2017/05/whats-new-for-search-in-dse-5-1\n[searchindexmanagementdocs]: https://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/search/indexMgmt.html?hl=index%252Cmanagement\n[videosschemaxml]: https://github.com/KillrVideo/killrvideo-data/blob/cbf72443ede4b4d7b712b422a5d95ea0c84664e6/search/videos.schema.xml\n\n","slug":"Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2","published":1,"updated":"2018-02-12T21:33:14.452Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjdkqmjen000anhkmc0t1jaat","content":"<p>Hello again and welcome to part 2 of my 3 part series on moving from Cassandra tables to using <a href=\"https://www.datastax.com/products/datastax-enterprise-search\" target=\"_blank\" rel=\"external\">DataStax Enterprise Search</a>.  If you haven’t read part 1 yet go take a look as it contains the backstory for this series.</p>\n<p>In part 1 we looked at the types of searches we perform in KillrVideo, scratched the surface on how those searches were implemented, and then I asked a set of questions that lead us into why we might use DSE Search.  Here in part 2, I’ll discuss why we moved to using DSE Search, detail what the transition encompassed, and explain considerations I took into account when making the switch.</p>\n<p>One thing I’d like to point out before we get started is the Cassandra only approach that we replaced with DSE Search is perfectly valid.  At times I make the case for why the Search approach is better IMO for our particular situation, but it is not broken or anything along those lines and it follows established denormalized query-first design patterns.</p>\n<h2 id=\"The-move-to-DSE-Search\"><a href=\"#The-move-to-DSE-Search\" class=\"headerlink\" title=\"The move to DSE Search\"></a>The move to DSE Search</h2><p>So, we decided to switch from using only Cassandra tables for our searches to using DSE Search.  That part is obvious enough, but some of you might be curious as to why we made this move.</p>\n<iframe src=\"https://giphy.com/embed/1M9fmo1WAFVK0\" width=\"480\" height=\"270\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe>\n\n<a id=\"more\"></a>\n<p>All of the searches worked perfectly fine with Cassandra tables, they performed well, and honestly the code to implement was not terribly complex so what was it that pushed us over the edge?</p>\n<p>It was the need to expand searches to include more than tags, provide more comprehensive, “fuzzy” searches, and enable more flexibility for future search enhancements.</p>\n<h3 id=\"Why-why-why\"><a href=\"#Why-why-why\" class=\"headerlink\" title=\"Why, why, why\"></a>Why, why, why</h3><p>If you remember from part 1, I detailed what the various searches were all doing.  One common denominator was the use of the <strong>tag</strong> column for all of our searches.  Now, we wanted to expand our searches to include both video <strong>name</strong> and <strong>description</strong> columns along with <strong>tag</strong>.  Sure, I could modify the existing schema to include the new columns, but then I would have a data migration to worry about to populate the new columns on existing rows.  I would also have to touch all code points that intersected with any of the searches, update entity classes, change CQL queries, and potentially change or add code logic to handle the new columns not to mention the inflexibility of it all if I needed to add another column(s) down the line.</p>\n<p>Now in all frankness I would have to do some of this if we switched to using DSE Search, but as you’ll see it’s more of a removal task than a data model and design change.  While writing this article it also dawned on me I have the benefit of hindsight since we’re already using Search.  It’s easy to say “well just do it this way”, but when coming at this fresh and looking at what we were trying to accomplish it was a no brainer.  Comparing the Cassandra, Search, Analytics, and Graph workloads available to <a href=\"https://www.datastax.com/products/datastax-enterprise\" target=\"_blank\" rel=\"external\">DSE</a> the requirements here almost read like a <a href=\"https://www.datastax.com/products/datastax-enterprise-search\" target=\"_blank\" rel=\"external\">product page for Search</a>.  It’s the right tool for the job.</p>\n<h2 id=\"Time-to-get-dirty\"><a href=\"#Time-to-get-dirty\" class=\"headerlink\" title=\"Time to get dirty\"></a>Time to get dirty</h2><p>Ok, we made the decision to use DSE Search and now it’s time to update the application.  Before I started hacking at code though I needed to figure out what I was dealing with from a query perspective.  Remember from part 1 of this series we have the following Cassandra only CQL queries to perform our searches.<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">// typeahead</div><div class=\"line\"><span class=\"keyword\">SELECT</span> tag <span class=\"keyword\">FROM</span> tags_by_letter <span class=\"keyword\">WHERE</span> first_letter = ? <span class=\"keyword\">AND</span> tag &gt;= ?</div></pre></td></tr></table></figure></p>\n<p>and<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">// tag and \"more videos like this\"</div><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> videos_by_tag <span class=\"keyword\">WHERE</span> tag = ?</div></pre></td></tr></table></figure></p>\n<p>Not very hard, but we need multiple, specialized tables to handle our searches.</p>\n<p>In order to start using DSE Search I needed to create a search index.  At this point I just want to point out my intent here is not to be a whole guide on how to create and implement search indexes.  The focus is on our case moving from Cassandra tables to DSE Search.  I will go over some of the highlights just to connect some dots and break down the sections that are relevant for this post.  If you are not familiar with how to create Search indexes I highly suggest you take a look at <a href=\"https://www.datastax.com/2017/05/whats-new-for-search-in-dse-5-1\" target=\"_blank\" rel=\"external\">this blog post on creating search indexes in DSE 5.1</a> along with the <a href=\"https://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/search/indexMgmt.html?hl=index%252Cmanagement\" target=\"_blank\" rel=\"external\">documentation</a> on the same topic.  If you want a total deep dive on DSE Search I highly suggest you check out the <a href=\"https://academy.datastax.com/resources/ds310-datastax-enterprise-search\" target=\"_blank\" rel=\"external\">DataStax Academy course on DSE Search</a> and prepare to have your mind blown.</p>\n<h3 id=\"Back-to-it\"><a href=\"#Back-to-it\" class=\"headerlink\" title=\"Back to it\"></a>Back to it</h3><p><a href=\"https://github.com/KillrVideo/killrvideo-data/blob/cbf72443ede4b4d7b712b422a5d95ea0c84664e6/search/videos.schema.xml\" target=\"_blank\" rel=\"external\">Here is the schema</a> defined for our <strong>videos</strong> table.  It was mostly auto-generated after enabling Search with dse_tool.  If you are curious about how the schema is configured take a look <a href=\"https://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/search/customizeSchemaSearch.html\" target=\"_blank\" rel=\"external\">here</a>.  Why the <strong>videos</strong> table?  Because it holds all of the information necessary for our searches, namely, <strong>tags</strong> (as before), <strong>name</strong>, and <strong>description</strong> and since the <strong>videos</strong> table is populated on each video upload we get everything we need without having to write to multiple denormalized tables.  As a matter of fact, implementing our searches against the <strong>videos</strong> table allowed us to remove the VideoAddedHandlers class and the asynchronous Cassandra queries contained within, but I am getting ahead of myself.</p>\n<p>For our current discussion lets focus on the following snippet:<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">&lt;!-- For search autocomplete functionality, copy name and tags fields to search_suggestions field --&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"search_suggestions\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"textSuggest\"</span> /&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">copyField</span> <span class=\"attr\">source</span>=<span class=\"string\">\"name\"</span> <span class=\"attr\">dest</span>=<span class=\"string\">\"search_suggestions\"</span> /&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">copyField</span> <span class=\"attr\">source</span>=<span class=\"string\">\"tags\"</span> <span class=\"attr\">dest</span>=<span class=\"string\">\"search_suggestions\"</span> /&gt;</span></div></pre></td></tr></table></figure></p>\n<p>Notice the field name of “search_suggestions” and both the “name” and “tags” <strong>copyField</strong>‘s.  We essentially copied <strong>name</strong> and <strong>tag</strong> column information into a single field called “search_suggestions”.  This will come into play here in a moment.</p>\n<p>Then take a look at the “Basic fields” section:<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">&lt;!-- Basic fields --&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"added_date\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TrieDateField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"location\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"preview_image_location\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"name\"</span> <span class=\"attr\">termVectors</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"tags\"</span> <span class=\"attr\">termVectors</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"userid\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"UUIDField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"videoid\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"UUIDField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"location_type\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TrieIntField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"description\"</span> <span class=\"attr\">termVectors</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div></pre></td></tr></table></figure></p>\n<p>As I mentioned above most of this was auto-generated.  This includes indexes for all of the columns in the <strong>videos</strong> table which allows us to perform searches against any of the columns in our table.  For our case we are using <strong>tags</strong>, <strong>name</strong>, and <strong>description</strong>.  If you are curious about why we might want the other columns I refer you to <em>OutOfScopeOfThisArticleException</em>.  It is something I will cover in the future.  The important takeaway is we have the needed columns indexed.</p>\n<p>Some of you might be thinking “wait, isn’t this more complex than just creating some Cassandra tables like you had before?”.  It’s about the same IMO.  We’re defining fields and their types in a schema, just a different type of schema, but once we do this we are all set to go…<strong>for all of our searches!</strong></p>\n<h3 id=\"Back-to-creating-our-index\"><a href=\"#Back-to-creating-our-index\" class=\"headerlink\" title=\"Back to creating our index\"></a>Back to creating our index</h3><p>I’ve pulled the following out of KillrVideo’s bootstrap script.  We use this to create all of the initial database artifacts needed to run KillrVideo on cluster creation.  This may obviously be different for you depending on your setup, but it should give you the general idea.  We are using dsetool to both create and reload our core against the <strong>videos</strong> tables in our <strong>killrvideo</strong> keyspace.<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'=&gt; Creating search core'</span></div><div class=\"line\">  dsetool -h <span class=\"variable\">$YOUR_CLUSTER_IP</span> create_core killrvideo.videos schema=<span class=\"variable\">$YOUR_SCHEMA_LOCATION</span>/videos.schema.xml solrconfig=<span class=\"variable\">$YOUR_SCHEMA_LOCATION</span>/videos.solrconfig.xml <span class=\"_\">-l</span> <span class=\"variable\">$USERNAME</span> -p <span class=\"variable\">$PASSWORD</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'=&gt; Reloading search core'</span></div><div class=\"line\">  dsetool -h <span class=\"variable\">$YOUR_CLUSTER_IP</span> reload_core killrvideo.videos schema=<span class=\"variable\">$YOUR_SCHEMA_LOCATION</span>/videos.schema.xml solrconfig=<span class=\"variable\">$YOUR_SCHEMA_LOCATION</span>/videos.solrconfig.xml <span class=\"_\">-l</span> <span class=\"variable\">$USERNAME</span> -p <span class=\"variable\">$PASSWORD</span></div></pre></td></tr></table></figure></p>\n<p>Once this completes, that’s it.  Search indexes are in place and ready for use.  As we insert data into the Cassandra based <strong>videos</strong> table our indexes will automatically be updated.  No extra queries, explicit code, or anything else needed.</p>\n<p><em>One more thing on this whole schema thing before I move on.  Search index creation will be a</em> <strong>whole lot easier in the upcoming DSE 6</strong>.  <em>I’ll have some posts digging into this in the near future and I’m totally stoked to say the least so keep an eye out for updates</em>.</p>\n<h3 id=\"Let’s-take-stock\"><a href=\"#Let’s-take-stock\" class=\"headerlink\" title=\"Let’s take stock\"></a>Let’s take stock</h3><p>I think it’s a good idea to summarize where we’re at so far.  We’ve effectively replaced our 2 Cassandra only tables with a Search core loaded against the <strong>videos</strong> table, and we’ve loaded that same core for use within our database.  Within our search core we created a field named “search_suggestions” that combines data from the <strong>tags</strong> and <strong>name</strong> columns into a single field and now we can start performing searches using DSE Search against any of the fields we created in the search schema above.</p>\n<h2 id=\"Cassandra-based-search-vs-DSE-Search-comparisons\"><a href=\"#Cassandra-based-search-vs-DSE-Search-comparisons\" class=\"headerlink\" title=\"Cassandra based search vs. DSE Search comparisons\"></a>Cassandra based search vs. DSE Search comparisons</h2><p>So now comes the fun part where we get to take a look at how the different Cassandra and Search based searches compare.</p>\n<h3 id=\"“Typeahead”-search\"><a href=\"#“Typeahead”-search\" class=\"headerlink\" title=\"“Typeahead” search\"></a>“Typeahead” search</h3><p>Let’s start with the “typeahead” search from the search bar.  For our examples I’m using query parameters with value ‘d’.  This is the same as if I typed ‘d’ in the search bar from the UI.<br>Here’s the original CQL:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span></div><div class=\"line\">    tag</div><div class=\"line\"><span class=\"keyword\">FROM</span> </div><div class=\"line\">    tags_by_letter </div><div class=\"line\"><span class=\"keyword\">WHERE</span> </div><div class=\"line\">    first_letter = <span class=\"string\">'d'</span> <span class=\"keyword\">AND</span> tag &gt;= <span class=\"string\">'d'</span>;</div></pre></td></tr></table></figure></p>\n<p>Here’s the CQL with Search in place:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span></div><div class=\"line\">    tags, <span class=\"keyword\">name</span></div><div class=\"line\"><span class=\"keyword\">FROM</span></div><div class=\"line\">    videos </div><div class=\"line\"><span class=\"keyword\">WHERE</span> </div><div class=\"line\">    solr_query=<span class=\"string\">'&#123;\"q\":\"search_suggestions:d*\", \"paging\":\"driver\"&#125;'</span>;</div></pre></td></tr></table></figure></p>\n<p>Right away there are a couple differences to point out.</p>\n<p>One, notice that in the original query I am selecting only the <strong>tag</strong> column.  This is because the <strong>tags_by_letter</strong> table only includes tags, there is nothing else to extract.  The purpose of the table is to provide tags in a very efficient manner.  In the Search based query I am selecting both <strong>tags</strong> and <strong>name</strong> in this case, but I could get any column from the <strong>videos</strong> table if I wanted to.  </p>\n<p>Also, notice the difference between the <strong>tag</strong> and <strong>tags</strong> columns between the two queries.  Since the Search based query is pulling from the <strong>videos</strong> table we return a set of tags in the <strong>tags</strong> column compared to a single tag per row.</p>\n<p>The final piece is probably the most obvious of all, the WHERE clause.  In the original query we are using both our partition key and clustering column to find rows that have the letter ‘d’ with tags &gt;= ‘d’.  I should note this will return an alphabetically ordered list of results because of how clustering columns work.  In the Search query we are looking for any words starting with the letter ‘d’ from the “search_suggestions” field.  This field is a combination of all tags and names.  Don’t forget <strong>tags</strong> is a set of tags per row.</p>\n<p><em>I’m totally glossing over the “paging” parameter you see above in the Search query.  We will get to that in part 3.</em></p>\n<p>Now comes the fun.  Watch what happens when I execute each query.  Also remember that our goal was to expand our search results to provide more complex and varied results.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tagsbyletterorig.png\" alt=\"tags_by_letter\" title=\"tags_by_letter\"><br>I’d like to point out there is no LIMIT clause in my query and this is from a database with thousands of videos.</p>\n<p>Now, here is the Search query.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch1.png\" alt=\"videos\" title=\"videos\"><br>………<br>……………<br>……………………..<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch2.png\" alt=\"videos2\" title=\"videos2\"></p>\n<p>Notice not only the amount of results, but that we are matching across both the <strong>tags</strong> and <strong>name</strong> columns and we are matching within the set of values in the <strong>tags</strong> column.  I could have added <strong>description</strong> or any other relevant column from the <strong>videos</strong> table if I wanted to by simply adding it to my query.</p>\n<p>So, ok, we have more results, we have more variation in results, but you might notice we have a lot of repeated terms where the Cassandra based query returned a more succinct set of results.  In my case I handled this with a little regex and a TreeSet that ensures I don’t have repeats and results are ordered alphabetically naturally within the set.  As a matter of fact here is that very snippet:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Use a TreeSet to ensure 1) no duplicates, and 2) words are ordered naturally alphabetically</span></div><div class=\"line\"><span class=\"keyword\">final</span> Set&lt;String&gt; suggestionSet = <span class=\"keyword\">new</span> TreeSet&lt;&gt;();</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/**</span></div><div class=\"line\"> * Here, we are inserting the request from the search bar, maybe something</div><div class=\"line\"> * like \"c\", \"ca\", or \"cas\" as someone starts to type the word \"cassandra\".</div><div class=\"line\"> * For each of these cases we are looking for any words in the search data that</div><div class=\"line\"> * start with the values above.</div><div class=\"line\"> */</div><div class=\"line\"><span class=\"keyword\">final</span> String pattern = <span class=\"string\">\"(?i)\\\\b\"</span> + request.getQuery() + <span class=\"string\">\"[a-z]*\\\\b\"</span>;</div><div class=\"line\"><span class=\"keyword\">final</span> Pattern checkRegex = Pattern.compile(pattern);</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">int</span> remaining = rows.getAvailableWithoutFetching();</div><div class=\"line\"><span class=\"keyword\">for</span> (Row row : rows) &#123;</div><div class=\"line\">    String name = row.getString(<span class=\"string\">\"name\"</span>);</div><div class=\"line\">    Set&lt;String&gt; tags = row.getSet(<span class=\"string\">\"tags\"</span>, <span class=\"keyword\">new</span> TypeToken&lt;String&gt;() &#123;&#125;);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">/**</span></div><div class=\"line\">     * Since I simply want matches from both the name and tags fields</div><div class=\"line\">     * concatenate them together, apply regex, and add any results into</div><div class=\"line\">     * our suggestionSet TreeMap.  The TreeMap will handle any duplicates.</div><div class=\"line\">     */</div><div class=\"line\">    Matcher regexMatcher = checkRegex.matcher(name.concat(tags.toString()));</div><div class=\"line\">    <span class=\"keyword\">while</span> (regexMatcher.find()) &#123;</div><div class=\"line\">        suggestionSet.add(regexMatcher.group().toLowerCase());</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span> (--remaining == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">        <span class=\"keyword\">break</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p> It was a small price to pay for taking this particular approach and there was no noticeable performance degradation in doing so.  I will explore some other options coming up here in the future.</p>\n<h4 id=\"Almost-there\"><a href=\"#Almost-there\" class=\"headerlink\" title=\"Almost there\"></a>Almost there</h4><p>Bear with me for another example to bring this together.  In the following case I purposely removed the constraint on my pagesize to illustrate the difference in results.  Remember with our Cassandra only query we returned just 5 tags out of thousands of videos.  These were simply the only tags that started with the letter ‘d’ in the database.  So, nothing wrong with this, it is doing exactly what it was designed for, but we wanted to provide a “richer” experience and expand beyond tags.  With Search in place we could now do exactly that and provide a definite increase in variation all while working right out of the <strong>videos</strong> table.  I could expand this further to include any column in my table by simply modifying my query, no data model change needed.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/hugesearchbarlist.png\" alt=\"long search bar list\" title=\"long search bar list\"></p>\n<p>Hopefully the amount, and variation of, the options in my search bar are obvious.  Compare this to the 5 results we had previously.</p>\n<h4 id=\"I-don’t-know-about-you-but-I-could-use-a-break-right-about-now\"><a href=\"#I-don’t-know-about-you-but-I-could-use-a-break-right-about-now\" class=\"headerlink\" title=\"I don’t know about you, but I could use a break right about now.\"></a>I don’t know about you, but I could use a break right about now.</h4><iframe src=\"https://giphy.com/embed/jAe22Ec5iICCk\" width=\"480\" height=\"358\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe>\n\n<p>Ok, moving on.</p>\n<h3 id=\"Tag-search-and-the-“more-videos-like-this”-section\"><a href=\"#Tag-search-and-the-“more-videos-like-this”-section\" class=\"headerlink\" title=\"Tag search and the “more videos like this” section\"></a>Tag search and the “more videos like this” section</h3><p>I’m just going to go ahead and combine these because the original Cassandra only searches are effectively the same.  For reference we are talking about the following query using ‘dsl’ as the query parameter for the <strong>tag</strong> column:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> videos_by_tag <span class=\"keyword\">WHERE</span> tag = <span class=\"string\">'dsl'</span>;</div></pre></td></tr></table></figure></p>\n<p>From the UI perspective this query was used both if an end-user clicked on any of the tag buttons on the video detail page and when viewing the “More videos like this” section at the bottom of the video detail page. The former case would simply pass the clicked tag value to the back-end and execute a query similar to what you see above. In our example it would be as if I clicked on the “dsl” button below.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tag.png\" alt=\"tag\" title=\"tag\"></p>\n<p>The latter case would essentially loop through all of the different tags associated with a video and execute the above query for each tag in the list.  In our example we have 4 queries for “datastax”, “dsl”, “graph”, and “gremlin”.  The results were then combined and used to populate the “more video like this” section.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/morelikethis.png\" alt=\"more videos like this\" title=\"more videos like this\"></p>\n<h4 id=\"Something-to-point-out\"><a href=\"#Something-to-point-out\" class=\"headerlink\" title=\"Something to point out\"></a>Something to point out</h4><p>At this point I’m sure you have noticed that tags are a core component of how searches are powered.  The UI enforces including at least one tag on video upload and they are included in the design for every search.  However, we loosened this restriction when pulling videos from the back-end using the generator service.  We did this because the difference in the amount of videos available to us without tags compared to those with tags under the various topics we are pulling from YouTube is pretty huge.  There are also some pretty useful/cool videos out there that don’t include tags.  For each of the Cassandra only searches, if there are no tags, you get no videos, nothing.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/notag.png\" alt=\"no tag\" title=\"no tag\"></p>\n<p>Case in point, take a look at the above image.  There are no tags at all, yet if you look at the “more videos like this” section at the bottom notice how relevant our results are when compared to the video we are viewing.  This is a nice example of how using Search allowed us to provide a more comprehensive experience by making it easy to include multiple facets of data and even cover the case of missing one of our key pieces of data.  In the previous solution the “more videos like this” section would be empty.</p>\n<h3 id=\"Let’s-wrap-this-up\"><a href=\"#Let’s-wrap-this-up\" class=\"headerlink\" title=\"Let’s wrap this up\"></a>Let’s wrap this up</h3><p>Ok, so we talked about why we made the switch to using DSE Search, looked at some of the details of how this was done, discussed some considerations taken into account, and then viewed some result comparisons.  That’s a good amount of stuff, but it’s not the full picture.  My goal here was to demonstrate how using DSE Search enhanced our search capability and didn’t require us to radically change our overall design.  Hopefully I accomplished my goal.</p>\n<p>In part 3, we’ll dive into simplifying our code base by removing the pieces we no longer needed after moving to Search, tie up some loose ends, and look at advanced search capabilities we got for “free” simply because we are using Search.</p>\n<p>See you soon :D </p>\n","excerpt":"<p>Hello again and welcome to part 2 of my 3 part series on moving from Cassandra tables to using <a href=\"https://www.datastax.com/products/datastax-enterprise-search\">DataStax Enterprise Search</a>.  If you haven’t read part 1 yet go take a look as it contains the backstory for this series.</p>\n<p>In part 1 we looked at the types of searches we perform in KillrVideo, scratched the surface on how those searches were implemented, and then I asked a set of questions that lead us into why we might use DSE Search.  Here in part 2, I’ll discuss why we moved to using DSE Search, detail what the transition encompassed, and explain considerations I took into account when making the switch.</p>\n<p>One thing I’d like to point out before we get started is the Cassandra only approach that we replaced with DSE Search is perfectly valid.  At times I make the case for why the Search approach is better IMO for our particular situation, but it is not broken or anything along those lines and it follows established denormalized query-first design patterns.</p>\n<h2 id=\"The-move-to-DSE-Search\"><a href=\"#The-move-to-DSE-Search\" class=\"headerlink\" title=\"The move to DSE Search\"></a>The move to DSE Search</h2><p>So, we decided to switch from using only Cassandra tables for our searches to using DSE Search.  That part is obvious enough, but some of you might be curious as to why we made this move.</p>\n<iframe src=\"https://giphy.com/embed/1M9fmo1WAFVK0\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>","more":"<p>All of the searches worked perfectly fine with Cassandra tables, they performed well, and honestly the code to implement was not terribly complex so what was it that pushed us over the edge?</p>\n<p>It was the need to expand searches to include more than tags, provide more comprehensive, “fuzzy” searches, and enable more flexibility for future search enhancements.</p>\n<h3 id=\"Why-why-why\"><a href=\"#Why-why-why\" class=\"headerlink\" title=\"Why, why, why\"></a>Why, why, why</h3><p>If you remember from part 1, I detailed what the various searches were all doing.  One common denominator was the use of the <strong>tag</strong> column for all of our searches.  Now, we wanted to expand our searches to include both video <strong>name</strong> and <strong>description</strong> columns along with <strong>tag</strong>.  Sure, I could modify the existing schema to include the new columns, but then I would have a data migration to worry about to populate the new columns on existing rows.  I would also have to touch all code points that intersected with any of the searches, update entity classes, change CQL queries, and potentially change or add code logic to handle the new columns not to mention the inflexibility of it all if I needed to add another column(s) down the line.</p>\n<p>Now in all frankness I would have to do some of this if we switched to using DSE Search, but as you’ll see it’s more of a removal task than a data model and design change.  While writing this article it also dawned on me I have the benefit of hindsight since we’re already using Search.  It’s easy to say “well just do it this way”, but when coming at this fresh and looking at what we were trying to accomplish it was a no brainer.  Comparing the Cassandra, Search, Analytics, and Graph workloads available to <a href=\"https://www.datastax.com/products/datastax-enterprise\">DSE</a> the requirements here almost read like a <a href=\"https://www.datastax.com/products/datastax-enterprise-search\">product page for Search</a>.  It’s the right tool for the job.</p>\n<h2 id=\"Time-to-get-dirty\"><a href=\"#Time-to-get-dirty\" class=\"headerlink\" title=\"Time to get dirty\"></a>Time to get dirty</h2><p>Ok, we made the decision to use DSE Search and now it’s time to update the application.  Before I started hacking at code though I needed to figure out what I was dealing with from a query perspective.  Remember from part 1 of this series we have the following Cassandra only CQL queries to perform our searches.<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">// typeahead</div><div class=\"line\"><span class=\"keyword\">SELECT</span> tag <span class=\"keyword\">FROM</span> tags_by_letter <span class=\"keyword\">WHERE</span> first_letter = ? <span class=\"keyword\">AND</span> tag &gt;= ?</div></pre></td></tr></table></figure></p>\n<p>and<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">// tag and \"more videos like this\"</div><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> videos_by_tag <span class=\"keyword\">WHERE</span> tag = ?</div></pre></td></tr></table></figure></p>\n<p>Not very hard, but we need multiple, specialized tables to handle our searches.</p>\n<p>In order to start using DSE Search I needed to create a search index.  At this point I just want to point out my intent here is not to be a whole guide on how to create and implement search indexes.  The focus is on our case moving from Cassandra tables to DSE Search.  I will go over some of the highlights just to connect some dots and break down the sections that are relevant for this post.  If you are not familiar with how to create Search indexes I highly suggest you take a look at <a href=\"https://www.datastax.com/2017/05/whats-new-for-search-in-dse-5-1\">this blog post on creating search indexes in DSE 5.1</a> along with the <a href=\"https://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/search/indexMgmt.html?hl=index%252Cmanagement\">documentation</a> on the same topic.  If you want a total deep dive on DSE Search I highly suggest you check out the <a href=\"https://academy.datastax.com/resources/ds310-datastax-enterprise-search\">DataStax Academy course on DSE Search</a> and prepare to have your mind blown.</p>\n<h3 id=\"Back-to-it\"><a href=\"#Back-to-it\" class=\"headerlink\" title=\"Back to it\"></a>Back to it</h3><p><a href=\"https://github.com/KillrVideo/killrvideo-data/blob/cbf72443ede4b4d7b712b422a5d95ea0c84664e6/search/videos.schema.xml\">Here is the schema</a> defined for our <strong>videos</strong> table.  It was mostly auto-generated after enabling Search with dse_tool.  If you are curious about how the schema is configured take a look <a href=\"https://docs.datastax.com/en/dse/5.1/dse-dev/datastax_enterprise/search/customizeSchemaSearch.html\">here</a>.  Why the <strong>videos</strong> table?  Because it holds all of the information necessary for our searches, namely, <strong>tags</strong> (as before), <strong>name</strong>, and <strong>description</strong> and since the <strong>videos</strong> table is populated on each video upload we get everything we need without having to write to multiple denormalized tables.  As a matter of fact, implementing our searches against the <strong>videos</strong> table allowed us to remove the VideoAddedHandlers class and the asynchronous Cassandra queries contained within, but I am getting ahead of myself.</p>\n<p>For our current discussion lets focus on the following snippet:<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">&lt;!-- For search autocomplete functionality, copy name and tags fields to search_suggestions field --&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"search_suggestions\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"textSuggest\"</span> /&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">copyField</span> <span class=\"attr\">source</span>=<span class=\"string\">\"name\"</span> <span class=\"attr\">dest</span>=<span class=\"string\">\"search_suggestions\"</span> /&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">copyField</span> <span class=\"attr\">source</span>=<span class=\"string\">\"tags\"</span> <span class=\"attr\">dest</span>=<span class=\"string\">\"search_suggestions\"</span> /&gt;</span></div></pre></td></tr></table></figure></p>\n<p>Notice the field name of “search_suggestions” and both the “name” and “tags” <strong>copyField</strong>‘s.  We essentially copied <strong>name</strong> and <strong>tag</strong> column information into a single field called “search_suggestions”.  This will come into play here in a moment.</p>\n<p>Then take a look at the “Basic fields” section:<br><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">&lt;!-- Basic fields --&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"added_date\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TrieDateField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"location\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"preview_image_location\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"name\"</span> <span class=\"attr\">termVectors</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"tags\"</span> <span class=\"attr\">termVectors</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"userid\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"UUIDField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"videoid\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"UUIDField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"location_type\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TrieIntField\"</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">field</span> <span class=\"attr\">indexed</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">multiValued</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">name</span>=<span class=\"string\">\"description\"</span> <span class=\"attr\">termVectors</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">stored</span>=<span class=\"string\">\"true\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"TextField\"</span>/&gt;</span></div></pre></td></tr></table></figure></p>\n<p>As I mentioned above most of this was auto-generated.  This includes indexes for all of the columns in the <strong>videos</strong> table which allows us to perform searches against any of the columns in our table.  For our case we are using <strong>tags</strong>, <strong>name</strong>, and <strong>description</strong>.  If you are curious about why we might want the other columns I refer you to <em>OutOfScopeOfThisArticleException</em>.  It is something I will cover in the future.  The important takeaway is we have the needed columns indexed.</p>\n<p>Some of you might be thinking “wait, isn’t this more complex than just creating some Cassandra tables like you had before?”.  It’s about the same IMO.  We’re defining fields and their types in a schema, just a different type of schema, but once we do this we are all set to go…<strong>for all of our searches!</strong></p>\n<h3 id=\"Back-to-creating-our-index\"><a href=\"#Back-to-creating-our-index\" class=\"headerlink\" title=\"Back to creating our index\"></a>Back to creating our index</h3><p>I’ve pulled the following out of KillrVideo’s bootstrap script.  We use this to create all of the initial database artifacts needed to run KillrVideo on cluster creation.  This may obviously be different for you depending on your setup, but it should give you the general idea.  We are using dsetool to both create and reload our core against the <strong>videos</strong> tables in our <strong>killrvideo</strong> keyspace.<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'=&gt; Creating search core'</span></div><div class=\"line\">  dsetool -h <span class=\"variable\">$YOUR_CLUSTER_IP</span> create_core killrvideo.videos schema=<span class=\"variable\">$YOUR_SCHEMA_LOCATION</span>/videos.schema.xml solrconfig=<span class=\"variable\">$YOUR_SCHEMA_LOCATION</span>/videos.solrconfig.xml <span class=\"_\">-l</span> <span class=\"variable\">$USERNAME</span> -p <span class=\"variable\">$PASSWORD</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"built_in\">echo</span> <span class=\"string\">'=&gt; Reloading search core'</span></div><div class=\"line\">  dsetool -h <span class=\"variable\">$YOUR_CLUSTER_IP</span> reload_core killrvideo.videos schema=<span class=\"variable\">$YOUR_SCHEMA_LOCATION</span>/videos.schema.xml solrconfig=<span class=\"variable\">$YOUR_SCHEMA_LOCATION</span>/videos.solrconfig.xml <span class=\"_\">-l</span> <span class=\"variable\">$USERNAME</span> -p <span class=\"variable\">$PASSWORD</span></div></pre></td></tr></table></figure></p>\n<p>Once this completes, that’s it.  Search indexes are in place and ready for use.  As we insert data into the Cassandra based <strong>videos</strong> table our indexes will automatically be updated.  No extra queries, explicit code, or anything else needed.</p>\n<p><em>One more thing on this whole schema thing before I move on.  Search index creation will be a</em> <strong>whole lot easier in the upcoming DSE 6</strong>.  <em>I’ll have some posts digging into this in the near future and I’m totally stoked to say the least so keep an eye out for updates</em>.</p>\n<h3 id=\"Let’s-take-stock\"><a href=\"#Let’s-take-stock\" class=\"headerlink\" title=\"Let’s take stock\"></a>Let’s take stock</h3><p>I think it’s a good idea to summarize where we’re at so far.  We’ve effectively replaced our 2 Cassandra only tables with a Search core loaded against the <strong>videos</strong> table, and we’ve loaded that same core for use within our database.  Within our search core we created a field named “search_suggestions” that combines data from the <strong>tags</strong> and <strong>name</strong> columns into a single field and now we can start performing searches using DSE Search against any of the fields we created in the search schema above.</p>\n<h2 id=\"Cassandra-based-search-vs-DSE-Search-comparisons\"><a href=\"#Cassandra-based-search-vs-DSE-Search-comparisons\" class=\"headerlink\" title=\"Cassandra based search vs. DSE Search comparisons\"></a>Cassandra based search vs. DSE Search comparisons</h2><p>So now comes the fun part where we get to take a look at how the different Cassandra and Search based searches compare.</p>\n<h3 id=\"“Typeahead”-search\"><a href=\"#“Typeahead”-search\" class=\"headerlink\" title=\"“Typeahead” search\"></a>“Typeahead” search</h3><p>Let’s start with the “typeahead” search from the search bar.  For our examples I’m using query parameters with value ‘d’.  This is the same as if I typed ‘d’ in the search bar from the UI.<br>Here’s the original CQL:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span></div><div class=\"line\">    tag</div><div class=\"line\"><span class=\"keyword\">FROM</span> </div><div class=\"line\">    tags_by_letter </div><div class=\"line\"><span class=\"keyword\">WHERE</span> </div><div class=\"line\">    first_letter = <span class=\"string\">'d'</span> <span class=\"keyword\">AND</span> tag &gt;= <span class=\"string\">'d'</span>;</div></pre></td></tr></table></figure></p>\n<p>Here’s the CQL with Search in place:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span></div><div class=\"line\">    tags, <span class=\"keyword\">name</span></div><div class=\"line\"><span class=\"keyword\">FROM</span></div><div class=\"line\">    videos </div><div class=\"line\"><span class=\"keyword\">WHERE</span> </div><div class=\"line\">    solr_query=<span class=\"string\">'&#123;\"q\":\"search_suggestions:d*\", \"paging\":\"driver\"&#125;'</span>;</div></pre></td></tr></table></figure></p>\n<p>Right away there are a couple differences to point out.</p>\n<p>One, notice that in the original query I am selecting only the <strong>tag</strong> column.  This is because the <strong>tags_by_letter</strong> table only includes tags, there is nothing else to extract.  The purpose of the table is to provide tags in a very efficient manner.  In the Search based query I am selecting both <strong>tags</strong> and <strong>name</strong> in this case, but I could get any column from the <strong>videos</strong> table if I wanted to.  </p>\n<p>Also, notice the difference between the <strong>tag</strong> and <strong>tags</strong> columns between the two queries.  Since the Search based query is pulling from the <strong>videos</strong> table we return a set of tags in the <strong>tags</strong> column compared to a single tag per row.</p>\n<p>The final piece is probably the most obvious of all, the WHERE clause.  In the original query we are using both our partition key and clustering column to find rows that have the letter ‘d’ with tags &gt;= ‘d’.  I should note this will return an alphabetically ordered list of results because of how clustering columns work.  In the Search query we are looking for any words starting with the letter ‘d’ from the “search_suggestions” field.  This field is a combination of all tags and names.  Don’t forget <strong>tags</strong> is a set of tags per row.</p>\n<p><em>I’m totally glossing over the “paging” parameter you see above in the Search query.  We will get to that in part 3.</em></p>\n<p>Now comes the fun.  Watch what happens when I execute each query.  Also remember that our goal was to expand our search results to provide more complex and varied results.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tagsbyletterorig.png\" alt=\"tags_by_letter\" title=\"tags_by_letter\"><br>I’d like to point out there is no LIMIT clause in my query and this is from a database with thousands of videos.</p>\n<p>Now, here is the Search query.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch1.png\" alt=\"videos\" title=\"videos\"><br>………<br>……………<br>……………………..<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch2.png\" alt=\"videos2\" title=\"videos2\"></p>\n<p>Notice not only the amount of results, but that we are matching across both the <strong>tags</strong> and <strong>name</strong> columns and we are matching within the set of values in the <strong>tags</strong> column.  I could have added <strong>description</strong> or any other relevant column from the <strong>videos</strong> table if I wanted to by simply adding it to my query.</p>\n<p>So, ok, we have more results, we have more variation in results, but you might notice we have a lot of repeated terms where the Cassandra based query returned a more succinct set of results.  In my case I handled this with a little regex and a TreeSet that ensures I don’t have repeats and results are ordered alphabetically naturally within the set.  As a matter of fact here is that very snippet:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">// Use a TreeSet to ensure 1) no duplicates, and 2) words are ordered naturally alphabetically</span></div><div class=\"line\"><span class=\"keyword\">final</span> Set&lt;String&gt; suggestionSet = <span class=\"keyword\">new</span> TreeSet&lt;&gt;();</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\">/**</div><div class=\"line\"> * Here, we are inserting the request from the search bar, maybe something</div><div class=\"line\"> * like \"c\", \"ca\", or \"cas\" as someone starts to type the word \"cassandra\".</div><div class=\"line\"> * For each of these cases we are looking for any words in the search data that</div><div class=\"line\"> * start with the values above.</div><div class=\"line\"> */</span></div><div class=\"line\"><span class=\"keyword\">final</span> String pattern = <span class=\"string\">\"(?i)\\\\b\"</span> + request.getQuery() + <span class=\"string\">\"[a-z]*\\\\b\"</span>;</div><div class=\"line\"><span class=\"keyword\">final</span> Pattern checkRegex = Pattern.compile(pattern);</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">int</span> remaining = rows.getAvailableWithoutFetching();</div><div class=\"line\"><span class=\"keyword\">for</span> (Row row : rows) &#123;</div><div class=\"line\">    String name = row.getString(<span class=\"string\">\"name\"</span>);</div><div class=\"line\">    Set&lt;String&gt; tags = row.getSet(<span class=\"string\">\"tags\"</span>, <span class=\"keyword\">new</span> TypeToken&lt;String&gt;() &#123;&#125;);</div><div class=\"line\"></div><div class=\"line\">    <span class=\"comment\">/**</div><div class=\"line\">     * Since I simply want matches from both the name and tags fields</div><div class=\"line\">     * concatenate them together, apply regex, and add any results into</div><div class=\"line\">     * our suggestionSet TreeMap.  The TreeMap will handle any duplicates.</div><div class=\"line\">     */</span></div><div class=\"line\">    Matcher regexMatcher = checkRegex.matcher(name.concat(tags.toString()));</div><div class=\"line\">    <span class=\"keyword\">while</span> (regexMatcher.find()) &#123;</div><div class=\"line\">        suggestionSet.add(regexMatcher.group().toLowerCase());</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    <span class=\"keyword\">if</span> (--remaining == <span class=\"number\">0</span>) &#123;</div><div class=\"line\">        <span class=\"keyword\">break</span>;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p> It was a small price to pay for taking this particular approach and there was no noticeable performance degradation in doing so.  I will explore some other options coming up here in the future.</p>\n<h4 id=\"Almost-there\"><a href=\"#Almost-there\" class=\"headerlink\" title=\"Almost there\"></a>Almost there</h4><p>Bear with me for another example to bring this together.  In the following case I purposely removed the constraint on my pagesize to illustrate the difference in results.  Remember with our Cassandra only query we returned just 5 tags out of thousands of videos.  These were simply the only tags that started with the letter ‘d’ in the database.  So, nothing wrong with this, it is doing exactly what it was designed for, but we wanted to provide a “richer” experience and expand beyond tags.  With Search in place we could now do exactly that and provide a definite increase in variation all while working right out of the <strong>videos</strong> table.  I could expand this further to include any column in my table by simply modifying my query, no data model change needed.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/hugesearchbarlist.png\" alt=\"long search bar list\" title=\"long search bar list\"></p>\n<p>Hopefully the amount, and variation of, the options in my search bar are obvious.  Compare this to the 5 results we had previously.</p>\n<h4 id=\"I-don’t-know-about-you-but-I-could-use-a-break-right-about-now\"><a href=\"#I-don’t-know-about-you-but-I-could-use-a-break-right-about-now\" class=\"headerlink\" title=\"I don’t know about you, but I could use a break right about now.\"></a>I don’t know about you, but I could use a break right about now.</h4><iframe src=\"https://giphy.com/embed/jAe22Ec5iICCk\" width=\"480\" height=\"358\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\n<p>Ok, moving on.</p>\n<h3 id=\"Tag-search-and-the-“more-videos-like-this”-section\"><a href=\"#Tag-search-and-the-“more-videos-like-this”-section\" class=\"headerlink\" title=\"Tag search and the “more videos like this” section\"></a>Tag search and the “more videos like this” section</h3><p>I’m just going to go ahead and combine these because the original Cassandra only searches are effectively the same.  For reference we are talking about the following query using ‘dsl’ as the query parameter for the <strong>tag</strong> column:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> videos_by_tag <span class=\"keyword\">WHERE</span> tag = <span class=\"string\">'dsl'</span>;</div></pre></td></tr></table></figure></p>\n<p>From the UI perspective this query was used both if an end-user clicked on any of the tag buttons on the video detail page and when viewing the “More videos like this” section at the bottom of the video detail page. The former case would simply pass the clicked tag value to the back-end and execute a query similar to what you see above. In our example it would be as if I clicked on the “dsl” button below.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tag.png\" alt=\"tag\" title=\"tag\"></p>\n<p>The latter case would essentially loop through all of the different tags associated with a video and execute the above query for each tag in the list.  In our example we have 4 queries for “datastax”, “dsl”, “graph”, and “gremlin”.  The results were then combined and used to populate the “more video like this” section.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/morelikethis.png\" alt=\"more videos like this\" title=\"more videos like this\"></p>\n<h4 id=\"Something-to-point-out\"><a href=\"#Something-to-point-out\" class=\"headerlink\" title=\"Something to point out\"></a>Something to point out</h4><p>At this point I’m sure you have noticed that tags are a core component of how searches are powered.  The UI enforces including at least one tag on video upload and they are included in the design for every search.  However, we loosened this restriction when pulling videos from the back-end using the generator service.  We did this because the difference in the amount of videos available to us without tags compared to those with tags under the various topics we are pulling from YouTube is pretty huge.  There are also some pretty useful/cool videos out there that don’t include tags.  For each of the Cassandra only searches, if there are no tags, you get no videos, nothing.<br><img src=\"/2018/02/12/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/notag.png\" alt=\"no tag\" title=\"no tag\"></p>\n<p>Case in point, take a look at the above image.  There are no tags at all, yet if you look at the “more videos like this” section at the bottom notice how relevant our results are when compared to the video we are viewing.  This is a nice example of how using Search allowed us to provide a more comprehensive experience by making it easy to include multiple facets of data and even cover the case of missing one of our key pieces of data.  In the previous solution the “more videos like this” section would be empty.</p>\n<h3 id=\"Let’s-wrap-this-up\"><a href=\"#Let’s-wrap-this-up\" class=\"headerlink\" title=\"Let’s wrap this up\"></a>Let’s wrap this up</h3><p>Ok, so we talked about why we made the switch to using DSE Search, looked at some of the details of how this was done, discussed some considerations taken into account, and then viewed some result comparisons.  That’s a good amount of stuff, but it’s not the full picture.  My goal here was to demonstrate how using DSE Search enhanced our search capability and didn’t require us to radically change our overall design.  Hopefully I accomplished my goal.</p>\n<p>In part 3, we’ll dive into simplifying our code base by removing the pieces we no longer needed after moving to Search, tie up some loose ends, and look at advanced search capabilities we got for “free” simply because we are using Search.</p>\n<p>See you soon :D </p>"},{"title":"Moving from Cassandra tables to Search with DataStax: Part 1","date":"2018-01-10T14:28:42.000Z","_content":"Hi there and welcome to **part 1** of a three part series on upgrading our KillrVideo java reference application from Cassandra based tabular searches to using DSE Search.\n\nHere in **part 1**, we'll take a look at the \"before\" picture and how we were previously performing searches.  I'll give some examples of the types of searches and how those were implemented with Cassandra tables.  We'll also talk a little about the \"why\" of moving to DSE Search.\n\nIn **part 2**, I'll explain the transition to DSE Search and what considerations I had to take into account along with a before and after code comparison.\n\nFinally, in **part 3**, we'll take a look at our results along with some of the more advanced types of searches we can now perform.\n\n## Ok, let's do this\nFirst things first...assumptions!  \nIf it isn't obvious, we are using the Java based KillrVideo application for reference.  If you aren't familiar with KillrVideo go take a look [here][killrvideo] to get up to speed.  In short, this is a real, open source, micro-service style application that we build and maintain to present examples and help folks understand the DataStax tech stack.  It's also a nice way that I personally get some code time against the stack in a real application as compared to punching out demo apps.  \n\nWe are using DataStax Enterprise from drivers to cluster.  All of the capabilities we're talking about here are assumed to be within that ecosystem.\n\n<!-- more -->\n\n## Do we really need to use DSE Search?\nNo. Maybe. Yes?  ¯\\\\\\_(ツ)_/¯\nOk, it depends, but for the most basic searches it isn't a requirement.  As a matter of fact search was already implemented in the Java version without using DSE Search.  So, why the change?  Mostly it comes down to requirements and the right tool for the job.  So, before I get into all of this why don't we take a look at the various types of searches that exist in KillrVideo.\n\nIn KillrVideo, you can get details and play any video from the video detail page.  A quick look at the whole page and you can see all of the available searches.  At the top left is the **\"typeahead\" search** bar, over to the right are the **tag search** buttons, and at the very bottom is the **\"more videos like this\"** search.\n{% asset_img videodetail.png \"videodetail\" %}\n\n#### \"Typeahead\" search\nSo, nothing new here really.  These types of searches have been around for quite some time.  Start typing letters in the search bar and you are provided with a list of potential matches \n{% asset_img typeahead.png \"typeahead\" %}\n\n#### Tag search\nThis next one is pretty straightforward as well.  If you click on any of the tag buttons on the video detail page it will perform a search for other videos with the same tag.\n{% asset_img tag.png \"tag\" %}\n\n#### \"More videos like this\" search\nAt the bottom of the video detail page is a section labeled \"More Videos Like This\".  This search will happen automatically when you navigate to any video and present a set of videos that are similar to the video you are currently viewing.  \n{% asset_img morelikethis.png \"more videos like this\" %}\n\n### Let's take a look at the implementation\nRemember I mentioned **before moving** to using DSE Search these were all powered with Cassandra tables.  Let's break some of this down and take a look at some details.  Also, if you are interested check out this [pull request][pullrequest] up on github.  You can use this as a reference of the before and after changes if you so choose.\n\n#### Overview\nSo overall the setup is pretty simple.  We have 3 searches that are supported by a combination of 3 Cassandra tables (the number of searches and tables just happen to match, there is no correlation between them), 3 [table entities][mappedclasses] that map to our Cassandra tables, and 3 [mapping objects][usingmapper] derived from our table entities.  Here is a simple visual representation.\n{% asset_img overviewarch.png \"overview\" %}\n\nNow, I'm really pointing out these particular items because they will come into play later once we move to using DSE Search, namely, we will need to remove most of them.  We'll leave that there for now and come back to it later.\n\nOf the 3 tables I just mentioned 2 of them exist only to support Cassandra based searches in KillrVideo, **tags_by_letter** and **videos_by_tag**.  They follow the [denormalized data model][datamodel] pattern we've come to love in Cassandra and were created solely to support this purpose.  The **videos** table stores all videos inserted into KillrVideo.  It is not specialized to Cassandra based searches and will come into play a little later.\n\nI just mentioned that both **tags_by_letter** and **videos_by_tag** were specially created to support searches within KillrVideo.  Let's take a deeper look at both tables and see what's going on.  If you aren't familiar with primary keys in Apache Cassandra{% raw %}&#8482{% endraw %}\n I highly suggest you take 5 minutes to read [Patrick McFadin's post][primarykeypatrick] on their importance.  This will better explain how they are applied below.\n\nHere is the CQL schema for the **tags_by_letter** table:\n```SQL\nCREATE TABLE IF NOT EXISTS tags_by_letter (\n    first_letter text,\n    tag text,\n    PRIMARY KEY (first_letter, tag)\n);\n```\nThe **first_letter** column is the partition key with **tag** as a clustering column.  The partition key determines where data is located in your cluster while clustering columns handle how data is ordered within the partition.  This is especially useful in cases like a \"typeahead\" search where searches typically start with the first letter of a given search term and usually provide an alphabetical list of results.  This, in a sense, pre-optimizes query results and prevents us from having to sort our data, whether in query execution or code.\n\nJust to absolutely belabor this point (because who doesn't like belaboring something) here is an example of this in action.  Notice how the results are sorted automatically per the **tag** column with no sorting or extra commands needed in the query.\n{% asset_img tagsbyletterexample.png \"tags_by_letter query example\" %}\n\n\nMoving on, here is the CQL schema for the **videos_by_tag** table:\n```SQL\nCREATE TABLE IF NOT EXISTS videos_by_tag (\n    tag text,\n    videoid uuid,\n    added_date timestamp,\n    userid uuid,\n    name text,\n    preview_image_location text,\n    tagged_date timestamp,\n    PRIMARY KEY (tag, videoid)\n);\n```\nAgain, this table was specially created to answer the question of what videos have a specified tag.  It uses **tag** as the partition key which allows for fast retrieval of videos that match a tag when querying.  The other fields you see listed are there to provide information required by our web tier UI.\n\n\n#### VideoAddedHandlers\nAnother portion we need to keep an eye on is the VideoAddedHandlers class.  As the name implies this class is responsible for performing some action(s) every time a video is added to KillrVideo.  If you take a look at the two prepared statements within the init() method you should notice they are inserting data into the 2 search tables we mentioned above **tags_by_letter** and **videos_by_tag**.\n```java\n        videosByTagPrepared = dseSession.prepare(\n                \"INSERT INTO \" + Schema.KEYSPACE + \".\" + videosByTagTableName + \" \" +\n                        \"(tag, videoid, added_date, userid, name, preview_image_location, tagged_date) \" +\n                        \"VALUES (?, ?, ?, ?, ?, ?, ?)\"\n        );\n\n        tagsByLetterPrepared = dseSession.prepare(\n                \"INSERT INTO \" + Schema.KEYSPACE + \".\" + tagsByLetterTableName + \" \" +\n                        \"(first_letter, tag) VALUES (?, ?)\"\n        );\n```\n\nEvery time a video is added these queries are fired off to power our searches.  Notice some of the column names, things like \"tag\" and \"first_letter\".  Again, we will dig into the detailed logic here soon.\n\n#### Detailed logic here soon \nAlrighty, so, we've gone over a high level overview of the various items and objects we are using to support our Cassandra based searches.  Now, let's get into the searches themselves and see what they are doing.\n\n##### \"Typeahead\" search \nAs I mentioned above the typeahead search simply takes the values the user types into the search bar and provides search suggestions based off of the sequence of letters typed in usually with a wildcard attached to the end of the sequence.  An example is something like \"d\" which might return \"database\", \"decision\", \"document\", etc... Then, if the user continues with something like \"da\" could be \"database\", \"databases\", \"datastax\", etc... and so on.\n\nIn the Cassandra based search case this is supported by the **tags_by_letter** table.  Every time a video is added the related subscriber method in the VideoAddedHandlers class is called and **ALL** tags are inserted along with the first letter of the tag into their respective columns.  Since multiple tags are allowed this means we end up looping through and batching up all commands for each tag.\n\nThen, when a user starts typing into the search bar we have the following query to get our results:\n```SQL\nSELECT tag FROM tags_by_letter WHERE first_letter = ? AND tag >= ?\n```\nWhich returns all tags that match the query string from our search.  We loop through those results and send our tags back to the UI.  Pretty simple.  \n\nRemember I previously mentioned the **first_letter** column is the partition key and **tag** is the clustering column which handles data ordering.  This is where this all comes into play.  \n\nAt this point I'd like to point out that we are working only with tags.  **Neither the name or description of any videos are considered**.  Sure, we could add support for this in our data model and code if we really wanted to, but it is something we have to explicitly take into account if we want that capability. \n\n##### Tag search\nOk, let's move to the tag based search.  This one is pretty straightforward.  Click on a tag button in the video details page and return all videos that have the same tag.  This search is supported by the **videos_by_tag** table.  Every time a video is added the related subscriber method in the VideoAddedHandlers class is called and an entry is made for each tag associated with the video.  If a video has one tag there will be a single entry, if it has 5 there will be 5 entries, and so on.  Note that the **videos_by_tag** table is optimized specifically for this task.\n\nIf you click on a tag button the following query is executed:\n```SQL\nSELECT * FROM videos_by_tag WHERE tag = ?\n```\nWhich returns all videos that match the tag provided in the query.  We send these back to the UI which provides a list of videos for you to choose from.\n\n##### \"More videos like this\" search\nThe related videos or \"More videos like this\" section is very similar to the tag search.  The difference in this case is instead of matching only to the selected tag this search will find videos that match all tags of the selected video.  So, if my selected video has tags of \"datastax\", \"dsl\", \"graph\", and \"gremlin\" then the search will return videos that include any of those.  It uses the same query as the tag search above.  The only difference is we'll perform a query for each tag that exists with the video and combine the results.\n\n## A couple things to point out\nFor one, notice how our tables and searches work in lock-step.  The tables were created to support a particular set of searches or \"questions\" asked by our application UI and our code supports whatever CRUD operations are needed to maintain the data we use for searches.  Essentially this was all purpose made to fit our search needs exactly in a denormalized fashion.  This is quite different from how we may have handled things in the relational world.\n\nAlso notice the number of operations needed, mostly on the insert end, to constantly populate the search based tables with data when videos are added to the system.  Now, we're talking about Cassandra here so this is not really that much of an issue, but there is overhead associated with those operations and the code needed to support it.\n\n## Why move to DSE Search?\nSo, what happens now when we want to expand our searches to include more fields separate from tag, provide more varied results, or enable advanced searches?  Is there a way we could reduce the number of overall actions and code needed to support our searches and also speed things up?  Lastly, can we do this in such a way that does not take a whole rethink of our data model?\n\nWell, I think at this point you know exactly what I'm going to suggest, but you'll have to wait until part 2 of this series for details.\n\nOooo...suspense...I know....totally suspenseful\n\nUntil then (quite soon honestly), thanks for reading and I hope you got something useful out of part 1.  Always feel free to add comments or contact me directly for any thoughts or questions.\n\nTake care :D\n\n\n\n[killrvideo]: https://killrvideo.github.io/\n[killrvideo-java]: https://github.com/KillrVideo/killrvideo-java\n[killrvideo-c#]: https://github.com/LukeTillman/killrvideo-csharp\n[killrvideo-nodejs]: https://github.com/KillrVideo/killrvideo-nodejs\n[pullrequest]: https://github.com/KillrVideo/killrvideo-java/pull/23/files\n[mappedclasses]: https://docs.datastax.com/en/developer/java-driver-dse/1.4/manual/object_mapper/creating/\n[usingmapper]: https://docs.datastax.com/en/developer/java-driver-dse/1.4/manual/object_mapper/using/\n[datamodel]: https://www.datastax.com/dev/blog/basic-rules-of-cassandra-data-modeling\n[primarykeypatrick]: https://www.datastax.com/dev/blog/the-most-important-thing-to-know-in-cassandra-data-modeling-the-primary-key\n","source":"_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I.md","raw":"---\ntitle: 'Moving from Cassandra tables to Search with DataStax: Part 1'\ndate: 2018-01-10 09:28:42\ncategories:\n    - Technical\ntags:\n    - killrvideo\n    - datastax\n    - search\n    - DSE Search\n---\nHi there and welcome to **part 1** of a three part series on upgrading our KillrVideo java reference application from Cassandra based tabular searches to using DSE Search.\n\nHere in **part 1**, we'll take a look at the \"before\" picture and how we were previously performing searches.  I'll give some examples of the types of searches and how those were implemented with Cassandra tables.  We'll also talk a little about the \"why\" of moving to DSE Search.\n\nIn **part 2**, I'll explain the transition to DSE Search and what considerations I had to take into account along with a before and after code comparison.\n\nFinally, in **part 3**, we'll take a look at our results along with some of the more advanced types of searches we can now perform.\n\n## Ok, let's do this\nFirst things first...assumptions!  \nIf it isn't obvious, we are using the Java based KillrVideo application for reference.  If you aren't familiar with KillrVideo go take a look [here][killrvideo] to get up to speed.  In short, this is a real, open source, micro-service style application that we build and maintain to present examples and help folks understand the DataStax tech stack.  It's also a nice way that I personally get some code time against the stack in a real application as compared to punching out demo apps.  \n\nWe are using DataStax Enterprise from drivers to cluster.  All of the capabilities we're talking about here are assumed to be within that ecosystem.\n\n<!-- more -->\n\n## Do we really need to use DSE Search?\nNo. Maybe. Yes?  ¯\\\\\\_(ツ)_/¯\nOk, it depends, but for the most basic searches it isn't a requirement.  As a matter of fact search was already implemented in the Java version without using DSE Search.  So, why the change?  Mostly it comes down to requirements and the right tool for the job.  So, before I get into all of this why don't we take a look at the various types of searches that exist in KillrVideo.\n\nIn KillrVideo, you can get details and play any video from the video detail page.  A quick look at the whole page and you can see all of the available searches.  At the top left is the **\"typeahead\" search** bar, over to the right are the **tag search** buttons, and at the very bottom is the **\"more videos like this\"** search.\n{% asset_img videodetail.png \"videodetail\" %}\n\n#### \"Typeahead\" search\nSo, nothing new here really.  These types of searches have been around for quite some time.  Start typing letters in the search bar and you are provided with a list of potential matches \n{% asset_img typeahead.png \"typeahead\" %}\n\n#### Tag search\nThis next one is pretty straightforward as well.  If you click on any of the tag buttons on the video detail page it will perform a search for other videos with the same tag.\n{% asset_img tag.png \"tag\" %}\n\n#### \"More videos like this\" search\nAt the bottom of the video detail page is a section labeled \"More Videos Like This\".  This search will happen automatically when you navigate to any video and present a set of videos that are similar to the video you are currently viewing.  \n{% asset_img morelikethis.png \"more videos like this\" %}\n\n### Let's take a look at the implementation\nRemember I mentioned **before moving** to using DSE Search these were all powered with Cassandra tables.  Let's break some of this down and take a look at some details.  Also, if you are interested check out this [pull request][pullrequest] up on github.  You can use this as a reference of the before and after changes if you so choose.\n\n#### Overview\nSo overall the setup is pretty simple.  We have 3 searches that are supported by a combination of 3 Cassandra tables (the number of searches and tables just happen to match, there is no correlation between them), 3 [table entities][mappedclasses] that map to our Cassandra tables, and 3 [mapping objects][usingmapper] derived from our table entities.  Here is a simple visual representation.\n{% asset_img overviewarch.png \"overview\" %}\n\nNow, I'm really pointing out these particular items because they will come into play later once we move to using DSE Search, namely, we will need to remove most of them.  We'll leave that there for now and come back to it later.\n\nOf the 3 tables I just mentioned 2 of them exist only to support Cassandra based searches in KillrVideo, **tags_by_letter** and **videos_by_tag**.  They follow the [denormalized data model][datamodel] pattern we've come to love in Cassandra and were created solely to support this purpose.  The **videos** table stores all videos inserted into KillrVideo.  It is not specialized to Cassandra based searches and will come into play a little later.\n\nI just mentioned that both **tags_by_letter** and **videos_by_tag** were specially created to support searches within KillrVideo.  Let's take a deeper look at both tables and see what's going on.  If you aren't familiar with primary keys in Apache Cassandra{% raw %}&#8482{% endraw %}\n I highly suggest you take 5 minutes to read [Patrick McFadin's post][primarykeypatrick] on their importance.  This will better explain how they are applied below.\n\nHere is the CQL schema for the **tags_by_letter** table:\n```SQL\nCREATE TABLE IF NOT EXISTS tags_by_letter (\n    first_letter text,\n    tag text,\n    PRIMARY KEY (first_letter, tag)\n);\n```\nThe **first_letter** column is the partition key with **tag** as a clustering column.  The partition key determines where data is located in your cluster while clustering columns handle how data is ordered within the partition.  This is especially useful in cases like a \"typeahead\" search where searches typically start with the first letter of a given search term and usually provide an alphabetical list of results.  This, in a sense, pre-optimizes query results and prevents us from having to sort our data, whether in query execution or code.\n\nJust to absolutely belabor this point (because who doesn't like belaboring something) here is an example of this in action.  Notice how the results are sorted automatically per the **tag** column with no sorting or extra commands needed in the query.\n{% asset_img tagsbyletterexample.png \"tags_by_letter query example\" %}\n\n\nMoving on, here is the CQL schema for the **videos_by_tag** table:\n```SQL\nCREATE TABLE IF NOT EXISTS videos_by_tag (\n    tag text,\n    videoid uuid,\n    added_date timestamp,\n    userid uuid,\n    name text,\n    preview_image_location text,\n    tagged_date timestamp,\n    PRIMARY KEY (tag, videoid)\n);\n```\nAgain, this table was specially created to answer the question of what videos have a specified tag.  It uses **tag** as the partition key which allows for fast retrieval of videos that match a tag when querying.  The other fields you see listed are there to provide information required by our web tier UI.\n\n\n#### VideoAddedHandlers\nAnother portion we need to keep an eye on is the VideoAddedHandlers class.  As the name implies this class is responsible for performing some action(s) every time a video is added to KillrVideo.  If you take a look at the two prepared statements within the init() method you should notice they are inserting data into the 2 search tables we mentioned above **tags_by_letter** and **videos_by_tag**.\n```java\n        videosByTagPrepared = dseSession.prepare(\n                \"INSERT INTO \" + Schema.KEYSPACE + \".\" + videosByTagTableName + \" \" +\n                        \"(tag, videoid, added_date, userid, name, preview_image_location, tagged_date) \" +\n                        \"VALUES (?, ?, ?, ?, ?, ?, ?)\"\n        );\n\n        tagsByLetterPrepared = dseSession.prepare(\n                \"INSERT INTO \" + Schema.KEYSPACE + \".\" + tagsByLetterTableName + \" \" +\n                        \"(first_letter, tag) VALUES (?, ?)\"\n        );\n```\n\nEvery time a video is added these queries are fired off to power our searches.  Notice some of the column names, things like \"tag\" and \"first_letter\".  Again, we will dig into the detailed logic here soon.\n\n#### Detailed logic here soon \nAlrighty, so, we've gone over a high level overview of the various items and objects we are using to support our Cassandra based searches.  Now, let's get into the searches themselves and see what they are doing.\n\n##### \"Typeahead\" search \nAs I mentioned above the typeahead search simply takes the values the user types into the search bar and provides search suggestions based off of the sequence of letters typed in usually with a wildcard attached to the end of the sequence.  An example is something like \"d\" which might return \"database\", \"decision\", \"document\", etc... Then, if the user continues with something like \"da\" could be \"database\", \"databases\", \"datastax\", etc... and so on.\n\nIn the Cassandra based search case this is supported by the **tags_by_letter** table.  Every time a video is added the related subscriber method in the VideoAddedHandlers class is called and **ALL** tags are inserted along with the first letter of the tag into their respective columns.  Since multiple tags are allowed this means we end up looping through and batching up all commands for each tag.\n\nThen, when a user starts typing into the search bar we have the following query to get our results:\n```SQL\nSELECT tag FROM tags_by_letter WHERE first_letter = ? AND tag >= ?\n```\nWhich returns all tags that match the query string from our search.  We loop through those results and send our tags back to the UI.  Pretty simple.  \n\nRemember I previously mentioned the **first_letter** column is the partition key and **tag** is the clustering column which handles data ordering.  This is where this all comes into play.  \n\nAt this point I'd like to point out that we are working only with tags.  **Neither the name or description of any videos are considered**.  Sure, we could add support for this in our data model and code if we really wanted to, but it is something we have to explicitly take into account if we want that capability. \n\n##### Tag search\nOk, let's move to the tag based search.  This one is pretty straightforward.  Click on a tag button in the video details page and return all videos that have the same tag.  This search is supported by the **videos_by_tag** table.  Every time a video is added the related subscriber method in the VideoAddedHandlers class is called and an entry is made for each tag associated with the video.  If a video has one tag there will be a single entry, if it has 5 there will be 5 entries, and so on.  Note that the **videos_by_tag** table is optimized specifically for this task.\n\nIf you click on a tag button the following query is executed:\n```SQL\nSELECT * FROM videos_by_tag WHERE tag = ?\n```\nWhich returns all videos that match the tag provided in the query.  We send these back to the UI which provides a list of videos for you to choose from.\n\n##### \"More videos like this\" search\nThe related videos or \"More videos like this\" section is very similar to the tag search.  The difference in this case is instead of matching only to the selected tag this search will find videos that match all tags of the selected video.  So, if my selected video has tags of \"datastax\", \"dsl\", \"graph\", and \"gremlin\" then the search will return videos that include any of those.  It uses the same query as the tag search above.  The only difference is we'll perform a query for each tag that exists with the video and combine the results.\n\n## A couple things to point out\nFor one, notice how our tables and searches work in lock-step.  The tables were created to support a particular set of searches or \"questions\" asked by our application UI and our code supports whatever CRUD operations are needed to maintain the data we use for searches.  Essentially this was all purpose made to fit our search needs exactly in a denormalized fashion.  This is quite different from how we may have handled things in the relational world.\n\nAlso notice the number of operations needed, mostly on the insert end, to constantly populate the search based tables with data when videos are added to the system.  Now, we're talking about Cassandra here so this is not really that much of an issue, but there is overhead associated with those operations and the code needed to support it.\n\n## Why move to DSE Search?\nSo, what happens now when we want to expand our searches to include more fields separate from tag, provide more varied results, or enable advanced searches?  Is there a way we could reduce the number of overall actions and code needed to support our searches and also speed things up?  Lastly, can we do this in such a way that does not take a whole rethink of our data model?\n\nWell, I think at this point you know exactly what I'm going to suggest, but you'll have to wait until part 2 of this series for details.\n\nOooo...suspense...I know....totally suspenseful\n\nUntil then (quite soon honestly), thanks for reading and I hope you got something useful out of part 1.  Always feel free to add comments or contact me directly for any thoughts or questions.\n\nTake care :D\n\n\n\n[killrvideo]: https://killrvideo.github.io/\n[killrvideo-java]: https://github.com/KillrVideo/killrvideo-java\n[killrvideo-c#]: https://github.com/LukeTillman/killrvideo-csharp\n[killrvideo-nodejs]: https://github.com/KillrVideo/killrvideo-nodejs\n[pullrequest]: https://github.com/KillrVideo/killrvideo-java/pull/23/files\n[mappedclasses]: https://docs.datastax.com/en/developer/java-driver-dse/1.4/manual/object_mapper/creating/\n[usingmapper]: https://docs.datastax.com/en/developer/java-driver-dse/1.4/manual/object_mapper/using/\n[datamodel]: https://www.datastax.com/dev/blog/basic-rules-of-cassandra-data-modeling\n[primarykeypatrick]: https://www.datastax.com/dev/blog/the-most-important-thing-to-know-in-cassandra-data-modeling-the-primary-key\n","slug":"Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I","published":1,"updated":"2018-02-12T21:11:14.747Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjdkqmjep000cnhkmuq5k4kxv","content":"<p>Hi there and welcome to <strong>part 1</strong> of a three part series on upgrading our KillrVideo java reference application from Cassandra based tabular searches to using DSE Search.</p>\n<p>Here in <strong>part 1</strong>, we’ll take a look at the “before” picture and how we were previously performing searches.  I’ll give some examples of the types of searches and how those were implemented with Cassandra tables.  We’ll also talk a little about the “why” of moving to DSE Search.</p>\n<p>In <strong>part 2</strong>, I’ll explain the transition to DSE Search and what considerations I had to take into account along with a before and after code comparison.</p>\n<p>Finally, in <strong>part 3</strong>, we’ll take a look at our results along with some of the more advanced types of searches we can now perform.</p>\n<h2 id=\"Ok-let’s-do-this\"><a href=\"#Ok-let’s-do-this\" class=\"headerlink\" title=\"Ok, let’s do this\"></a>Ok, let’s do this</h2><p>First things first…assumptions!<br>If it isn’t obvious, we are using the Java based KillrVideo application for reference.  If you aren’t familiar with KillrVideo go take a look <a href=\"https://killrvideo.github.io/\" target=\"_blank\" rel=\"external\">here</a> to get up to speed.  In short, this is a real, open source, micro-service style application that we build and maintain to present examples and help folks understand the DataStax tech stack.  It’s also a nice way that I personally get some code time against the stack in a real application as compared to punching out demo apps.  </p>\n<p>We are using DataStax Enterprise from drivers to cluster.  All of the capabilities we’re talking about here are assumed to be within that ecosystem.</p>\n<a id=\"more\"></a>\n<h2 id=\"Do-we-really-need-to-use-DSE-Search\"><a href=\"#Do-we-really-need-to-use-DSE-Search\" class=\"headerlink\" title=\"Do we really need to use DSE Search?\"></a>Do we really need to use DSE Search?</h2><p>No. Maybe. Yes?  ¯\\_(ツ)_/¯<br>Ok, it depends, but for the most basic searches it isn’t a requirement.  As a matter of fact search was already implemented in the Java version without using DSE Search.  So, why the change?  Mostly it comes down to requirements and the right tool for the job.  So, before I get into all of this why don’t we take a look at the various types of searches that exist in KillrVideo.</p>\n<p>In KillrVideo, you can get details and play any video from the video detail page.  A quick look at the whole page and you can see all of the available searches.  At the top left is the <strong>“typeahead” search</strong> bar, over to the right are the <strong>tag search</strong> buttons, and at the very bottom is the <strong>“more videos like this”</strong> search.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/videodetail.png\" alt=\"videodetail\" title=\"videodetail\"></p>\n<h4 id=\"“Typeahead”-search\"><a href=\"#“Typeahead”-search\" class=\"headerlink\" title=\"“Typeahead” search\"></a>“Typeahead” search</h4><p>So, nothing new here really.  These types of searches have been around for quite some time.  Start typing letters in the search bar and you are provided with a list of potential matches<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/typeahead.png\" alt=\"typeahead\" title=\"typeahead\"></p>\n<h4 id=\"Tag-search\"><a href=\"#Tag-search\" class=\"headerlink\" title=\"Tag search\"></a>Tag search</h4><p>This next one is pretty straightforward as well.  If you click on any of the tag buttons on the video detail page it will perform a search for other videos with the same tag.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tag.png\" alt=\"tag\" title=\"tag\"></p>\n<h4 id=\"“More-videos-like-this”-search\"><a href=\"#“More-videos-like-this”-search\" class=\"headerlink\" title=\"“More videos like this” search\"></a>“More videos like this” search</h4><p>At the bottom of the video detail page is a section labeled “More Videos Like This”.  This search will happen automatically when you navigate to any video and present a set of videos that are similar to the video you are currently viewing.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/morelikethis.png\" alt=\"more videos like this\" title=\"more videos like this\"></p>\n<h3 id=\"Let’s-take-a-look-at-the-implementation\"><a href=\"#Let’s-take-a-look-at-the-implementation\" class=\"headerlink\" title=\"Let’s take a look at the implementation\"></a>Let’s take a look at the implementation</h3><p>Remember I mentioned <strong>before moving</strong> to using DSE Search these were all powered with Cassandra tables.  Let’s break some of this down and take a look at some details.  Also, if you are interested check out this <a href=\"https://github.com/KillrVideo/killrvideo-java/pull/23/files\" target=\"_blank\" rel=\"external\">pull request</a> up on github.  You can use this as a reference of the before and after changes if you so choose.</p>\n<h4 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h4><p>So overall the setup is pretty simple.  We have 3 searches that are supported by a combination of 3 Cassandra tables (the number of searches and tables just happen to match, there is no correlation between them), 3 <a href=\"https://docs.datastax.com/en/developer/java-driver-dse/1.4/manual/object_mapper/creating/\" target=\"_blank\" rel=\"external\">table entities</a> that map to our Cassandra tables, and 3 <a href=\"https://docs.datastax.com/en/developer/java-driver-dse/1.4/manual/object_mapper/using/\" target=\"_blank\" rel=\"external\">mapping objects</a> derived from our table entities.  Here is a simple visual representation.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/overviewarch.png\" alt=\"overview\" title=\"overview\"></p>\n<p>Now, I’m really pointing out these particular items because they will come into play later once we move to using DSE Search, namely, we will need to remove most of them.  We’ll leave that there for now and come back to it later.</p>\n<p>Of the 3 tables I just mentioned 2 of them exist only to support Cassandra based searches in KillrVideo, <strong>tags_by_letter</strong> and <strong>videos_by_tag</strong>.  They follow the <a href=\"https://www.datastax.com/dev/blog/basic-rules-of-cassandra-data-modeling\" target=\"_blank\" rel=\"external\">denormalized data model</a> pattern we’ve come to love in Cassandra and were created solely to support this purpose.  The <strong>videos</strong> table stores all videos inserted into KillrVideo.  It is not specialized to Cassandra based searches and will come into play a little later.</p>\n<p>I just mentioned that both <strong>tags_by_letter</strong> and <strong>videos_by_tag</strong> were specially created to support searches within KillrVideo.  Let’s take a deeper look at both tables and see what’s going on.  If you aren’t familiar with primary keys in Apache Cassandra&#8482<br> I highly suggest you take 5 minutes to read <a href=\"https://www.datastax.com/dev/blog/the-most-important-thing-to-know-in-cassandra-data-modeling-the-primary-key\" target=\"_blank\" rel=\"external\">Patrick McFadin’s post</a> on their importance.  This will better explain how they are applied below.</p>\n<p>Here is the CQL schema for the <strong>tags_by_letter</strong> table:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"keyword\">IF</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> tags_by_letter (</div><div class=\"line\">    first_letter <span class=\"built_in\">text</span>,</div><div class=\"line\">    tag <span class=\"built_in\">text</span>,</div><div class=\"line\">    PRIMARY <span class=\"keyword\">KEY</span> (first_letter, tag)</div><div class=\"line\">);</div></pre></td></tr></table></figure></p>\n<p>The <strong>first_letter</strong> column is the partition key with <strong>tag</strong> as a clustering column.  The partition key determines where data is located in your cluster while clustering columns handle how data is ordered within the partition.  This is especially useful in cases like a “typeahead” search where searches typically start with the first letter of a given search term and usually provide an alphabetical list of results.  This, in a sense, pre-optimizes query results and prevents us from having to sort our data, whether in query execution or code.</p>\n<p>Just to absolutely belabor this point (because who doesn’t like belaboring something) here is an example of this in action.  Notice how the results are sorted automatically per the <strong>tag</strong> column with no sorting or extra commands needed in the query.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tagsbyletterexample.png\" alt=\"tags_by_letter query example\" title=\"tags_by_letter query example\"></p>\n<p>Moving on, here is the CQL schema for the <strong>videos_by_tag</strong> table:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"keyword\">IF</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> videos_by_tag (</div><div class=\"line\">    tag <span class=\"built_in\">text</span>,</div><div class=\"line\">    videoid <span class=\"keyword\">uuid</span>,</div><div class=\"line\">    added_date <span class=\"keyword\">timestamp</span>,</div><div class=\"line\">    userid <span class=\"keyword\">uuid</span>,</div><div class=\"line\">    <span class=\"keyword\">name</span> <span class=\"built_in\">text</span>,</div><div class=\"line\">    preview_image_location <span class=\"built_in\">text</span>,</div><div class=\"line\">    tagged_date <span class=\"keyword\">timestamp</span>,</div><div class=\"line\">    PRIMARY <span class=\"keyword\">KEY</span> (tag, videoid)</div><div class=\"line\">);</div></pre></td></tr></table></figure></p>\n<p>Again, this table was specially created to answer the question of what videos have a specified tag.  It uses <strong>tag</strong> as the partition key which allows for fast retrieval of videos that match a tag when querying.  The other fields you see listed are there to provide information required by our web tier UI.</p>\n<h4 id=\"VideoAddedHandlers\"><a href=\"#VideoAddedHandlers\" class=\"headerlink\" title=\"VideoAddedHandlers\"></a>VideoAddedHandlers</h4><p>Another portion we need to keep an eye on is the VideoAddedHandlers class.  As the name implies this class is responsible for performing some action(s) every time a video is added to KillrVideo.  If you take a look at the two prepared statements within the init() method you should notice they are inserting data into the 2 search tables we mentioned above <strong>tags_by_letter</strong> and <strong>videos_by_tag</strong>.<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">videosByTagPrepared = dseSession.prepare(</div><div class=\"line\">        <span class=\"string\">\"INSERT INTO \"</span> + Schema.KEYSPACE + <span class=\"string\">\".\"</span> + videosByTagTableName + <span class=\"string\">\" \"</span> +</div><div class=\"line\">                <span class=\"string\">\"(tag, videoid, added_date, userid, name, preview_image_location, tagged_date) \"</span> +</div><div class=\"line\">                <span class=\"string\">\"VALUES (?, ?, ?, ?, ?, ?, ?)\"</span></div><div class=\"line\">);</div><div class=\"line\"></div><div class=\"line\">tagsByLetterPrepared = dseSession.prepare(</div><div class=\"line\">        <span class=\"string\">\"INSERT INTO \"</span> + Schema.KEYSPACE + <span class=\"string\">\".\"</span> + tagsByLetterTableName + <span class=\"string\">\" \"</span> +</div><div class=\"line\">                <span class=\"string\">\"(first_letter, tag) VALUES (?, ?)\"</span></div><div class=\"line\">);</div></pre></td></tr></table></figure></p>\n<p>Every time a video is added these queries are fired off to power our searches.  Notice some of the column names, things like “tag” and “first_letter”.  Again, we will dig into the detailed logic here soon.</p>\n<h4 id=\"Detailed-logic-here-soon\"><a href=\"#Detailed-logic-here-soon\" class=\"headerlink\" title=\"Detailed logic here soon\"></a>Detailed logic here soon</h4><p>Alrighty, so, we’ve gone over a high level overview of the various items and objects we are using to support our Cassandra based searches.  Now, let’s get into the searches themselves and see what they are doing.</p>\n<h5 id=\"“Typeahead”-search-1\"><a href=\"#“Typeahead”-search-1\" class=\"headerlink\" title=\"“Typeahead” search\"></a>“Typeahead” search</h5><p>As I mentioned above the typeahead search simply takes the values the user types into the search bar and provides search suggestions based off of the sequence of letters typed in usually with a wildcard attached to the end of the sequence.  An example is something like “d” which might return “database”, “decision”, “document”, etc… Then, if the user continues with something like “da” could be “database”, “databases”, “datastax”, etc… and so on.</p>\n<p>In the Cassandra based search case this is supported by the <strong>tags_by_letter</strong> table.  Every time a video is added the related subscriber method in the VideoAddedHandlers class is called and <strong>ALL</strong> tags are inserted along with the first letter of the tag into their respective columns.  Since multiple tags are allowed this means we end up looping through and batching up all commands for each tag.</p>\n<p>Then, when a user starts typing into the search bar we have the following query to get our results:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> tag <span class=\"keyword\">FROM</span> tags_by_letter <span class=\"keyword\">WHERE</span> first_letter = ? <span class=\"keyword\">AND</span> tag &gt;= ?</div></pre></td></tr></table></figure></p>\n<p>Which returns all tags that match the query string from our search.  We loop through those results and send our tags back to the UI.  Pretty simple.  </p>\n<p>Remember I previously mentioned the <strong>first_letter</strong> column is the partition key and <strong>tag</strong> is the clustering column which handles data ordering.  This is where this all comes into play.  </p>\n<p>At this point I’d like to point out that we are working only with tags.  <strong>Neither the name or description of any videos are considered</strong>.  Sure, we could add support for this in our data model and code if we really wanted to, but it is something we have to explicitly take into account if we want that capability. </p>\n<h5 id=\"Tag-search-1\"><a href=\"#Tag-search-1\" class=\"headerlink\" title=\"Tag search\"></a>Tag search</h5><p>Ok, let’s move to the tag based search.  This one is pretty straightforward.  Click on a tag button in the video details page and return all videos that have the same tag.  This search is supported by the <strong>videos_by_tag</strong> table.  Every time a video is added the related subscriber method in the VideoAddedHandlers class is called and an entry is made for each tag associated with the video.  If a video has one tag there will be a single entry, if it has 5 there will be 5 entries, and so on.  Note that the <strong>videos_by_tag</strong> table is optimized specifically for this task.</p>\n<p>If you click on a tag button the following query is executed:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> videos_by_tag <span class=\"keyword\">WHERE</span> tag = ?</div></pre></td></tr></table></figure></p>\n<p>Which returns all videos that match the tag provided in the query.  We send these back to the UI which provides a list of videos for you to choose from.</p>\n<h5 id=\"“More-videos-like-this”-search-1\"><a href=\"#“More-videos-like-this”-search-1\" class=\"headerlink\" title=\"“More videos like this” search\"></a>“More videos like this” search</h5><p>The related videos or “More videos like this” section is very similar to the tag search.  The difference in this case is instead of matching only to the selected tag this search will find videos that match all tags of the selected video.  So, if my selected video has tags of “datastax”, “dsl”, “graph”, and “gremlin” then the search will return videos that include any of those.  It uses the same query as the tag search above.  The only difference is we’ll perform a query for each tag that exists with the video and combine the results.</p>\n<h2 id=\"A-couple-things-to-point-out\"><a href=\"#A-couple-things-to-point-out\" class=\"headerlink\" title=\"A couple things to point out\"></a>A couple things to point out</h2><p>For one, notice how our tables and searches work in lock-step.  The tables were created to support a particular set of searches or “questions” asked by our application UI and our code supports whatever CRUD operations are needed to maintain the data we use for searches.  Essentially this was all purpose made to fit our search needs exactly in a denormalized fashion.  This is quite different from how we may have handled things in the relational world.</p>\n<p>Also notice the number of operations needed, mostly on the insert end, to constantly populate the search based tables with data when videos are added to the system.  Now, we’re talking about Cassandra here so this is not really that much of an issue, but there is overhead associated with those operations and the code needed to support it.</p>\n<h2 id=\"Why-move-to-DSE-Search\"><a href=\"#Why-move-to-DSE-Search\" class=\"headerlink\" title=\"Why move to DSE Search?\"></a>Why move to DSE Search?</h2><p>So, what happens now when we want to expand our searches to include more fields separate from tag, provide more varied results, or enable advanced searches?  Is there a way we could reduce the number of overall actions and code needed to support our searches and also speed things up?  Lastly, can we do this in such a way that does not take a whole rethink of our data model?</p>\n<p>Well, I think at this point you know exactly what I’m going to suggest, but you’ll have to wait until part 2 of this series for details.</p>\n<p>Oooo…suspense…I know….totally suspenseful</p>\n<p>Until then (quite soon honestly), thanks for reading and I hope you got something useful out of part 1.  Always feel free to add comments or contact me directly for any thoughts or questions.</p>\n<p>Take care :D</p>\n","excerpt":"<p>Hi there and welcome to <strong>part 1</strong> of a three part series on upgrading our KillrVideo java reference application from Cassandra based tabular searches to using DSE Search.</p>\n<p>Here in <strong>part 1</strong>, we’ll take a look at the “before” picture and how we were previously performing searches.  I’ll give some examples of the types of searches and how those were implemented with Cassandra tables.  We’ll also talk a little about the “why” of moving to DSE Search.</p>\n<p>In <strong>part 2</strong>, I’ll explain the transition to DSE Search and what considerations I had to take into account along with a before and after code comparison.</p>\n<p>Finally, in <strong>part 3</strong>, we’ll take a look at our results along with some of the more advanced types of searches we can now perform.</p>\n<h2 id=\"Ok-let’s-do-this\"><a href=\"#Ok-let’s-do-this\" class=\"headerlink\" title=\"Ok, let’s do this\"></a>Ok, let’s do this</h2><p>First things first…assumptions!<br>If it isn’t obvious, we are using the Java based KillrVideo application for reference.  If you aren’t familiar with KillrVideo go take a look <a href=\"https://killrvideo.github.io/\">here</a> to get up to speed.  In short, this is a real, open source, micro-service style application that we build and maintain to present examples and help folks understand the DataStax tech stack.  It’s also a nice way that I personally get some code time against the stack in a real application as compared to punching out demo apps.  </p>\n<p>We are using DataStax Enterprise from drivers to cluster.  All of the capabilities we’re talking about here are assumed to be within that ecosystem.</p>","more":"<h2 id=\"Do-we-really-need-to-use-DSE-Search\"><a href=\"#Do-we-really-need-to-use-DSE-Search\" class=\"headerlink\" title=\"Do we really need to use DSE Search?\"></a>Do we really need to use DSE Search?</h2><p>No. Maybe. Yes?  ¯\\_(ツ)_/¯<br>Ok, it depends, but for the most basic searches it isn’t a requirement.  As a matter of fact search was already implemented in the Java version without using DSE Search.  So, why the change?  Mostly it comes down to requirements and the right tool for the job.  So, before I get into all of this why don’t we take a look at the various types of searches that exist in KillrVideo.</p>\n<p>In KillrVideo, you can get details and play any video from the video detail page.  A quick look at the whole page and you can see all of the available searches.  At the top left is the <strong>“typeahead” search</strong> bar, over to the right are the <strong>tag search</strong> buttons, and at the very bottom is the <strong>“more videos like this”</strong> search.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/videodetail.png\" alt=\"videodetail\" title=\"videodetail\"></p>\n<h4 id=\"“Typeahead”-search\"><a href=\"#“Typeahead”-search\" class=\"headerlink\" title=\"“Typeahead” search\"></a>“Typeahead” search</h4><p>So, nothing new here really.  These types of searches have been around for quite some time.  Start typing letters in the search bar and you are provided with a list of potential matches<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/typeahead.png\" alt=\"typeahead\" title=\"typeahead\"></p>\n<h4 id=\"Tag-search\"><a href=\"#Tag-search\" class=\"headerlink\" title=\"Tag search\"></a>Tag search</h4><p>This next one is pretty straightforward as well.  If you click on any of the tag buttons on the video detail page it will perform a search for other videos with the same tag.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tag.png\" alt=\"tag\" title=\"tag\"></p>\n<h4 id=\"“More-videos-like-this”-search\"><a href=\"#“More-videos-like-this”-search\" class=\"headerlink\" title=\"“More videos like this” search\"></a>“More videos like this” search</h4><p>At the bottom of the video detail page is a section labeled “More Videos Like This”.  This search will happen automatically when you navigate to any video and present a set of videos that are similar to the video you are currently viewing.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/morelikethis.png\" alt=\"more videos like this\" title=\"more videos like this\"></p>\n<h3 id=\"Let’s-take-a-look-at-the-implementation\"><a href=\"#Let’s-take-a-look-at-the-implementation\" class=\"headerlink\" title=\"Let’s take a look at the implementation\"></a>Let’s take a look at the implementation</h3><p>Remember I mentioned <strong>before moving</strong> to using DSE Search these were all powered with Cassandra tables.  Let’s break some of this down and take a look at some details.  Also, if you are interested check out this <a href=\"https://github.com/KillrVideo/killrvideo-java/pull/23/files\">pull request</a> up on github.  You can use this as a reference of the before and after changes if you so choose.</p>\n<h4 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h4><p>So overall the setup is pretty simple.  We have 3 searches that are supported by a combination of 3 Cassandra tables (the number of searches and tables just happen to match, there is no correlation between them), 3 <a href=\"https://docs.datastax.com/en/developer/java-driver-dse/1.4/manual/object_mapper/creating/\">table entities</a> that map to our Cassandra tables, and 3 <a href=\"https://docs.datastax.com/en/developer/java-driver-dse/1.4/manual/object_mapper/using/\">mapping objects</a> derived from our table entities.  Here is a simple visual representation.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/overviewarch.png\" alt=\"overview\" title=\"overview\"></p>\n<p>Now, I’m really pointing out these particular items because they will come into play later once we move to using DSE Search, namely, we will need to remove most of them.  We’ll leave that there for now and come back to it later.</p>\n<p>Of the 3 tables I just mentioned 2 of them exist only to support Cassandra based searches in KillrVideo, <strong>tags_by_letter</strong> and <strong>videos_by_tag</strong>.  They follow the <a href=\"https://www.datastax.com/dev/blog/basic-rules-of-cassandra-data-modeling\">denormalized data model</a> pattern we’ve come to love in Cassandra and were created solely to support this purpose.  The <strong>videos</strong> table stores all videos inserted into KillrVideo.  It is not specialized to Cassandra based searches and will come into play a little later.</p>\n<p>I just mentioned that both <strong>tags_by_letter</strong> and <strong>videos_by_tag</strong> were specially created to support searches within KillrVideo.  Let’s take a deeper look at both tables and see what’s going on.  If you aren’t familiar with primary keys in Apache Cassandra&#8482<br> I highly suggest you take 5 minutes to read <a href=\"https://www.datastax.com/dev/blog/the-most-important-thing-to-know-in-cassandra-data-modeling-the-primary-key\">Patrick McFadin’s post</a> on their importance.  This will better explain how they are applied below.</p>\n<p>Here is the CQL schema for the <strong>tags_by_letter</strong> table:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"keyword\">IF</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> tags_by_letter (</div><div class=\"line\">    first_letter <span class=\"built_in\">text</span>,</div><div class=\"line\">    tag <span class=\"built_in\">text</span>,</div><div class=\"line\">    PRIMARY <span class=\"keyword\">KEY</span> (first_letter, tag)</div><div class=\"line\">);</div></pre></td></tr></table></figure></p>\n<p>The <strong>first_letter</strong> column is the partition key with <strong>tag</strong> as a clustering column.  The partition key determines where data is located in your cluster while clustering columns handle how data is ordered within the partition.  This is especially useful in cases like a “typeahead” search where searches typically start with the first letter of a given search term and usually provide an alphabetical list of results.  This, in a sense, pre-optimizes query results and prevents us from having to sort our data, whether in query execution or code.</p>\n<p>Just to absolutely belabor this point (because who doesn’t like belaboring something) here is an example of this in action.  Notice how the results are sorted automatically per the <strong>tag</strong> column with no sorting or extra commands needed in the query.<br><img src=\"/2018/01/10/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tagsbyletterexample.png\" alt=\"tags_by_letter query example\" title=\"tags_by_letter query example\"></p>\n<p>Moving on, here is the CQL schema for the <strong>videos_by_tag</strong> table:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">CREATE</span> <span class=\"keyword\">TABLE</span> <span class=\"keyword\">IF</span> <span class=\"keyword\">NOT</span> <span class=\"keyword\">EXISTS</span> videos_by_tag (</div><div class=\"line\">    tag <span class=\"built_in\">text</span>,</div><div class=\"line\">    videoid <span class=\"keyword\">uuid</span>,</div><div class=\"line\">    added_date <span class=\"keyword\">timestamp</span>,</div><div class=\"line\">    userid <span class=\"keyword\">uuid</span>,</div><div class=\"line\">    <span class=\"keyword\">name</span> <span class=\"built_in\">text</span>,</div><div class=\"line\">    preview_image_location <span class=\"built_in\">text</span>,</div><div class=\"line\">    tagged_date <span class=\"keyword\">timestamp</span>,</div><div class=\"line\">    PRIMARY <span class=\"keyword\">KEY</span> (tag, videoid)</div><div class=\"line\">);</div></pre></td></tr></table></figure></p>\n<p>Again, this table was specially created to answer the question of what videos have a specified tag.  It uses <strong>tag</strong> as the partition key which allows for fast retrieval of videos that match a tag when querying.  The other fields you see listed are there to provide information required by our web tier UI.</p>\n<h4 id=\"VideoAddedHandlers\"><a href=\"#VideoAddedHandlers\" class=\"headerlink\" title=\"VideoAddedHandlers\"></a>VideoAddedHandlers</h4><p>Another portion we need to keep an eye on is the VideoAddedHandlers class.  As the name implies this class is responsible for performing some action(s) every time a video is added to KillrVideo.  If you take a look at the two prepared statements within the init() method you should notice they are inserting data into the 2 search tables we mentioned above <strong>tags_by_letter</strong> and <strong>videos_by_tag</strong>.<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">videosByTagPrepared = dseSession.prepare(</div><div class=\"line\">        <span class=\"string\">\"INSERT INTO \"</span> + Schema.KEYSPACE + <span class=\"string\">\".\"</span> + videosByTagTableName + <span class=\"string\">\" \"</span> +</div><div class=\"line\">                <span class=\"string\">\"(tag, videoid, added_date, userid, name, preview_image_location, tagged_date) \"</span> +</div><div class=\"line\">                <span class=\"string\">\"VALUES (?, ?, ?, ?, ?, ?, ?)\"</span></div><div class=\"line\">);</div><div class=\"line\"></div><div class=\"line\">tagsByLetterPrepared = dseSession.prepare(</div><div class=\"line\">        <span class=\"string\">\"INSERT INTO \"</span> + Schema.KEYSPACE + <span class=\"string\">\".\"</span> + tagsByLetterTableName + <span class=\"string\">\" \"</span> +</div><div class=\"line\">                <span class=\"string\">\"(first_letter, tag) VALUES (?, ?)\"</span></div><div class=\"line\">);</div></pre></td></tr></table></figure></p>\n<p>Every time a video is added these queries are fired off to power our searches.  Notice some of the column names, things like “tag” and “first_letter”.  Again, we will dig into the detailed logic here soon.</p>\n<h4 id=\"Detailed-logic-here-soon\"><a href=\"#Detailed-logic-here-soon\" class=\"headerlink\" title=\"Detailed logic here soon\"></a>Detailed logic here soon</h4><p>Alrighty, so, we’ve gone over a high level overview of the various items and objects we are using to support our Cassandra based searches.  Now, let’s get into the searches themselves and see what they are doing.</p>\n<h5 id=\"“Typeahead”-search-1\"><a href=\"#“Typeahead”-search-1\" class=\"headerlink\" title=\"“Typeahead” search\"></a>“Typeahead” search</h5><p>As I mentioned above the typeahead search simply takes the values the user types into the search bar and provides search suggestions based off of the sequence of letters typed in usually with a wildcard attached to the end of the sequence.  An example is something like “d” which might return “database”, “decision”, “document”, etc… Then, if the user continues with something like “da” could be “database”, “databases”, “datastax”, etc… and so on.</p>\n<p>In the Cassandra based search case this is supported by the <strong>tags_by_letter</strong> table.  Every time a video is added the related subscriber method in the VideoAddedHandlers class is called and <strong>ALL</strong> tags are inserted along with the first letter of the tag into their respective columns.  Since multiple tags are allowed this means we end up looping through and batching up all commands for each tag.</p>\n<p>Then, when a user starts typing into the search bar we have the following query to get our results:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> tag <span class=\"keyword\">FROM</span> tags_by_letter <span class=\"keyword\">WHERE</span> first_letter = ? <span class=\"keyword\">AND</span> tag &gt;= ?</div></pre></td></tr></table></figure></p>\n<p>Which returns all tags that match the query string from our search.  We loop through those results and send our tags back to the UI.  Pretty simple.  </p>\n<p>Remember I previously mentioned the <strong>first_letter</strong> column is the partition key and <strong>tag</strong> is the clustering column which handles data ordering.  This is where this all comes into play.  </p>\n<p>At this point I’d like to point out that we are working only with tags.  <strong>Neither the name or description of any videos are considered</strong>.  Sure, we could add support for this in our data model and code if we really wanted to, but it is something we have to explicitly take into account if we want that capability. </p>\n<h5 id=\"Tag-search-1\"><a href=\"#Tag-search-1\" class=\"headerlink\" title=\"Tag search\"></a>Tag search</h5><p>Ok, let’s move to the tag based search.  This one is pretty straightforward.  Click on a tag button in the video details page and return all videos that have the same tag.  This search is supported by the <strong>videos_by_tag</strong> table.  Every time a video is added the related subscriber method in the VideoAddedHandlers class is called and an entry is made for each tag associated with the video.  If a video has one tag there will be a single entry, if it has 5 there will be 5 entries, and so on.  Note that the <strong>videos_by_tag</strong> table is optimized specifically for this task.</p>\n<p>If you click on a tag button the following query is executed:<br><figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> videos_by_tag <span class=\"keyword\">WHERE</span> tag = ?</div></pre></td></tr></table></figure></p>\n<p>Which returns all videos that match the tag provided in the query.  We send these back to the UI which provides a list of videos for you to choose from.</p>\n<h5 id=\"“More-videos-like-this”-search-1\"><a href=\"#“More-videos-like-this”-search-1\" class=\"headerlink\" title=\"“More videos like this” search\"></a>“More videos like this” search</h5><p>The related videos or “More videos like this” section is very similar to the tag search.  The difference in this case is instead of matching only to the selected tag this search will find videos that match all tags of the selected video.  So, if my selected video has tags of “datastax”, “dsl”, “graph”, and “gremlin” then the search will return videos that include any of those.  It uses the same query as the tag search above.  The only difference is we’ll perform a query for each tag that exists with the video and combine the results.</p>\n<h2 id=\"A-couple-things-to-point-out\"><a href=\"#A-couple-things-to-point-out\" class=\"headerlink\" title=\"A couple things to point out\"></a>A couple things to point out</h2><p>For one, notice how our tables and searches work in lock-step.  The tables were created to support a particular set of searches or “questions” asked by our application UI and our code supports whatever CRUD operations are needed to maintain the data we use for searches.  Essentially this was all purpose made to fit our search needs exactly in a denormalized fashion.  This is quite different from how we may have handled things in the relational world.</p>\n<p>Also notice the number of operations needed, mostly on the insert end, to constantly populate the search based tables with data when videos are added to the system.  Now, we’re talking about Cassandra here so this is not really that much of an issue, but there is overhead associated with those operations and the code needed to support it.</p>\n<h2 id=\"Why-move-to-DSE-Search\"><a href=\"#Why-move-to-DSE-Search\" class=\"headerlink\" title=\"Why move to DSE Search?\"></a>Why move to DSE Search?</h2><p>So, what happens now when we want to expand our searches to include more fields separate from tag, provide more varied results, or enable advanced searches?  Is there a way we could reduce the number of overall actions and code needed to support our searches and also speed things up?  Lastly, can we do this in such a way that does not take a whole rethink of our data model?</p>\n<p>Well, I think at this point you know exactly what I’m going to suggest, but you’ll have to wait until part 2 of this series for details.</p>\n<p>Oooo…suspense…I know….totally suspenseful</p>\n<p>Until then (quite soon honestly), thanks for reading and I hope you got something useful out of part 1.  Always feel free to add comments or contact me directly for any thoughts or questions.</p>\n<p>Take care :D</p>"},{"title":"Ok, yea, so maybe it's been a while since I posted","date":"2018-01-09T15:38:20.000Z","_content":"So...I've been busy.  Quite busy since the last time I posted.  Let's see, I got married, added 2 greyhounds to the family, repaired things from Hurricane Irma, been digging into all things [DataStax][datastax], and I have a child on the way (due March 15th).  On the [DataStax][datastax] and [KillrVideo][killrvideo] front I added both a graph based recommendation engine with [DSE Graph][dsegraph] and recently [DSE Search][dsesearch] capability for all video searches in the [Java][killrvideo-java] version.  We also have SparkSQL fun coming up here soon as well.  All of the [application code][killrvideo-java] is available for folks to really do whatever they want with it.  Feel free to leave comments, issues, or make pull requests if you have something fun to add.  My main goal is for KillrVideo to be useful to folks trying to figure this stuff out.\n\nOnce Spark gets into the mix KillrVideo will cover the 4 horsemen of [DataStax Enterprise][enterprise], namely, \n**[Cassandra][enterprise]**, **[Graph][dsegraph]**, **[Search][dsesearch]**, and **[Analytics][dseanalytics]**.  \n<iframe src=\"https://giphy.com/embed/4lF4W1jzt6jC0\" width=\"480\" height=\"272\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\n<!-- more -->\n\nAnd then...\n...this battle station will be fully operational!!!!\n<iframe src=\"https://giphy.com/embed/yI3rO1XBSf0He\" width=\"480\" height=\"203\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\nMostly, except for some unfinished turbo lasers, maybe some panels, like a whole hemisphere worth, just some small items really.\n\n## Sooooo much cool stuff coming!\nSeriously, new OpsCenter, Studio, and DSE everything updates on the way along with a child, but that last one is not part of the normal development cycle....kind of a side project.  Once I can talk about some of the new changes I'll start posting and getting things worked into code.\n\nUntil then I'll be posting about much of what I've been up to this last year and passing on some things I've learned while wrapping my tendrils around all of this NoSQL distributed database stuff.  Fun for all I'm sure.  ;)\n\n\n\n[datastax]: https://www.datastax.com/\n[enterprise]: https://www.datastax.com/products/datastax-enterprise\n[killrvideo]: https://killrvideo.github.io/\n[dsegraph]: http://www.datastax.com/products/datastax-enterprise-graph\n[dsesearch]: https://www.datastax.com/products/datastax-enterprise-search\n[dseanalytics]: https://www.datastax.com/products/datastax-enterprise-analytics\n[opscenter]: https://www.datastax.com/products/datastax-opscenter\n[studio]: https://www.datastax.com/products/datastax-studio-and-development-tools#DataStax-Studio\n[killrvideo-java]: https://github.com/KillrVideo/killrvideo-java","source":"_posts/Ok-yea-so-maybe-it-s-been-a-while-since-I-posted.md","raw":"---\ntitle: 'Ok, yea, so maybe it''s been a while since I posted'\ndate: 2018-01-09 10:38:20\ncategories:\n    - Something Else\ntags:\n    - killrvideo\n    - datastax\n---\nSo...I've been busy.  Quite busy since the last time I posted.  Let's see, I got married, added 2 greyhounds to the family, repaired things from Hurricane Irma, been digging into all things [DataStax][datastax], and I have a child on the way (due March 15th).  On the [DataStax][datastax] and [KillrVideo][killrvideo] front I added both a graph based recommendation engine with [DSE Graph][dsegraph] and recently [DSE Search][dsesearch] capability for all video searches in the [Java][killrvideo-java] version.  We also have SparkSQL fun coming up here soon as well.  All of the [application code][killrvideo-java] is available for folks to really do whatever they want with it.  Feel free to leave comments, issues, or make pull requests if you have something fun to add.  My main goal is for KillrVideo to be useful to folks trying to figure this stuff out.\n\nOnce Spark gets into the mix KillrVideo will cover the 4 horsemen of [DataStax Enterprise][enterprise], namely, \n**[Cassandra][enterprise]**, **[Graph][dsegraph]**, **[Search][dsesearch]**, and **[Analytics][dseanalytics]**.  \n<iframe src=\"https://giphy.com/embed/4lF4W1jzt6jC0\" width=\"480\" height=\"272\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\n\n<!-- more -->\n\nAnd then...\n...this battle station will be fully operational!!!!\n<iframe src=\"https://giphy.com/embed/yI3rO1XBSf0He\" width=\"480\" height=\"203\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>\nMostly, except for some unfinished turbo lasers, maybe some panels, like a whole hemisphere worth, just some small items really.\n\n## Sooooo much cool stuff coming!\nSeriously, new OpsCenter, Studio, and DSE everything updates on the way along with a child, but that last one is not part of the normal development cycle....kind of a side project.  Once I can talk about some of the new changes I'll start posting and getting things worked into code.\n\nUntil then I'll be posting about much of what I've been up to this last year and passing on some things I've learned while wrapping my tendrils around all of this NoSQL distributed database stuff.  Fun for all I'm sure.  ;)\n\n\n\n[datastax]: https://www.datastax.com/\n[enterprise]: https://www.datastax.com/products/datastax-enterprise\n[killrvideo]: https://killrvideo.github.io/\n[dsegraph]: http://www.datastax.com/products/datastax-enterprise-graph\n[dsesearch]: https://www.datastax.com/products/datastax-enterprise-search\n[dseanalytics]: https://www.datastax.com/products/datastax-enterprise-analytics\n[opscenter]: https://www.datastax.com/products/datastax-opscenter\n[studio]: https://www.datastax.com/products/datastax-studio-and-development-tools#DataStax-Studio\n[killrvideo-java]: https://github.com/KillrVideo/killrvideo-java","slug":"Ok-yea-so-maybe-it-s-been-a-while-since-I-posted","published":1,"updated":"2018-01-09T19:14:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjdkqmjeu000gnhkmqvx9yq8a","content":"<p>So…I’ve been busy.  Quite busy since the last time I posted.  Let’s see, I got married, added 2 greyhounds to the family, repaired things from Hurricane Irma, been digging into all things <a href=\"https://www.datastax.com/\" target=\"_blank\" rel=\"external\">DataStax</a>, and I have a child on the way (due March 15th).  On the <a href=\"https://www.datastax.com/\" target=\"_blank\" rel=\"external\">DataStax</a> and <a href=\"https://killrvideo.github.io/\" target=\"_blank\" rel=\"external\">KillrVideo</a> front I added both a graph based recommendation engine with <a href=\"http://www.datastax.com/products/datastax-enterprise-graph\" target=\"_blank\" rel=\"external\">DSE Graph</a> and recently <a href=\"https://www.datastax.com/products/datastax-enterprise-search\" target=\"_blank\" rel=\"external\">DSE Search</a> capability for all video searches in the <a href=\"https://github.com/KillrVideo/killrvideo-java\" target=\"_blank\" rel=\"external\">Java</a> version.  We also have SparkSQL fun coming up here soon as well.  All of the <a href=\"https://github.com/KillrVideo/killrvideo-java\" target=\"_blank\" rel=\"external\">application code</a> is available for folks to really do whatever they want with it.  Feel free to leave comments, issues, or make pull requests if you have something fun to add.  My main goal is for KillrVideo to be useful to folks trying to figure this stuff out.</p>\n<p>Once Spark gets into the mix KillrVideo will cover the 4 horsemen of <a href=\"https://www.datastax.com/products/datastax-enterprise\" target=\"_blank\" rel=\"external\">DataStax Enterprise</a>, namely,<br><strong><a href=\"https://www.datastax.com/products/datastax-enterprise\" target=\"_blank\" rel=\"external\">Cassandra</a></strong>, <strong><a href=\"http://www.datastax.com/products/datastax-enterprise-graph\" target=\"_blank\" rel=\"external\">Graph</a></strong>, <strong><a href=\"https://www.datastax.com/products/datastax-enterprise-search\" target=\"_blank\" rel=\"external\">Search</a></strong>, and <strong><a href=\"https://www.datastax.com/products/datastax-enterprise-analytics\" target=\"_blank\" rel=\"external\">Analytics</a></strong>.  </p>\n<iframe src=\"https://giphy.com/embed/4lF4W1jzt6jC0\" width=\"480\" height=\"272\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe>\n\n<a id=\"more\"></a>\n<p>And then…<br>…this battle station will be fully operational!!!!</p>\n<p><iframe src=\"https://giphy.com/embed/yI3rO1XBSf0He\" width=\"480\" height=\"203\" frameborder=\"0\" class=\"giphy-embed\" allowfullscreen></iframe><br>Mostly, except for some unfinished turbo lasers, maybe some panels, like a whole hemisphere worth, just some small items really.</p>\n<h2 id=\"Sooooo-much-cool-stuff-coming\"><a href=\"#Sooooo-much-cool-stuff-coming\" class=\"headerlink\" title=\"Sooooo much cool stuff coming!\"></a>Sooooo much cool stuff coming!</h2><p>Seriously, new OpsCenter, Studio, and DSE everything updates on the way along with a child, but that last one is not part of the normal development cycle….kind of a side project.  Once I can talk about some of the new changes I’ll start posting and getting things worked into code.</p>\n<p>Until then I’ll be posting about much of what I’ve been up to this last year and passing on some things I’ve learned while wrapping my tendrils around all of this NoSQL distributed database stuff.  Fun for all I’m sure.  ;)</p>\n","excerpt":"<p>So…I’ve been busy.  Quite busy since the last time I posted.  Let’s see, I got married, added 2 greyhounds to the family, repaired things from Hurricane Irma, been digging into all things <a href=\"https://www.datastax.com/\">DataStax</a>, and I have a child on the way (due March 15th).  On the <a href=\"https://www.datastax.com/\">DataStax</a> and <a href=\"https://killrvideo.github.io/\">KillrVideo</a> front I added both a graph based recommendation engine with <a href=\"http://www.datastax.com/products/datastax-enterprise-graph\">DSE Graph</a> and recently <a href=\"https://www.datastax.com/products/datastax-enterprise-search\">DSE Search</a> capability for all video searches in the <a href=\"https://github.com/KillrVideo/killrvideo-java\">Java</a> version.  We also have SparkSQL fun coming up here soon as well.  All of the <a href=\"https://github.com/KillrVideo/killrvideo-java\">application code</a> is available for folks to really do whatever they want with it.  Feel free to leave comments, issues, or make pull requests if you have something fun to add.  My main goal is for KillrVideo to be useful to folks trying to figure this stuff out.</p>\n<p>Once Spark gets into the mix KillrVideo will cover the 4 horsemen of <a href=\"https://www.datastax.com/products/datastax-enterprise\">DataStax Enterprise</a>, namely,<br><strong><a href=\"https://www.datastax.com/products/datastax-enterprise\">Cassandra</a></strong>, <strong><a href=\"http://www.datastax.com/products/datastax-enterprise-graph\">Graph</a></strong>, <strong><a href=\"https://www.datastax.com/products/datastax-enterprise-search\">Search</a></strong>, and <strong><a href=\"https://www.datastax.com/products/datastax-enterprise-analytics\">Analytics</a></strong>.  </p>\n<iframe src=\"https://giphy.com/embed/4lF4W1jzt6jC0\" width=\"480\" height=\"272\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe>","more":"<p>And then…<br>…this battle station will be fully operational!!!!</p>\n<p><iframe src=\"https://giphy.com/embed/yI3rO1XBSf0He\" width=\"480\" height=\"203\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><br>Mostly, except for some unfinished turbo lasers, maybe some panels, like a whole hemisphere worth, just some small items really.</p>\n<h2 id=\"Sooooo-much-cool-stuff-coming\"><a href=\"#Sooooo-much-cool-stuff-coming\" class=\"headerlink\" title=\"Sooooo much cool stuff coming!\"></a>Sooooo much cool stuff coming!</h2><p>Seriously, new OpsCenter, Studio, and DSE everything updates on the way along with a child, but that last one is not part of the normal development cycle….kind of a side project.  Once I can talk about some of the new changes I’ll start posting and getting things worked into code.</p>\n<p>Until then I’ll be posting about much of what I’ve been up to this last year and passing on some things I’ve learned while wrapping my tendrils around all of this NoSQL distributed database stuff.  Fun for all I’m sure.  ;)</p>"}],"PostAsset":[{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberry.jpg","slug":"raspberry.jpg","post":"cjdkqmjee0006nhkmfmlpf7j5","modified":1,"renderable":0},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch2.png","slug":"videoswithsearch2.png","post":"cjdkqmjen000anhkmc0t1jaat","modified":1,"renderable":0},{"_id":"source/_posts/Dropping-in-on-my-cluster/datastax_drop.gif","slug":"datastax_drop.gif","post":"cjdkqmjdy0002nhkmtoby0ogn","modified":1,"renderable":0},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/myPIs.gif","slug":"myPIs.gif","post":"cjdkqmjee0006nhkmfmlpf7j5","modified":1,"renderable":0},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/opscenter_cluster.png","post":"cjdkqmjee0006nhkmfmlpf7j5","slug":"opscenter_cluster.png","modified":1,"renderable":1},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/pie-pi.jpg","post":"cjdkqmjee0006nhkmfmlpf7j5","slug":"pie-pi.jpg","modified":1,"renderable":1},{"_id":"source/_posts/Mixed-Workload-DSE-Cluster-with-Raspberry-PI-s/raspberrypi.jpg","post":"cjdkqmjee0006nhkmfmlpf7j5","slug":"raspberrypi.jpg","modified":1,"renderable":1},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/morelikethis.png","slug":"morelikethis.png","post":"cjdkqmjep000cnhkmuq5k4kxv","modified":1,"renderable":0},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/overviewarch.png","post":"cjdkqmjep000cnhkmuq5k4kxv","slug":"overviewarch.png","modified":1,"renderable":1},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tag.png","post":"cjdkqmjep000cnhkmuq5k4kxv","slug":"tag.png","modified":1,"renderable":1},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/tagsbyletterexample.png","post":"cjdkqmjep000cnhkmuq5k4kxv","slug":"tagsbyletterexample.png","modified":1,"renderable":1},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/typeahead.png","slug":"typeahead.png","post":"cjdkqmjep000cnhkmuq5k4kxv","modified":1,"renderable":0},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-I/videodetail.png","slug":"videodetail.png","post":"cjdkqmjep000cnhkmuq5k4kxv","modified":1,"renderable":0},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/hugesearchbarlist.png","slug":"hugesearchbarlist.png","post":"cjdkqmjen000anhkmc0t1jaat","modified":1,"renderable":0},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/morelikethis.png","slug":"morelikethis.png","post":"cjdkqmjen000anhkmc0t1jaat","modified":1,"renderable":0},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/notag.png","slug":"notag.png","post":"cjdkqmjen000anhkmc0t1jaat","modified":1,"renderable":0},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tag.png","post":"cjdkqmjen000anhkmc0t1jaat","slug":"tag.png","modified":1,"renderable":1},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/tagsbyletterorig.png","post":"cjdkqmjen000anhkmc0t1jaat","slug":"tagsbyletterorig.png","modified":1,"renderable":1},{"_id":"source/_posts/Moving-from-Cassandra-tables-to-Search-with-DataStax-Part-2/videoswithsearch1.png","post":"cjdkqmjen000anhkmc0t1jaat","slug":"videoswithsearch1.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"cjdkqmjee0006nhkmfmlpf7j5","category_id":"cjdkqmje20003nhkmhq6tuaym","_id":"cjdkqmjep000bnhkmxie9uo4l"},{"post_id":"cjdkqmjds0001nhkm3dxrj2l7","category_id":"cjdkqmje20003nhkmhq6tuaym","_id":"cjdkqmjet000fnhkmwtlz73xs"},{"post_id":"cjdkqmjej0007nhkm7nbywoua","category_id":"cjdkqmje20003nhkmhq6tuaym","_id":"cjdkqmjew000hnhkmdcb839lp"},{"post_id":"cjdkqmjen000anhkmc0t1jaat","category_id":"cjdkqmje20003nhkmhq6tuaym","_id":"cjdkqmjex000jnhkmroxhf7zm"},{"post_id":"cjdkqmjdy0002nhkmtoby0ogn","category_id":"cjdkqmjek0008nhkmvlrxg3xz","_id":"cjdkqmjex000knhkmak2g8ih8"},{"post_id":"cjdkqmjep000cnhkmuq5k4kxv","category_id":"cjdkqmje20003nhkmhq6tuaym","_id":"cjdkqmjey000lnhkmfeapdtvi"},{"post_id":"cjdkqmjeu000gnhkmqvx9yq8a","category_id":"cjdkqmjes000dnhkmvu8o6p7j","_id":"cjdkqmjey000nnhkmb03v63ed"},{"post_id":"cjdkqmje50005nhkm631rdeng","category_id":"cjdkqmjes000dnhkmvu8o6p7j","_id":"cjdkqmjez000onhkm4xju6c7j"}],"PostTag":[{"post_id":"cjdkqmjds0001nhkm3dxrj2l7","tag_id":"cjdkqmje40004nhkmq0u68hlw","_id":"cjdkqmjf1000qnhkmzkkbinj1"},{"post_id":"cjdkqmjds0001nhkm3dxrj2l7","tag_id":"cjdkqmjel0009nhkm76fo1oz1","_id":"cjdkqmjf1000rnhkmg624td43"},{"post_id":"cjdkqmjds0001nhkm3dxrj2l7","tag_id":"cjdkqmjes000enhkmeiu3lk5y","_id":"cjdkqmjf2000tnhkm5drjs6kx"},{"post_id":"cjdkqmjds0001nhkm3dxrj2l7","tag_id":"cjdkqmjew000inhkm2sgo7yvi","_id":"cjdkqmjf2000unhkmroluvxii"},{"post_id":"cjdkqmjds0001nhkm3dxrj2l7","tag_id":"cjdkqmjey000mnhkma4hs2enm","_id":"cjdkqmjf3000wnhkmefyhg0sk"},{"post_id":"cjdkqmjdy0002nhkmtoby0ogn","tag_id":"cjdkqmjf0000pnhkmb2fxi66v","_id":"cjdkqmjf7000znhkm60qq8bmw"},{"post_id":"cjdkqmjdy0002nhkmtoby0ogn","tag_id":"cjdkqmjf1000snhkm8lx652zi","_id":"cjdkqmjf70010nhkmjabtjjfl"},{"post_id":"cjdkqmjdy0002nhkmtoby0ogn","tag_id":"cjdkqmjf2000vnhkm6aoeok9p","_id":"cjdkqmjf80012nhkmoj4bfgdk"},{"post_id":"cjdkqmjdy0002nhkmtoby0ogn","tag_id":"cjdkqmjf4000xnhkm4ijlx3bc","_id":"cjdkqmjf90013nhkmrhj4t9v6"},{"post_id":"cjdkqmje50005nhkm631rdeng","tag_id":"cjdkqmjf7000ynhkmww3iylh7","_id":"cjdkqmjfb0017nhkm7kvtxdlx"},{"post_id":"cjdkqmje50005nhkm631rdeng","tag_id":"cjdkqmjf80011nhkmnzfx8vp9","_id":"cjdkqmjfc0018nhkml8eu5jx3"},{"post_id":"cjdkqmje50005nhkm631rdeng","tag_id":"cjdkqmjf90014nhkmn9eenznt","_id":"cjdkqmjfc001anhkmfso2oniu"},{"post_id":"cjdkqmje50005nhkm631rdeng","tag_id":"cjdkqmjfa0015nhkmdwfmo5zq","_id":"cjdkqmjfd001bnhkm53zui5f7"},{"post_id":"cjdkqmjee0006nhkmfmlpf7j5","tag_id":"cjdkqmjfa0016nhkmfa9k580a","_id":"cjdkqmjff001enhkm4as3wuhn"},{"post_id":"cjdkqmjee0006nhkmfmlpf7j5","tag_id":"cjdkqmjfc0019nhkmhq412i1x","_id":"cjdkqmjff001fnhkmvighn23c"},{"post_id":"cjdkqmjee0006nhkmfmlpf7j5","tag_id":"cjdkqmjey000mnhkma4hs2enm","_id":"cjdkqmjff001hnhkmhpp1cxvz"},{"post_id":"cjdkqmjej0007nhkm7nbywoua","tag_id":"cjdkqmjey000mnhkma4hs2enm","_id":"cjdkqmjfg001knhkmgcemmb48"},{"post_id":"cjdkqmjej0007nhkm7nbywoua","tag_id":"cjdkqmjf0000pnhkmb2fxi66v","_id":"cjdkqmjfg001lnhkm5ow0r2nt"},{"post_id":"cjdkqmjej0007nhkm7nbywoua","tag_id":"cjdkqmjff001inhkmetkpgiqn","_id":"cjdkqmjfg001nnhkmrwxkb69i"},{"post_id":"cjdkqmjen000anhkmc0t1jaat","tag_id":"cjdkqmjey000mnhkma4hs2enm","_id":"cjdkqmjfk001rnhkm4nqjvl29"},{"post_id":"cjdkqmjen000anhkmc0t1jaat","tag_id":"cjdkqmjf0000pnhkmb2fxi66v","_id":"cjdkqmjfl001snhkmpoefdnyg"},{"post_id":"cjdkqmjen000anhkmc0t1jaat","tag_id":"cjdkqmjff001inhkmetkpgiqn","_id":"cjdkqmjfl001unhkmc0pe3t7a"},{"post_id":"cjdkqmjen000anhkmc0t1jaat","tag_id":"cjdkqmjfh001pnhkmktb34pu0","_id":"cjdkqmjfl001vnhkmr46c0z0c"},{"post_id":"cjdkqmjep000cnhkmuq5k4kxv","tag_id":"cjdkqmjey000mnhkma4hs2enm","_id":"cjdkqmjfo001znhkm47llcrmi"},{"post_id":"cjdkqmjep000cnhkmuq5k4kxv","tag_id":"cjdkqmjf0000pnhkmb2fxi66v","_id":"cjdkqmjfo0020nhkmddwj6s8s"},{"post_id":"cjdkqmjep000cnhkmuq5k4kxv","tag_id":"cjdkqmjff001inhkmetkpgiqn","_id":"cjdkqmjfp0022nhkmwpd2ndg9"},{"post_id":"cjdkqmjep000cnhkmuq5k4kxv","tag_id":"cjdkqmjfh001pnhkmktb34pu0","_id":"cjdkqmjfq0023nhkmz7biv5ug"},{"post_id":"cjdkqmjeu000gnhkmqvx9yq8a","tag_id":"cjdkqmjey000mnhkma4hs2enm","_id":"cjdkqmjfq0024nhkmki11c2gw"},{"post_id":"cjdkqmjeu000gnhkmqvx9yq8a","tag_id":"cjdkqmjf0000pnhkmb2fxi66v","_id":"cjdkqmjfq0025nhkmku0po0p5"}],"Tag":[{"name":"TIL","_id":"cjdkqmje40004nhkmq0u68hlw"},{"name":"async","_id":"cjdkqmjel0009nhkm76fo1oz1"},{"name":"blocking","_id":"cjdkqmjes000enhkmeiu3lk5y"},{"name":"java","_id":"cjdkqmjew000inhkm2sgo7yvi"},{"name":"killrvideo","_id":"cjdkqmjey000mnhkma4hs2enm"},{"name":"datastax","_id":"cjdkqmjf0000pnhkmb2fxi66v"},{"name":"opscenter","_id":"cjdkqmjf1000snhkm8lx652zi"},{"name":"aerial","_id":"cjdkqmjf2000vnhkm6aoeok9p"},{"name":"drop","_id":"cjdkqmjf4000xnhkm4ijlx3bc"},{"name":"hi there","_id":"cjdkqmjf7000ynhkmww3iylh7"},{"name":"welcome","_id":"cjdkqmjf80011nhkmnzfx8vp9"},{"name":"fun times","_id":"cjdkqmjf90014nhkmn9eenznt"},{"name":"OMG","_id":"cjdkqmjfa0015nhkmdwfmo5zq"},{"name":"raspberry PI","_id":"cjdkqmjfa0016nhkmfa9k580a"},{"name":"cluster","_id":"cjdkqmjfc0019nhkmhq412i1x"},{"name":"search","_id":"cjdkqmjff001inhkmetkpgiqn"},{"name":"DSE Search","_id":"cjdkqmjfh001pnhkmktb34pu0"}]}}